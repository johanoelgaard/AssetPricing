{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model for predicting the electricity prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "\n",
    "from modelling import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# moving to GPU if available (Metal)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpotPrice</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>temp_pca_1</th>\n",
       "      <th>temp_pca_2</th>\n",
       "      <th>temp_pca_3</th>\n",
       "      <th>wind_speed_pca_1</th>\n",
       "      <th>wind_speed_pca_2</th>\n",
       "      <th>wind_speed_pca_3</th>\n",
       "      <th>wind_speed_pca_4</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_wind_dir_pca_39</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>gas_price</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596.570007</td>\n",
       "      <td>2024-11-29 23:00:00+00:00</td>\n",
       "      <td>2024-11-30 00:00:00+00:00</td>\n",
       "      <td>-33.480249</td>\n",
       "      <td>7.339981</td>\n",
       "      <td>1.718044</td>\n",
       "      <td>3.248249</td>\n",
       "      <td>2.159318</td>\n",
       "      <td>0.612078</td>\n",
       "      <td>3.505092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093112</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770.270020</td>\n",
       "      <td>2024-11-29 22:00:00+00:00</td>\n",
       "      <td>2024-11-29 23:00:00+00:00</td>\n",
       "      <td>-32.131543</td>\n",
       "      <td>8.173021</td>\n",
       "      <td>2.038769</td>\n",
       "      <td>2.387323</td>\n",
       "      <td>3.215623</td>\n",
       "      <td>0.288633</td>\n",
       "      <td>3.701821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004524</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848.200012</td>\n",
       "      <td>2024-11-29 21:00:00+00:00</td>\n",
       "      <td>2024-11-29 22:00:00+00:00</td>\n",
       "      <td>-30.659681</td>\n",
       "      <td>8.780246</td>\n",
       "      <td>1.967827</td>\n",
       "      <td>1.620036</td>\n",
       "      <td>2.482432</td>\n",
       "      <td>0.516816</td>\n",
       "      <td>3.950176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081036</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>836.049988</td>\n",
       "      <td>2024-11-29 20:00:00+00:00</td>\n",
       "      <td>2024-11-29 21:00:00+00:00</td>\n",
       "      <td>-29.321284</td>\n",
       "      <td>9.297498</td>\n",
       "      <td>1.494915</td>\n",
       "      <td>1.490229</td>\n",
       "      <td>2.968878</td>\n",
       "      <td>1.071656</td>\n",
       "      <td>3.674438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073105</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>894.219971</td>\n",
       "      <td>2024-11-29 19:00:00+00:00</td>\n",
       "      <td>2024-11-29 20:00:00+00:00</td>\n",
       "      <td>-27.818541</td>\n",
       "      <td>9.207599</td>\n",
       "      <td>0.853380</td>\n",
       "      <td>2.309477</td>\n",
       "      <td>2.890789</td>\n",
       "      <td>0.990981</td>\n",
       "      <td>2.872615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040381</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SpotPrice                       from                         to  \\\n",
       "0  596.570007  2024-11-29 23:00:00+00:00  2024-11-30 00:00:00+00:00   \n",
       "1  770.270020  2024-11-29 22:00:00+00:00  2024-11-29 23:00:00+00:00   \n",
       "2  848.200012  2024-11-29 21:00:00+00:00  2024-11-29 22:00:00+00:00   \n",
       "3  836.049988  2024-11-29 20:00:00+00:00  2024-11-29 21:00:00+00:00   \n",
       "4  894.219971  2024-11-29 19:00:00+00:00  2024-11-29 20:00:00+00:00   \n",
       "\n",
       "   temp_pca_1  temp_pca_2  temp_pca_3  wind_speed_pca_1  wind_speed_pca_2  \\\n",
       "0  -33.480249    7.339981    1.718044          3.248249          2.159318   \n",
       "1  -32.131543    8.173021    2.038769          2.387323          3.215623   \n",
       "2  -30.659681    8.780246    1.967827          1.620036          2.482432   \n",
       "3  -29.321284    9.297498    1.494915          1.490229          2.968878   \n",
       "4  -27.818541    9.207599    0.853380          2.309477          2.890789   \n",
       "\n",
       "   wind_speed_pca_3  wind_speed_pca_4  ...  mean_wind_dir_pca_39  hour_sin  \\\n",
       "0          0.612078          3.505092  ...             -0.093112 -0.258819   \n",
       "1          0.288633          3.701821  ...             -0.004524 -0.500000   \n",
       "2          0.516816          3.950176  ...             -0.081036 -0.707107   \n",
       "3          1.071656          3.674438  ...             -0.073105 -0.866025   \n",
       "4          0.990981          2.872615  ...             -0.040381 -0.965926   \n",
       "\n",
       "   hour_cos   day_sin   day_cos  month_sin  month_cos  oil_price  gas_price  \\\n",
       "0  0.965926 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "1  0.866025 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "2  0.707107 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "3  0.500000 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "4  0.258819 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "\n",
       "   constant  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62280, 68)\n"
     ]
    }
   ],
   "source": [
    "# path to the CSV file\n",
    "path = '../../data/fulldata.csv'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "display(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpotPrice</th>\n",
       "      <th>from</th>\n",
       "      <th>temp_pca_1</th>\n",
       "      <th>temp_pca_2</th>\n",
       "      <th>temp_pca_3</th>\n",
       "      <th>wind_speed_pca_1</th>\n",
       "      <th>wind_speed_pca_2</th>\n",
       "      <th>wind_speed_pca_3</th>\n",
       "      <th>wind_speed_pca_4</th>\n",
       "      <th>wind_speed_pca_5</th>\n",
       "      <th>...</th>\n",
       "      <th>price_lag_-4</th>\n",
       "      <th>price_lag_-5</th>\n",
       "      <th>price_lag_-6</th>\n",
       "      <th>price_lag_-24</th>\n",
       "      <th>oil_price_-24</th>\n",
       "      <th>gas_price_-24</th>\n",
       "      <th>oil_price_-48</th>\n",
       "      <th>gas_price_-48</th>\n",
       "      <th>oil_price_-72</th>\n",
       "      <th>gas_price_-72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.019997</td>\n",
       "      <td>2017-10-27 00:00:00+00:00</td>\n",
       "      <td>11.237675</td>\n",
       "      <td>0.831761</td>\n",
       "      <td>0.323180</td>\n",
       "      <td>6.760909</td>\n",
       "      <td>2.790222</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>3.612175</td>\n",
       "      <td>4.192237</td>\n",
       "      <td>...</td>\n",
       "      <td>210.059998</td>\n",
       "      <td>219.059998</td>\n",
       "      <td>222.639999</td>\n",
       "      <td>95.199997</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.349998</td>\n",
       "      <td>2017-10-27 01:00:00+00:00</td>\n",
       "      <td>11.377424</td>\n",
       "      <td>0.873795</td>\n",
       "      <td>0.021477</td>\n",
       "      <td>5.367659</td>\n",
       "      <td>1.404028</td>\n",
       "      <td>0.596286</td>\n",
       "      <td>4.109275</td>\n",
       "      <td>3.550561</td>\n",
       "      <td>...</td>\n",
       "      <td>201.720001</td>\n",
       "      <td>210.059998</td>\n",
       "      <td>219.059998</td>\n",
       "      <td>104.129997</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141.729996</td>\n",
       "      <td>2017-10-27 02:00:00+00:00</td>\n",
       "      <td>11.360804</td>\n",
       "      <td>0.662414</td>\n",
       "      <td>-0.153373</td>\n",
       "      <td>4.258495</td>\n",
       "      <td>1.098352</td>\n",
       "      <td>-0.898239</td>\n",
       "      <td>4.812269</td>\n",
       "      <td>2.074639</td>\n",
       "      <td>...</td>\n",
       "      <td>194.720001</td>\n",
       "      <td>201.720001</td>\n",
       "      <td>210.059998</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178.720001</td>\n",
       "      <td>2017-10-27 03:00:00+00:00</td>\n",
       "      <td>11.961742</td>\n",
       "      <td>0.604866</td>\n",
       "      <td>-0.202105</td>\n",
       "      <td>3.781656</td>\n",
       "      <td>0.551939</td>\n",
       "      <td>-0.444115</td>\n",
       "      <td>4.825875</td>\n",
       "      <td>1.811022</td>\n",
       "      <td>...</td>\n",
       "      <td>186.460007</td>\n",
       "      <td>194.720001</td>\n",
       "      <td>201.720001</td>\n",
       "      <td>196.139999</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>238.199997</td>\n",
       "      <td>2017-10-27 04:00:00+00:00</td>\n",
       "      <td>12.162359</td>\n",
       "      <td>0.136666</td>\n",
       "      <td>-0.113291</td>\n",
       "      <td>3.029801</td>\n",
       "      <td>1.184454</td>\n",
       "      <td>-0.552593</td>\n",
       "      <td>5.198467</td>\n",
       "      <td>2.016204</td>\n",
       "      <td>...</td>\n",
       "      <td>185.720001</td>\n",
       "      <td>186.460007</td>\n",
       "      <td>194.720001</td>\n",
       "      <td>258.070007</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SpotPrice                      from  temp_pca_1  temp_pca_2  temp_pca_3  \\\n",
       "0   96.019997 2017-10-27 00:00:00+00:00   11.237675    0.831761    0.323180   \n",
       "1   95.349998 2017-10-27 01:00:00+00:00   11.377424    0.873795    0.021477   \n",
       "2  141.729996 2017-10-27 02:00:00+00:00   11.360804    0.662414   -0.153373   \n",
       "3  178.720001 2017-10-27 03:00:00+00:00   11.961742    0.604866   -0.202105   \n",
       "4  238.199997 2017-10-27 04:00:00+00:00   12.162359    0.136666   -0.113291   \n",
       "\n",
       "   wind_speed_pca_1  wind_speed_pca_2  wind_speed_pca_3  wind_speed_pca_4  \\\n",
       "0          6.760909          2.790222          0.398300          3.612175   \n",
       "1          5.367659          1.404028          0.596286          4.109275   \n",
       "2          4.258495          1.098352         -0.898239          4.812269   \n",
       "3          3.781656          0.551939         -0.444115          4.825875   \n",
       "4          3.029801          1.184454         -0.552593          5.198467   \n",
       "\n",
       "   wind_speed_pca_5  ...  price_lag_-4  price_lag_-5  price_lag_-6  \\\n",
       "0          4.192237  ...    210.059998    219.059998    222.639999   \n",
       "1          3.550561  ...    201.720001    210.059998    219.059998   \n",
       "2          2.074639  ...    194.720001    201.720001    210.059998   \n",
       "3          1.811022  ...    186.460007    194.720001    201.720001   \n",
       "4          2.016204  ...    185.720001    186.460007    194.720001   \n",
       "\n",
       "   price_lag_-24  oil_price_-24  gas_price_-24  oil_price_-48  gas_price_-48  \\\n",
       "0      95.199997      58.439999      18.110001      58.330002      17.959999   \n",
       "1     104.129997      58.439999      18.110001      58.330002      17.959999   \n",
       "2     126.760002      58.439999      18.110001      58.330002      17.959999   \n",
       "3     196.139999      58.439999      18.110001      58.330002      17.959999   \n",
       "4     258.070007      58.439999      18.110001      58.330002      17.959999   \n",
       "\n",
       "   oil_price_-72  gas_price_-72  \n",
       "0      57.369999          18.09  \n",
       "1      57.369999          18.09  \n",
       "2      57.369999          18.09  \n",
       "3      57.369999          18.09  \n",
       "4      57.369999          18.09  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62184, 81)\n"
     ]
    }
   ],
   "source": [
    "data['from'] = pd.to_datetime(data['from'])\n",
    "\n",
    "# drop to column\n",
    "data = data.drop(columns=['to'])\n",
    "\n",
    "# explicitly including lagged prices as well\n",
    "lag_hours = [0, \n",
    "            -1, -2, -3, -4, -5, -6, -24, #-48, -72, -96, -120, -144, -168\n",
    "             ]\n",
    "for lag in lag_hours:\n",
    "    data[f'price_lag_{lag}'] = data['SpotPrice'].shift(lag)\n",
    "\n",
    "lag_oil_gas = [-24, -48, -72, # -168\n",
    "               ]\n",
    "for lag in lag_oil_gas:\n",
    "    data[f'oil_price_{lag}'] = data['oil_price'].shift(lag)\n",
    "    data[f'gas_price_{lag}'] = data['gas_price'].shift(lag)\n",
    "\n",
    "# offset price by 1 day\n",
    "data['SpotPrice'] = data['SpotPrice'].shift(24)\n",
    "data['from'] = data['from'].shift(24)\n",
    "\n",
    "time_features = ['hour', 'day', 'month']\n",
    "for i in time_features:\n",
    "    data[f'{i}_sin'] = data[f'{i}_sin'].shift(24)\n",
    "    data[f'{i}_cos'] = data[f'{i}_cos'].shift(24)\n",
    "\n",
    "# drop the first 24 rows\n",
    "data = data.dropna()\n",
    "\n",
    "# sort data to be ascending\n",
    "data = data.sort_values('from')\n",
    "\n",
    "# reset index\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "display(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of features before interaction terms: 79\n",
      "Target variable: ['SpotPrice']\n"
     ]
    }
   ],
   "source": [
    "# extract column names\n",
    "cols = data.columns.tolist()\n",
    "\n",
    "# select features and target variable\n",
    "all_features = cols[2:]\n",
    "target = cols[:1]\n",
    "\n",
    "print(f'Count of features before interaction terms: {len(all_features)}')\n",
    "print(f'Target variable: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data: until July 2023\n",
    "train_data = data[data['from'] < '2023-08-01']\n",
    "\n",
    "# validation data: July 2023 to December 2023\n",
    "val_data = data[(data['from'] >= '2023-08-01') & (data['from'] < '2024-08-01')]\n",
    "\n",
    "# Test data: Aug 2024 and beyond \n",
    "test_data = data[data['from'] >= '2024-07-31'] # initialized 24 hours before to get the first 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[all_features].values\n",
    "X_val = val_data[all_features].values\n",
    "X_test = test_data[all_features].values\n",
    "\n",
    "# initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler on the training features and transform\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# transform the validation and test features using the same scaler\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract target values\n",
    "train_targets = train_data[target].values\n",
    "val_targets = val_data[target].values\n",
    "test_targets = test_data[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "torch.manual_seed(2024)\n",
    "np.random.seed(2024)\n",
    "\n",
    "# hyperparameters\n",
    "seq_length = 24  # Use past 24 hours to form a sequence\n",
    "batch_size = 256\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "# update the array to load all models\n",
    "lambda_l1_array = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "lambda_l2_array = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "hidden_dim_array = [128, 256, 512]\n",
    "layer_dim_array = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "train_dataset = LSTMdataset(X_train, train_targets, seq_length)\n",
    "val_dataset = LSTMdataset(X_val, val_targets, seq_length)\n",
    "test_dataset = LSTMdataset(X_test, test_targets, seq_length)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# loss evaluation function\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the model\n",
    "# num_epochs = 100\n",
    "# patience = 10  # for early stopping\n",
    "# best_loss_global = np.inf\n",
    "\n",
    "# for hidden_dim in hidden_dim_array:\n",
    "#     for layer_dim in layer_dim_array:\n",
    "#         for lambda_l1 in lambda_l1_array:\n",
    "#             for lambda_l2 in lambda_l2_array:\n",
    "#                 torch.manual_seed(2024)\n",
    "#                 np.random.seed(2024)\n",
    "#                 model = LSTMmodel(input_dim, hidden_dim, layer_dim, output_dim).to(device)\n",
    "#                 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#                 # set seed for reproducibility\n",
    "#                 best_loss = np.inf\n",
    "#                 counter = 0\n",
    "\n",
    "#                 # initialize lists to store loss values\n",
    "#                 training_losses = []\n",
    "#                 validation_losses = []\n",
    "\n",
    "#                 for epoch in range(num_epochs):\n",
    "#                     model.train()\n",
    "#                     train_loss = 0\n",
    "#                     for X_batch, y_batch in train_loader:\n",
    "#                         X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#                         optimizer.zero_grad()\n",
    "\n",
    "#                         # forward pass\n",
    "#                         outputs = model(X_batch)\n",
    "\n",
    "#                         mse_loss = criterion(outputs.squeeze(), y_batch.squeeze())\n",
    "\n",
    "#                         # L1 regularization\n",
    "#                         l1_loss = l1_regularization(model, lambda_l1)\n",
    "#                         l2_loss = l2_regularization(model, lambda_l2)\n",
    "\n",
    "#                         # calc total loss\n",
    "#                         loss = mse_loss + l1_loss + l2_loss\n",
    "\n",
    "#                         # backward pass and optimization\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "\n",
    "#                         train_loss += loss.item()\n",
    "\n",
    "\n",
    "#                     # average training loss\n",
    "#                     avg_train_loss = train_loss / len(train_loader)\n",
    "#                     training_losses.append(avg_train_loss)\n",
    "\n",
    "#                     # validation\n",
    "#                     model.eval()\n",
    "#                     val_losses = []\n",
    "#                     with torch.no_grad():\n",
    "#                         for X_batch, y_batch in val_loader:\n",
    "#                             X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#                             outputs = model(X_batch)\n",
    "#                             mse_loss = criterion(outputs.squeeze(), y_batch.squeeze())\n",
    "#                             loss = mse_loss\n",
    "#                             val_losses.append(loss.item())\n",
    "\n",
    "#                     avg_val_loss = np.mean(val_losses)\n",
    "#                     validation_losses.append(avg_val_loss)\n",
    "#                     if (epoch + 1) % 10 == 0:\n",
    "#                         print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "#                     # torch.save(model.state_dict(), 'output/nn-paths/last_model.pth')\n",
    "                    \n",
    "#                     # early stopping\n",
    "#                     if avg_val_loss < best_loss:\n",
    "#                         best_loss = avg_val_loss\n",
    "#                         counter = 0\n",
    "#                         # save the best model\n",
    "#                         torch.save(model.state_dict(), f'output/nn-paths/best_model_{layer_dim}_{hidden_dim}_{int(np.abs(np.log10(lambda_l1)))}_{int(np.abs(np.log10(lambda_l2)))}.pth')\n",
    "#                     else:\n",
    "#                         counter += 1\n",
    "#                         if counter >= patience:\n",
    "#                             print(f\"Early stopping after {epoch} epochs. Best validation loss: {best_loss:.4f}\")\n",
    "#                             break\n",
    "                    \n",
    "#                     if epoch == (num_epochs - 1):\n",
    "#                         print(f\"Training stopped after {epoch} epochs. Best validation loss: {best_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating all models in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden dim:  128, Layer dim: 2,  L1:    0.1,  L2:  0.1,    Validation Loss:     81444.3724\n",
      "RMSE: 365.5452, MAE: 278.4396\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.1,  L2:  0.01,    Validation Loss:     77399.2890\n",
      "RMSE: 369.0497, MAE: 280.5470\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.1,  L2:  0.001,    Validation Loss:     72896.4416\n",
      "RMSE: 358.6684, MAE: 274.9196\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.1,  L2:  0.0001,    Validation Loss:     80378.5820\n",
      "RMSE: 372.9278, MAE: 288.5375\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.1,  L2:  1e-05,    Validation Loss:     79988.5750\n",
      "RMSE: 358.8839, MAE: 270.3241\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.01,  L2:  0.1,    Validation Loss:     82258.0099\n",
      "RMSE: 358.3621, MAE: 271.6883\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.01,  L2:  0.01,    Validation Loss:     80376.9750\n",
      "RMSE: 369.5752, MAE: 278.8642\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.01,  L2:  0.001,    Validation Loss:     81129.4104\n",
      "RMSE: 356.3283, MAE: 269.8279\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.01,  L2:  0.0001,    Validation Loss:     80541.0055\n",
      "RMSE: 350.3617, MAE: 268.4735\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.01,  L2:  1e-05,    Validation Loss:     82340.9874\n",
      "RMSE: 372.0551, MAE: 283.0481\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.001,  L2:  0.1,    Validation Loss:     79044.0120\n",
      "RMSE: 365.0031, MAE: 274.7946\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.001,  L2:  0.01,    Validation Loss:     74305.7698\n",
      "RMSE: 354.5715, MAE: 269.7069\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.001,  L2:  0.001,    Validation Loss:     77036.7050\n",
      "RMSE: 356.3491, MAE: 272.0420\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.001,  L2:  0.0001,    Validation Loss:     78629.0976\n",
      "RMSE: 373.1940, MAE: 280.0496\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.001,  L2:  1e-05,    Validation Loss:     79511.2698\n",
      "RMSE: 355.9616, MAE: 273.6997\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.0001,  L2:  0.1,    Validation Loss:     77482.0165\n",
      "RMSE: 363.3860, MAE: 278.5939\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.0001,  L2:  0.01,    Validation Loss:     78067.3186\n",
      "RMSE: 372.7256, MAE: 284.7359\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.0001,  L2:  0.001,    Validation Loss:     76987.3795\n",
      "RMSE: 361.9315, MAE: 273.7368\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.0001,  L2:  0.0001,    Validation Loss:     73133.8977\n",
      "RMSE: 349.8129, MAE: 268.8156\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    0.0001,  L2:  1e-05,    Validation Loss:     77789.3145\n",
      "RMSE: 352.5907, MAE: 265.7636\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    1e-05,  L2:  0.1,    Validation Loss:     79277.2127\n",
      "RMSE: 354.6523, MAE: 268.7787\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    1e-05,  L2:  0.01,    Validation Loss:     82185.9058\n",
      "RMSE: 356.8558, MAE: 272.7788\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    1e-05,  L2:  0.001,    Validation Loss:     77781.0998\n",
      "RMSE: 360.9349, MAE: 275.1975\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    1e-05,  L2:  0.0001,    Validation Loss:     77232.1754\n",
      "RMSE: 357.9366, MAE: 273.7433\n",
      "Hidden dim:  128, Layer dim: 2,  L1:    1e-05,  L2:  1e-05,    Validation Loss:     80281.7565\n",
      "RMSE: 355.5398, MAE: 270.3518\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.1,  L2:  0.1,    Validation Loss:     101738.1807\n",
      "RMSE: 397.1070, MAE: 308.3395\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.1,  L2:  0.01,    Validation Loss:     101738.5974\n",
      "RMSE: 397.0791, MAE: 308.3063\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.1,  L2:  0.001,    Validation Loss:     101738.6396\n",
      "RMSE: 397.0763, MAE: 308.3030\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.1,  L2:  0.0001,    Validation Loss:     101738.6473\n",
      "RMSE: 397.0760, MAE: 308.3026\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.1,  L2:  1e-05,    Validation Loss:     101738.6479\n",
      "RMSE: 397.0759, MAE: 308.3026\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.01,  L2:  0.1,    Validation Loss:     101737.9414\n",
      "RMSE: 397.1248, MAE: 308.3606\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.01,  L2:  0.01,    Validation Loss:     79374.7412\n",
      "RMSE: 350.7414, MAE: 268.4383\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.01,  L2:  0.001,    Validation Loss:     76013.2860\n",
      "RMSE: 356.9259, MAE: 271.6054\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.01,  L2:  0.0001,    Validation Loss:     82494.2605\n",
      "RMSE: 366.3120, MAE: 279.2824\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.01,  L2:  1e-05,    Validation Loss:     81967.9281\n",
      "RMSE: 350.3406, MAE: 268.6927\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.001,  L2:  0.1,    Validation Loss:     81051.4164\n",
      "RMSE: 356.9504, MAE: 270.6131\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.001,  L2:  0.01,    Validation Loss:     80950.5228\n",
      "RMSE: 363.5260, MAE: 279.5040\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.001,  L2:  0.001,    Validation Loss:     76017.7007\n",
      "RMSE: 365.3875, MAE: 277.3784\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.001,  L2:  0.0001,    Validation Loss:     77125.8290\n",
      "RMSE: 355.1842, MAE: 265.9735\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.001,  L2:  1e-05,    Validation Loss:     76731.3747\n",
      "RMSE: 363.2345, MAE: 275.1608\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.0001,  L2:  0.1,    Validation Loss:     75846.9958\n",
      "RMSE: 372.5114, MAE: 283.9581\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.0001,  L2:  0.01,    Validation Loss:     78912.4862\n",
      "RMSE: 363.4354, MAE: 274.0179\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.0001,  L2:  0.001,    Validation Loss:     73617.6773\n",
      "RMSE: 359.8407, MAE: 270.9088\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.0001,  L2:  0.0001,    Validation Loss:     78270.4413\n",
      "RMSE: 351.6494, MAE: 264.7206\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    0.0001,  L2:  1e-05,    Validation Loss:     76617.9901\n",
      "RMSE: 361.6098, MAE: 274.8852\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    1e-05,  L2:  0.1,    Validation Loss:     74857.3606\n",
      "RMSE: 348.7152, MAE: 267.6359\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    1e-05,  L2:  0.01,    Validation Loss:     76331.7272\n",
      "RMSE: 360.4013, MAE: 272.9633\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    1e-05,  L2:  0.001,    Validation Loss:     78888.3626\n",
      "RMSE: 357.9335, MAE: 268.8754\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    1e-05,  L2:  0.0001,    Validation Loss:     73348.6648\n",
      "RMSE: 348.2182, MAE: 263.4730\n",
      "Hidden dim:  128, Layer dim: 3,  L1:    1e-05,  L2:  1e-05,    Validation Loss:     76310.6208\n",
      "RMSE: 357.3133, MAE: 268.5396\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.1,  L2:  0.1,    Validation Loss:     77622.9924\n",
      "RMSE: 344.1562, MAE: 262.1487\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.1,  L2:  0.01,    Validation Loss:     77303.8584\n",
      "RMSE: 349.3148, MAE: 263.5581\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.1,  L2:  0.001,    Validation Loss:     80715.6045\n",
      "RMSE: 355.9651, MAE: 269.9920\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.1,  L2:  0.0001,    Validation Loss:     74814.6020\n",
      "RMSE: 357.7968, MAE: 274.0679\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.1,  L2:  1e-05,    Validation Loss:     74613.0492\n",
      "RMSE: 354.5755, MAE: 271.0325\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.01,  L2:  0.1,    Validation Loss:     73258.0644\n",
      "RMSE: 343.6433, MAE: 262.3329\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.01,  L2:  0.01,    Validation Loss:     77183.5318\n",
      "RMSE: 361.7771, MAE: 275.2752\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.01,  L2:  0.001,    Validation Loss:     75527.4948\n",
      "RMSE: 348.5686, MAE: 266.1539\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.01,  L2:  0.0001,    Validation Loss:     77232.8224\n",
      "RMSE: 365.2243, MAE: 278.9388\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.01,  L2:  1e-05,    Validation Loss:     76029.9561\n",
      "RMSE: 367.2852, MAE: 276.2856\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.001,  L2:  0.1,    Validation Loss:     72825.5492\n",
      "RMSE: 354.7986, MAE: 271.9027\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.001,  L2:  0.01,    Validation Loss:     75344.9480\n",
      "RMSE: 348.3410, MAE: 264.8826\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.001,  L2:  0.001,    Validation Loss:     74134.2818\n",
      "RMSE: 355.1904, MAE: 271.8117\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.001,  L2:  0.0001,    Validation Loss:     75372.5410\n",
      "RMSE: 349.9407, MAE: 266.2254\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.001,  L2:  1e-05,    Validation Loss:     75032.1378\n",
      "RMSE: 350.7764, MAE: 265.8291\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.0001,  L2:  0.1,    Validation Loss:     72315.0473\n",
      "RMSE: 347.0074, MAE: 263.4895\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.0001,  L2:  0.01,    Validation Loss:     75548.0772\n",
      "RMSE: 344.5599, MAE: 263.9644\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.0001,  L2:  0.001,    Validation Loss:     74632.8743\n",
      "RMSE: 343.9976, MAE: 265.7617\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.0001,  L2:  0.0001,    Validation Loss:     76012.5253\n",
      "RMSE: 352.3293, MAE: 262.9980\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    0.0001,  L2:  1e-05,    Validation Loss:     75917.5680\n",
      "RMSE: 350.9903, MAE: 264.8198\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    1e-05,  L2:  0.1,    Validation Loss:     76434.8286\n",
      "RMSE: 346.2718, MAE: 265.3421\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    1e-05,  L2:  0.01,    Validation Loss:     76128.0492\n",
      "RMSE: 354.1948, MAE: 267.0624\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    1e-05,  L2:  0.001,    Validation Loss:     72785.0868\n",
      "RMSE: 347.1666, MAE: 259.5893\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    1e-05,  L2:  0.0001,    Validation Loss:     76814.2079\n",
      "RMSE: 356.6977, MAE: 275.8632\n",
      "Hidden dim:  256, Layer dim: 2,  L1:    1e-05,  L2:  1e-05,    Validation Loss:     73312.9610\n",
      "RMSE: 345.2787, MAE: 260.1275\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.1,  L2:  0.1,    Validation Loss:     101738.1525\n",
      "RMSE: 397.1091, MAE: 308.3419\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.1,  L2:  0.01,    Validation Loss:     101738.4323\n",
      "RMSE: 397.0898, MAE: 308.3190\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.1,  L2:  0.001,    Validation Loss:     101738.4875\n",
      "RMSE: 397.0862, MAE: 308.3148\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.1,  L2:  0.0001,    Validation Loss:     76544.6424\n",
      "RMSE: 348.0581, MAE: 257.9451\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.1,  L2:  1e-05,    Validation Loss:     101738.5731\n",
      "RMSE: 397.0806, MAE: 308.3082\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.01,  L2:  0.1,    Validation Loss:     67472.8161\n",
      "RMSE: 340.7349, MAE: 257.8053\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.01,  L2:  0.01,    Validation Loss:     76134.6472\n",
      "RMSE: 342.8614, MAE: 259.6757\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.01,  L2:  0.001,    Validation Loss:     71253.5223\n",
      "RMSE: 348.2910, MAE: 264.7201\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.01,  L2:  0.0001,    Validation Loss:     73324.6147\n",
      "RMSE: 351.0097, MAE: 267.8091\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.01,  L2:  1e-05,    Validation Loss:     69099.1056\n",
      "RMSE: 345.3438, MAE: 263.7085\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.001,  L2:  0.1,    Validation Loss:     71642.8825\n",
      "RMSE: 341.7725, MAE: 259.2563\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.001,  L2:  0.01,    Validation Loss:     77757.1551\n",
      "RMSE: 348.1249, MAE: 264.8520\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.001,  L2:  0.001,    Validation Loss:     69763.9152\n",
      "RMSE: 344.5032, MAE: 264.4816\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.001,  L2:  0.0001,    Validation Loss:     75218.6173\n",
      "RMSE: 349.1985, MAE: 268.2225\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.001,  L2:  1e-05,    Validation Loss:     72721.2764\n",
      "RMSE: 348.4670, MAE: 263.6712\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.0001,  L2:  0.1,    Validation Loss:     71629.3708\n",
      "RMSE: 355.7845, MAE: 268.3095\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.0001,  L2:  0.01,    Validation Loss:     72844.4585\n",
      "RMSE: 339.8262, MAE: 258.0711\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.0001,  L2:  0.001,    Validation Loss:     75507.0169\n",
      "RMSE: 356.7902, MAE: 271.9405\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.0001,  L2:  0.0001,    Validation Loss:     72268.0804\n",
      "RMSE: 335.6230, MAE: 250.0249\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    0.0001,  L2:  1e-05,    Validation Loss:     79051.9738\n",
      "RMSE: 346.6062, MAE: 262.7506\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    1e-05,  L2:  0.1,    Validation Loss:     76961.2735\n",
      "RMSE: 354.6481, MAE: 275.3497\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    1e-05,  L2:  0.01,    Validation Loss:     71758.7535\n",
      "RMSE: 359.3159, MAE: 277.0490\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    1e-05,  L2:  0.001,    Validation Loss:     74255.6374\n",
      "RMSE: 344.2040, MAE: 255.4875\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    1e-05,  L2:  0.0001,    Validation Loss:     72719.6427\n",
      "RMSE: 351.6789, MAE: 268.3051\n",
      "Hidden dim:  256, Layer dim: 3,  L1:    1e-05,  L2:  1e-05,    Validation Loss:     74735.6525\n",
      "RMSE: 355.6707, MAE: 266.2295\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.1,  L2:  0.1,    Validation Loss:     70237.0743\n",
      "RMSE: 338.9777, MAE: 260.3147\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.1,  L2:  0.01,    Validation Loss:     70724.8307\n",
      "RMSE: 340.9507, MAE: 256.2469\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.1,  L2:  0.001,    Validation Loss:     68017.0533\n",
      "RMSE: 336.9614, MAE: 257.3013\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.1,  L2:  0.0001,    Validation Loss:     65450.1864\n",
      "RMSE: 324.0369, MAE: 249.2722\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.1,  L2:  1e-05,    Validation Loss:     74113.1555\n",
      "RMSE: 349.7734, MAE: 269.9904\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.01,  L2:  0.1,    Validation Loss:     74679.8120\n",
      "RMSE: 341.7157, MAE: 260.1591\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.01,  L2:  0.01,    Validation Loss:     68506.7801\n",
      "RMSE: 341.9121, MAE: 256.5657\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.01,  L2:  0.001,    Validation Loss:     70870.0201\n",
      "RMSE: 333.8487, MAE: 255.3798\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.01,  L2:  0.0001,    Validation Loss:     68189.2845\n",
      "RMSE: 340.2821, MAE: 260.1509\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.01,  L2:  1e-05,    Validation Loss:     75120.3825\n",
      "RMSE: 360.8244, MAE: 269.5978\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.001,  L2:  0.1,    Validation Loss:     71715.7024\n",
      "RMSE: 347.9971, MAE: 265.0511\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.001,  L2:  0.01,    Validation Loss:     68647.8088\n",
      "RMSE: 330.0593, MAE: 252.1092\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.001,  L2:  0.001,    Validation Loss:     68066.3654\n",
      "RMSE: 343.9955, MAE: 259.1480\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.001,  L2:  0.0001,    Validation Loss:     66932.6997\n",
      "RMSE: 341.0124, MAE: 260.0303\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.001,  L2:  1e-05,    Validation Loss:     69583.1644\n",
      "RMSE: 330.5352, MAE: 247.3250\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.0001,  L2:  0.1,    Validation Loss:     68126.7177\n",
      "RMSE: 334.3689, MAE: 256.2382\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.0001,  L2:  0.01,    Validation Loss:     67609.3756\n",
      "RMSE: 338.0536, MAE: 259.3974\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.0001,  L2:  0.001,    Validation Loss:     66756.0036\n",
      "RMSE: 337.0394, MAE: 255.9608\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.0001,  L2:  0.0001,    Validation Loss:     68490.0741\n",
      "RMSE: 338.8720, MAE: 256.3944\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    0.0001,  L2:  1e-05,    Validation Loss:     69367.6442\n",
      "RMSE: 346.8448, MAE: 262.1241\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    1e-05,  L2:  0.1,    Validation Loss:     69400.3754\n",
      "RMSE: 346.3238, MAE: 259.8589\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    1e-05,  L2:  0.01,    Validation Loss:     66848.4565\n",
      "RMSE: 333.8206, MAE: 248.0939\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    1e-05,  L2:  0.001,    Validation Loss:     71634.4976\n",
      "RMSE: 346.0162, MAE: 265.8197\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    1e-05,  L2:  0.0001,    Validation Loss:     70348.2035\n",
      "RMSE: 335.0336, MAE: 254.9638\n",
      "Hidden dim:  512, Layer dim: 2,  L1:    1e-05,  L2:  1e-05,    Validation Loss:     101946.1096\n",
      "RMSE: 394.8530, MAE: 305.4702\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.1,  L2:  0.1,    Validation Loss:     69125.7954\n",
      "RMSE: 335.3145, MAE: 254.0022\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.1,  L2:  0.01,    Validation Loss:     68354.6593\n",
      "RMSE: 345.1687, MAE: 271.2837\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.1,  L2:  0.001,    Validation Loss:     67169.6975\n",
      "RMSE: 337.5741, MAE: 250.9242\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.1,  L2:  0.0001,    Validation Loss:     101828.0358\n",
      "RMSE: 399.2906, MAE: 310.8168\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.1,  L2:  1e-05,    Validation Loss:     67376.1069\n",
      "RMSE: 336.7145, MAE: 249.0176\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.01,  L2:  0.1,    Validation Loss:     72096.2160\n",
      "RMSE: 343.1390, MAE: 263.6855\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.01,  L2:  0.01,    Validation Loss:     69563.1855\n",
      "RMSE: 338.7818, MAE: 253.2263\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.01,  L2:  0.001,    Validation Loss:     69816.3751\n",
      "RMSE: 335.4352, MAE: 255.3727\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.01,  L2:  0.0001,    Validation Loss:     72529.1099\n",
      "RMSE: 345.0842, MAE: 263.6685\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.01,  L2:  1e-05,    Validation Loss:     70590.9506\n",
      "RMSE: 337.0503, MAE: 258.1724\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.001,  L2:  0.1,    Validation Loss:     70026.9292\n",
      "RMSE: 348.8211, MAE: 263.2334\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.001,  L2:  0.01,    Validation Loss:     72025.1033\n",
      "RMSE: 349.7712, MAE: 266.2712\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.001,  L2:  0.001,    Validation Loss:     112683.5879\n",
      "RMSE: 429.7491, MAE: 338.6295\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.001,  L2:  0.0001,    Validation Loss:     73002.9271\n",
      "RMSE: 345.2700, MAE: 270.4774\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.001,  L2:  1e-05,    Validation Loss:     67602.2583\n",
      "RMSE: 336.0084, MAE: 260.6890\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.0001,  L2:  0.1,    Validation Loss:     69856.2075\n",
      "RMSE: 343.1276, MAE: 261.5572\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.0001,  L2:  0.01,    Validation Loss:     70109.2367\n",
      "RMSE: 342.6483, MAE: 263.4999\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.0001,  L2:  0.001,    Validation Loss:     74484.9584\n",
      "RMSE: 359.5212, MAE: 276.6638\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.0001,  L2:  0.0001,    Validation Loss:     73363.0131\n",
      "RMSE: 347.9545, MAE: 270.5091\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    0.0001,  L2:  1e-05,    Validation Loss:     69210.2953\n",
      "RMSE: 341.2506, MAE: 255.4042\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    1e-05,  L2:  0.1,    Validation Loss:     72478.5680\n",
      "RMSE: 340.7026, MAE: 262.0058\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    1e-05,  L2:  0.01,    Validation Loss:     73939.7412\n",
      "RMSE: 349.1162, MAE: 262.4412\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    1e-05,  L2:  0.001,    Validation Loss:     73313.9706\n",
      "RMSE: 337.2804, MAE: 261.1958\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    1e-05,  L2:  0.0001,    Validation Loss:     74412.7923\n",
      "RMSE: 346.7279, MAE: 268.5129\n",
      "Hidden dim:  512, Layer dim: 3,  L1:    1e-05,  L2:  1e-05,    Validation Loss:     73801.5129\n",
      "RMSE: 347.0321, MAE: 260.9538\n",
      "Best: \n",
      " Hidden dim:  512, Layer dim: 2,  L1:    0.1,  L2:  0.0001,    Best Validation Loss:     65450.1864\n",
      "Best RMSE: 324.0369, Best MAE: 249.2722\n",
      "Best model saved as output/nn-paths/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# load in the all the models and print the best validation loss\n",
    "best_val_loss = np.inf\n",
    "for hidden_dim in hidden_dim_array:\n",
    "    for layer_dim in layer_dim_array:\n",
    "        for lambda_l1 in lambda_l1_array:\n",
    "            for lambda_l2 in lambda_l2_array:\n",
    "                model = LSTMmodel(input_dim, hidden_dim, layer_dim, output_dim).to(device)\n",
    "                try:\n",
    "                    model.load_state_dict(torch.load(f'output/nn-paths/best_model_{layer_dim}_{hidden_dim}_{int(np.abs(np.log10(lambda_l1)))}_{int(np.abs(np.log10(lambda_l2)))}.pth'))\n",
    "                except:\n",
    "                    continue\n",
    "                model.eval()\n",
    "                val_losses = []\n",
    "                with torch.no_grad():\n",
    "                    for X_batch, y_batch in val_loader:\n",
    "                        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                        outputs = model(X_batch)\n",
    "                        mse_loss = criterion(outputs.squeeze(), y_batch.squeeze())\n",
    "                        loss = mse_loss\n",
    "                        val_losses.append(loss.item())\n",
    "\n",
    "                avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    best_hidden_dim = hidden_dim\n",
    "                    best_lambda_l1 = lambda_l1\n",
    "                    best_lambda_l2 = lambda_l2\n",
    "                    best_layer_dim = layer_dim\n",
    "                print(f'Hidden dim:  {hidden_dim}, Layer dim: {layer_dim},  L1:    {lambda_l1},  L2:  {lambda_l2},\\nValidation Loss:     {avg_val_loss:.4f}')\n",
    "\n",
    "print(f'Best: \\n Hidden dim:  {best_hidden_dim}, Layer dim: {best_layer_dim},  L1:    {best_lambda_l1},  L2:  {best_lambda_l2},\\nBest Validation Loss:     {best_val_loss:.4f}')\n",
    "\n",
    "# save the best model as best_model.pth\n",
    "model = LSTMmodel(input_dim, best_hidden_dim, best_layer_dim, output_dim).to(device)\n",
    "model.load_state_dict(torch.load(f'output/nn-paths/best_model_{best_layer_dim}_{best_hidden_dim}_{int(np.abs(np.log10(best_lambda_l1)))}_{int(np.abs(np.log10(best_lambda_l2)))}.pth'))\n",
    "torch.save(model.state_dict(), 'output/nn-paths/best_model.pth')\n",
    "print('Best model saved as output/nn-paths/best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-training best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current best hyperparameters\n",
    "opt_hidden_dim = best_hidden_dim #512 # 512 seem to work best 256 can do\n",
    "opt_layer_dim = best_layer_dim #2 dimensions seems to work best\n",
    "opt_lambda_l1 =  best_lambda_l1 # 1e-1 seems to work best\n",
    "opt_lambda_l2 = best_lambda_l2 #1e-4 # 1e-4, 1e-5 and 1e-6 all seem to work well, maybe 1-e6 is best\n",
    "\n",
    "torch.manual_seed(2024)\n",
    "np.random.seed(2024)\n",
    "# initialize the model\n",
    "model = LSTMmodel(input_dim, opt_hidden_dim, opt_layer_dim, output_dim).to(device)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Training Loss: 820204.2926, Validation Loss: 264223.9813\n",
      "Epoch [2/150], Training Loss: 720552.9733, Validation Loss: 199643.7498\n",
      "Epoch [3/150], Training Loss: 647908.3088, Validation Loss: 155791.2917\n",
      "Epoch [4/150], Training Loss: 597923.4184, Validation Loss: 128693.2910\n",
      "Epoch [5/150], Training Loss: 576356.9318, Validation Loss: 178868.0626\n",
      "Epoch [6/150], Training Loss: 571664.0807, Validation Loss: 111391.0458\n",
      "Epoch [7/150], Training Loss: 500836.2825, Validation Loss: 101637.1550\n",
      "Epoch [8/150], Training Loss: 464650.0011, Validation Loss: 95562.7242\n",
      "Epoch [9/150], Training Loss: 429469.2240, Validation Loss: 89579.8041\n",
      "Epoch [10/150], Training Loss: 397481.3644, Validation Loss: 79679.5913\n",
      "Epoch [11/150], Training Loss: 372431.4884, Validation Loss: 88724.4418\n",
      "Epoch [12/150], Training Loss: 349803.7461, Validation Loss: 92122.8112\n",
      "Epoch [13/150], Training Loss: 329407.0987, Validation Loss: 67862.7783\n",
      "Epoch [14/150], Training Loss: 309741.2367, Validation Loss: 68184.1020\n",
      "Epoch [15/150], Training Loss: 289433.6521, Validation Loss: 67063.3530\n",
      "Epoch [16/150], Training Loss: 272348.9472, Validation Loss: 66132.6011\n",
      "Epoch [17/150], Training Loss: 255409.3816, Validation Loss: 68437.2715\n",
      "Epoch [18/150], Training Loss: 239817.8853, Validation Loss: 66461.5617\n",
      "Epoch [19/150], Training Loss: 223741.6189, Validation Loss: 74107.5598\n",
      "Epoch [20/150], Training Loss: 210365.2341, Validation Loss: 69282.8852\n",
      "Epoch [21/150], Training Loss: 195667.7579, Validation Loss: 66067.1870\n",
      "Epoch [22/150], Training Loss: 183867.3695, Validation Loss: 65450.1864\n",
      "Epoch [23/150], Training Loss: 171659.6824, Validation Loss: 67150.0517\n",
      "Epoch [24/150], Training Loss: 160177.4535, Validation Loss: 67128.6607\n",
      "Epoch [25/150], Training Loss: 151017.9117, Validation Loss: 68562.0430\n",
      "Epoch [26/150], Training Loss: 144044.1544, Validation Loss: 70990.1236\n",
      "Epoch [27/150], Training Loss: 132171.5834, Validation Loss: 68346.8968\n",
      "Epoch [28/150], Training Loss: 122897.6608, Validation Loss: 70209.3508\n",
      "Epoch [29/150], Training Loss: 114405.4291, Validation Loss: 71463.3900\n",
      "Epoch [30/150], Training Loss: 107097.2132, Validation Loss: 72216.4821\n",
      "Epoch [31/150], Training Loss: 100719.9621, Validation Loss: 68869.9268\n",
      "Epoch [32/150], Training Loss: 94793.2573, Validation Loss: 69855.7847\n",
      "Epoch [33/150], Training Loss: 97913.1009, Validation Loss: 68407.8914\n",
      "Epoch [34/150], Training Loss: 88437.8581, Validation Loss: 71424.6924\n",
      "Epoch [35/150], Training Loss: 81398.2207, Validation Loss: 72066.4379\n",
      "Epoch [36/150], Training Loss: 75497.3344, Validation Loss: 71394.1753\n",
      "Epoch [37/150], Training Loss: 70467.8765, Validation Loss: 73203.1657\n",
      "Epoch [38/150], Training Loss: 67725.6490, Validation Loss: 70747.8345\n",
      "Epoch [39/150], Training Loss: 64094.8175, Validation Loss: 71086.3960\n",
      "Epoch [40/150], Training Loss: 61037.4858, Validation Loss: 71997.8735\n",
      "Epoch [41/150], Training Loss: 55747.6750, Validation Loss: 72584.4137\n",
      "Epoch [42/150], Training Loss: 52253.7997, Validation Loss: 71535.6110\n",
      "Epoch [43/150], Training Loss: 48979.9198, Validation Loss: 71998.8394\n",
      "Epoch [44/150], Training Loss: 45132.6516, Validation Loss: 73105.5513\n",
      "Epoch [45/150], Training Loss: 42685.3690, Validation Loss: 73328.9576\n",
      "Epoch [46/150], Training Loss: 41497.6880, Validation Loss: 77275.7150\n",
      "Epoch [47/150], Training Loss: 40002.5066, Validation Loss: 74003.6040\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# retraining the model to get the loss-path of the model\n",
    "num_epochs = 150\n",
    "patience = 25  # for early stopping\n",
    "best_loss = np.inf\n",
    "counter = 0\n",
    "\n",
    "# initialize lists to store loss values\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        mse_loss = criterion(outputs.squeeze(), y_batch.squeeze())\n",
    "\n",
    "        # L1 regularization\n",
    "        l1_loss = l1_regularization(model, opt_lambda_l1)\n",
    "        l2_loss = l2_regularization(model, opt_lambda_l2)\n",
    "\n",
    "        # calc total loss\n",
    "        loss = mse_loss + l1_loss + l2_loss\n",
    "\n",
    "        # backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # average training loss\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    training_losses.append(avg_train_loss)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            mse_loss = criterion(outputs.squeeze(), y_batch.squeeze())\n",
    "            loss = mse_loss\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    validation_losses.append(avg_val_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    # early stopping\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        # save the best model\n",
    "        torch.save(model.state_dict(), 'output/nn-paths/best_model.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on test data:\n",
      "RMSE: 324.0369\n",
      "MAE: 249.2722\n"
     ]
    }
   ],
   "source": [
    "# load the best model\n",
    "model = LSTMmodel(input_dim, opt_hidden_dim, opt_layer_dim, output_dim).to(device)\n",
    "model.load_state_dict(torch.load('output/nn-paths/best_model.pth'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        predictions.extend(outputs.squeeze().tolist())\n",
    "\n",
    "        actuals.extend(y_batch.tolist())\n",
    "\n",
    "rmse = root_mean_squared_error(actuals, predictions)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "\n",
    "print(f'Performance on test data:\\nRMSE: {rmse:.4f}\\nMAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = np.array(training_losses)/1000\n",
    "val_losses = np.array(validation_losses)/1000\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', linewidth=3)\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', linewidth=3)\n",
    "plt.xlabel('Epoch', fontsize=26)\n",
    "plt.ylabel('Avg loss (x1,000)', fontsize=26)\n",
    "plt.tick_params(axis='both', which='major', labelsize=24)\n",
    "plt.legend(fontsize=24)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/loss.png')\n",
    "# plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'predictions' and 'actuals' to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "\n",
    "# save the predicted vaules\n",
    "np.save('output/forecast/forecast_lstm.npy', predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
