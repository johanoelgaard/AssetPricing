{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI model for predicting the electricity prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from LSTMmodel import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# moving to GPU if available (Metal)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpotPriceDKK</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>temp_pca_1</th>\n",
       "      <th>temp_pca_2</th>\n",
       "      <th>temp_pca_3</th>\n",
       "      <th>wind_speed_pca_1</th>\n",
       "      <th>wind_speed_pca_2</th>\n",
       "      <th>wind_speed_pca_3</th>\n",
       "      <th>wind_speed_pca_4</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_wind_dir_pca_39</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>gas_price</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596.570007</td>\n",
       "      <td>2024-11-29 23:00:00+00:00</td>\n",
       "      <td>2024-11-30 00:00:00+00:00</td>\n",
       "      <td>-33.480249</td>\n",
       "      <td>7.339981</td>\n",
       "      <td>1.718044</td>\n",
       "      <td>3.248249</td>\n",
       "      <td>2.159318</td>\n",
       "      <td>0.612078</td>\n",
       "      <td>3.505092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093112</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770.270020</td>\n",
       "      <td>2024-11-29 22:00:00+00:00</td>\n",
       "      <td>2024-11-29 23:00:00+00:00</td>\n",
       "      <td>-32.131543</td>\n",
       "      <td>8.173021</td>\n",
       "      <td>2.038769</td>\n",
       "      <td>2.387323</td>\n",
       "      <td>3.215623</td>\n",
       "      <td>0.288633</td>\n",
       "      <td>3.701821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004524</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848.200012</td>\n",
       "      <td>2024-11-29 21:00:00+00:00</td>\n",
       "      <td>2024-11-29 22:00:00+00:00</td>\n",
       "      <td>-30.659681</td>\n",
       "      <td>8.780246</td>\n",
       "      <td>1.967827</td>\n",
       "      <td>1.620036</td>\n",
       "      <td>2.482432</td>\n",
       "      <td>0.516816</td>\n",
       "      <td>3.950176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081036</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>836.049988</td>\n",
       "      <td>2024-11-29 20:00:00+00:00</td>\n",
       "      <td>2024-11-29 21:00:00+00:00</td>\n",
       "      <td>-29.321284</td>\n",
       "      <td>9.297498</td>\n",
       "      <td>1.494915</td>\n",
       "      <td>1.490229</td>\n",
       "      <td>2.968878</td>\n",
       "      <td>1.071656</td>\n",
       "      <td>3.674438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073105</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>894.219971</td>\n",
       "      <td>2024-11-29 19:00:00+00:00</td>\n",
       "      <td>2024-11-29 20:00:00+00:00</td>\n",
       "      <td>-27.818541</td>\n",
       "      <td>9.207599</td>\n",
       "      <td>0.853380</td>\n",
       "      <td>2.309477</td>\n",
       "      <td>2.890789</td>\n",
       "      <td>0.990981</td>\n",
       "      <td>2.872615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040381</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>47.811001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SpotPriceDKK                       from                         to  \\\n",
       "0    596.570007  2024-11-29 23:00:00+00:00  2024-11-30 00:00:00+00:00   \n",
       "1    770.270020  2024-11-29 22:00:00+00:00  2024-11-29 23:00:00+00:00   \n",
       "2    848.200012  2024-11-29 21:00:00+00:00  2024-11-29 22:00:00+00:00   \n",
       "3    836.049988  2024-11-29 20:00:00+00:00  2024-11-29 21:00:00+00:00   \n",
       "4    894.219971  2024-11-29 19:00:00+00:00  2024-11-29 20:00:00+00:00   \n",
       "\n",
       "   temp_pca_1  temp_pca_2  temp_pca_3  wind_speed_pca_1  wind_speed_pca_2  \\\n",
       "0  -33.480249    7.339981    1.718044          3.248249          2.159318   \n",
       "1  -32.131543    8.173021    2.038769          2.387323          3.215623   \n",
       "2  -30.659681    8.780246    1.967827          1.620036          2.482432   \n",
       "3  -29.321284    9.297498    1.494915          1.490229          2.968878   \n",
       "4  -27.818541    9.207599    0.853380          2.309477          2.890789   \n",
       "\n",
       "   wind_speed_pca_3  wind_speed_pca_4  ...  mean_wind_dir_pca_39  hour_sin  \\\n",
       "0          0.612078          3.505092  ...             -0.093112 -0.258819   \n",
       "1          0.288633          3.701821  ...             -0.004524 -0.500000   \n",
       "2          0.516816          3.950176  ...             -0.081036 -0.707107   \n",
       "3          1.071656          3.674438  ...             -0.073105 -0.866025   \n",
       "4          0.990981          2.872615  ...             -0.040381 -0.965926   \n",
       "\n",
       "   hour_cos   day_sin   day_cos  month_sin  month_cos  oil_price  gas_price  \\\n",
       "0  0.965926 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "1  0.866025 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "2  0.707107 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "3  0.500000 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "4  0.258819 -0.433884 -0.900969       -0.5   0.866025  72.940002  47.811001   \n",
       "\n",
       "   constant  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62280, 68)\n"
     ]
    }
   ],
   "source": [
    "# path to the CSV file\n",
    "path = '../../data/fulldata.csv'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "display(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpotPriceDKK</th>\n",
       "      <th>from</th>\n",
       "      <th>temp_pca_1</th>\n",
       "      <th>temp_pca_2</th>\n",
       "      <th>temp_pca_3</th>\n",
       "      <th>wind_speed_pca_1</th>\n",
       "      <th>wind_speed_pca_2</th>\n",
       "      <th>wind_speed_pca_3</th>\n",
       "      <th>wind_speed_pca_4</th>\n",
       "      <th>wind_speed_pca_5</th>\n",
       "      <th>...</th>\n",
       "      <th>price_lag_-5</th>\n",
       "      <th>price_lag_-6</th>\n",
       "      <th>price_lag_-24</th>\n",
       "      <th>oil_price_-24</th>\n",
       "      <th>gas_price_-24</th>\n",
       "      <th>oil_price_-48</th>\n",
       "      <th>gas_price_-48</th>\n",
       "      <th>oil_price_-72</th>\n",
       "      <th>gas_price_-72</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.019997</td>\n",
       "      <td>2017-10-27 00:00:00+00:00</td>\n",
       "      <td>11.237675</td>\n",
       "      <td>0.831761</td>\n",
       "      <td>0.323180</td>\n",
       "      <td>6.760909</td>\n",
       "      <td>2.790222</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>3.612175</td>\n",
       "      <td>4.192237</td>\n",
       "      <td>...</td>\n",
       "      <td>219.059998</td>\n",
       "      <td>222.639999</td>\n",
       "      <td>95.199997</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.349998</td>\n",
       "      <td>2017-10-27 01:00:00+00:00</td>\n",
       "      <td>11.377424</td>\n",
       "      <td>0.873795</td>\n",
       "      <td>0.021477</td>\n",
       "      <td>5.367659</td>\n",
       "      <td>1.404028</td>\n",
       "      <td>0.596286</td>\n",
       "      <td>4.109275</td>\n",
       "      <td>3.550561</td>\n",
       "      <td>...</td>\n",
       "      <td>210.059998</td>\n",
       "      <td>219.059998</td>\n",
       "      <td>104.129997</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141.729996</td>\n",
       "      <td>2017-10-27 02:00:00+00:00</td>\n",
       "      <td>11.360804</td>\n",
       "      <td>0.662414</td>\n",
       "      <td>-0.153373</td>\n",
       "      <td>4.258495</td>\n",
       "      <td>1.098352</td>\n",
       "      <td>-0.898239</td>\n",
       "      <td>4.812269</td>\n",
       "      <td>2.074639</td>\n",
       "      <td>...</td>\n",
       "      <td>201.720001</td>\n",
       "      <td>210.059998</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178.720001</td>\n",
       "      <td>2017-10-27 03:00:00+00:00</td>\n",
       "      <td>11.961742</td>\n",
       "      <td>0.604866</td>\n",
       "      <td>-0.202105</td>\n",
       "      <td>3.781656</td>\n",
       "      <td>0.551939</td>\n",
       "      <td>-0.444115</td>\n",
       "      <td>4.825875</td>\n",
       "      <td>1.811022</td>\n",
       "      <td>...</td>\n",
       "      <td>194.720001</td>\n",
       "      <td>201.720001</td>\n",
       "      <td>196.139999</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>238.199997</td>\n",
       "      <td>2017-10-27 04:00:00+00:00</td>\n",
       "      <td>12.162359</td>\n",
       "      <td>0.136666</td>\n",
       "      <td>-0.113291</td>\n",
       "      <td>3.029801</td>\n",
       "      <td>1.184454</td>\n",
       "      <td>-0.552593</td>\n",
       "      <td>5.198467</td>\n",
       "      <td>2.016204</td>\n",
       "      <td>...</td>\n",
       "      <td>186.460007</td>\n",
       "      <td>194.720001</td>\n",
       "      <td>258.070007</td>\n",
       "      <td>58.439999</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>58.330002</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>18.09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SpotPriceDKK                      from  temp_pca_1  temp_pca_2  temp_pca_3  \\\n",
       "0     96.019997 2017-10-27 00:00:00+00:00   11.237675    0.831761    0.323180   \n",
       "1     95.349998 2017-10-27 01:00:00+00:00   11.377424    0.873795    0.021477   \n",
       "2    141.729996 2017-10-27 02:00:00+00:00   11.360804    0.662414   -0.153373   \n",
       "3    178.720001 2017-10-27 03:00:00+00:00   11.961742    0.604866   -0.202105   \n",
       "4    238.199997 2017-10-27 04:00:00+00:00   12.162359    0.136666   -0.113291   \n",
       "\n",
       "   wind_speed_pca_1  wind_speed_pca_2  wind_speed_pca_3  wind_speed_pca_4  \\\n",
       "0          6.760909          2.790222          0.398300          3.612175   \n",
       "1          5.367659          1.404028          0.596286          4.109275   \n",
       "2          4.258495          1.098352         -0.898239          4.812269   \n",
       "3          3.781656          0.551939         -0.444115          4.825875   \n",
       "4          3.029801          1.184454         -0.552593          5.198467   \n",
       "\n",
       "   wind_speed_pca_5  ...  price_lag_-5  price_lag_-6  price_lag_-24  \\\n",
       "0          4.192237  ...    219.059998    222.639999      95.199997   \n",
       "1          3.550561  ...    210.059998    219.059998     104.129997   \n",
       "2          2.074639  ...    201.720001    210.059998     126.760002   \n",
       "3          1.811022  ...    194.720001    201.720001     196.139999   \n",
       "4          2.016204  ...    186.460007    194.720001     258.070007   \n",
       "\n",
       "   oil_price_-24  gas_price_-24  oil_price_-48  gas_price_-48  oil_price_-72  \\\n",
       "0      58.439999      18.110001      58.330002      17.959999      57.369999   \n",
       "1      58.439999      18.110001      58.330002      17.959999      57.369999   \n",
       "2      58.439999      18.110001      58.330002      17.959999      57.369999   \n",
       "3      58.439999      18.110001      58.330002      17.959999      57.369999   \n",
       "4      58.439999      18.110001      58.330002      17.959999      57.369999   \n",
       "\n",
       "   gas_price_-72  weekend  \n",
       "0          18.09    False  \n",
       "1          18.09    False  \n",
       "2          18.09    False  \n",
       "3          18.09    False  \n",
       "4          18.09    False  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62184, 80)\n"
     ]
    }
   ],
   "source": [
    "data['from'] = pd.to_datetime(data['from'])\n",
    "\n",
    "# drop to column\n",
    "data = data.drop(columns=['to'])\n",
    "\n",
    "# explicitly including lagged prices as well\n",
    "lag_hours = [0, \n",
    "            -1, -2, -3, -4, -5, -6, -24, #-48, -72, -96, -120, -144, -168\n",
    "             ]\n",
    "for lag in lag_hours:\n",
    "    data[f'price_lag_{lag}'] = data['SpotPriceDKK'].shift(lag)\n",
    "\n",
    "lag_oil_gas = [-24, -48, -72, # -168\n",
    "               ]\n",
    "for lag in lag_oil_gas:\n",
    "    data[f'oil_price_{lag}'] = data['oil_price'].shift(lag)\n",
    "    data[f'gas_price_{lag}'] = data['gas_price'].shift(lag)\n",
    "\n",
    "# offset price by 1 day\n",
    "data['SpotPriceDKK'] = data['SpotPriceDKK'].shift(24)\n",
    "data['from'] = data['from'].shift(24)\n",
    "\n",
    "time_features = ['day', 'month']\n",
    "\n",
    "for i in time_features:\n",
    "    data[f'{i}_sin'] = data[f'{i}_sin'].shift(24)\n",
    "    data[f'{i}_cos'] = data[f'{i}_cos'].shift(24)\n",
    "\n",
    "# drop hour variable\n",
    "data = data.drop(columns=['hour_sin', 'hour_cos'])\n",
    "\n",
    "# drop the first 24 rows\n",
    "data = data.dropna()\n",
    "\n",
    "# weekdend feature\n",
    "data['weekend'] = data['from'].dt.dayofweek > 4\n",
    "\n",
    "# sort data to be ascending\n",
    "data = data.sort_values('from')\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "display(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of features before interaction terms: 78\n",
      "Target variable: ['SpotPriceDKK']\n"
     ]
    }
   ],
   "source": [
    "# extract column names\n",
    "cols = data.columns.tolist()\n",
    "\n",
    "# select features and target variable\n",
    "all_features = cols[2:]\n",
    "target = cols[:1]\n",
    "\n",
    "print(f'Count of features before interaction terms: {len(all_features)}')\n",
    "print(f'Target variable: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 24 datasets, one for each hour of the day\n",
    "datasets = []\n",
    "for i in range(24):\n",
    "    datasets.append(data[data['from'].dt.hour == i])\n",
    "\n",
    "# split into train, val and test, for dates ['from'] < '2023-08-01' (data['from'] >= '2023-08-01') & (data['from'] < '2024-08-01') and data['from'] >= '2024-08-01' respectively\n",
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "for i in range(24):\n",
    "    train.append(datasets[i][(datasets[i]['from'] < '2023-08-01')])\n",
    "    val.append(datasets[i][(datasets[i]['from'] >= '2023-08-01') & (datasets[i]['from'] < '2024-08-01')])\n",
    "    test.append(datasets[i][(datasets[i]['from'] >= '2024-07-31')])  # initialized 24 hours before to get the first 24 hours\n",
    "\n",
    "X_train = []\n",
    "X_val = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_val = []\n",
    "y_test = []\n",
    "for i in range(24):\n",
    "    X_train.append(train[i][all_features].values)\n",
    "    X_val.append(val[i][all_features].values)\n",
    "    X_test.append(test[i][all_features].values)\n",
    "\n",
    "    scalar = StandardScaler()\n",
    "    X_train[i] = scalar.fit_transform(X_train[i])\n",
    "    X_val[i] = scalar.transform(X_val[i])\n",
    "    X_test[i] = scalar.transform(X_test[i])\n",
    "\n",
    "    y_train.append(train[i][target].values)\n",
    "    y_val.append(val[i][target].values)\n",
    "    y_test.append(test[i][target].values)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "torch.manual_seed(2024)\n",
    "np.random.seed(2024)\n",
    "\n",
    "# hyperparameters\n",
    "seq_length = 7  # Use past week to form a sequence\n",
    "batch_size = 256\n",
    "input_dim = X_train[1].shape[1]\n",
    "output_dim = 1\n",
    "learning_rate = 0.0025\n",
    "\n",
    "# arrays for tuning\n",
    "lambda_l1_array = [1e-1]\n",
    "lambda_l2_array = [1e-4]\n",
    "hidden_dim_array = [512]\n",
    "layer_dim_array = [2]\n",
    "\n",
    "# loss evaluation function\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = []\n",
    "val_loader = []\n",
    "test_loader = []\n",
    "for i in range(24):\n",
    "    train_data = dataset(X_train[i], y_train[i], seq_length)\n",
    "    val_data = dataset(X_val[i], y_val[i], seq_length)\n",
    "    test_data = dataset(X_test[i], y_test[i], seq_length)\n",
    "    torch.manual_seed(2024)\n",
    "    np.random.seed(2024)\n",
    "    train_loader.append(DataLoader(train_data, batch_size=batch_size, shuffle=True))\n",
    "    val_loader.append(DataLoader(val_data, batch_size=batch_size, shuffle=False))\n",
    "    test_loader.append(DataLoader(test_data, batch_size=batch_size, shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for hour 0\n",
      "Epoch [50/250], Training Loss: 481330.7361, Validation Loss: 144881.1797\n",
      "Epoch [100/250], Training Loss: 461937.8368, Validation Loss: 85837.7109\n",
      "Epoch [150/250], Training Loss: 383512.0868, Validation Loss: 57548.8711\n",
      "Epoch [200/250], Training Loss: 296887.9913, Validation Loss: 49479.3535\n",
      "Early stopping after 215 epochs. Best validation loss: 48349.8535\n",
      "Epoch [50/250], Training Loss: 481318.8611, Validation Loss: 144882.2891\n",
      "Epoch [100/250], Training Loss: 461628.3542, Validation Loss: 85735.0234\n",
      "Epoch [150/250], Training Loss: 383184.2014, Validation Loss: 56586.9258\n",
      "Epoch [200/250], Training Loss: 296786.3958, Validation Loss: 47118.2520\n",
      "Early stopping after 209 epochs. Best validation loss: 47118.2520\n",
      "Epoch [50/250], Training Loss: 481319.4236, Validation Loss: 144882.0625\n",
      "Epoch [100/250], Training Loss: 461920.8056, Validation Loss: 85751.6641\n",
      "Epoch [150/250], Training Loss: 383698.8056, Validation Loss: 57707.5430\n",
      "Epoch [200/250], Training Loss: 296293.2378, Validation Loss: 51700.5293\n",
      "Early stopping after 206 epochs. Best validation loss: 51320.5820\n",
      "Epoch [50/250], Training Loss: 481285.1111, Validation Loss: 145029.3906\n",
      "Epoch [100/250], Training Loss: 461932.1771, Validation Loss: 85904.9102\n",
      "Epoch [150/250], Training Loss: 383101.0972, Validation Loss: 58305.6680\n",
      "Epoch [200/250], Training Loss: 296485.0365, Validation Loss: 49577.5566\n",
      "Early stopping after 215 epochs. Best validation loss: 48689.4922\n",
      "Epoch [50/250], Training Loss: 481284.9549, Validation Loss: 145029.5000\n",
      "Epoch [100/250], Training Loss: 461718.2361, Validation Loss: 85926.2383\n",
      "Epoch [150/250], Training Loss: 383010.7431, Validation Loss: 57160.5625\n",
      "Epoch [200/250], Training Loss: 296281.0469, Validation Loss: 49185.2715\n",
      "Early stopping after 206 epochs. Best validation loss: 48569.3770\n",
      "Epoch [50/250], Training Loss: 481284.8993, Validation Loss: 145029.4922\n",
      "Epoch [100/250], Training Loss: 461353.1736, Validation Loss: 85810.5664\n",
      "Epoch [150/250], Training Loss: 382762.5556, Validation Loss: 55552.8691\n",
      "Epoch [200/250], Training Loss: 296133.9201, Validation Loss: 48221.9668\n",
      "Early stopping after 218 epochs. Best validation loss: 46848.6016\n",
      "Epoch [50/250], Training Loss: 481251.2257, Validation Loss: 145038.8750\n",
      "Epoch [100/250], Training Loss: 461783.9757, Validation Loss: 85997.2031\n",
      "Epoch [150/250], Training Loss: 383002.4201, Validation Loss: 56079.8770\n",
      "Early stopping after 198 epochs. Best validation loss: 47116.7051\n",
      "Epoch [50/250], Training Loss: 481250.6042, Validation Loss: 145038.9453\n",
      "Epoch [100/250], Training Loss: 461468.8750, Validation Loss: 86014.6328\n",
      "Epoch [150/250], Training Loss: 382696.8958, Validation Loss: 57517.3457\n",
      "Early stopping after 196 epochs. Best validation loss: 47928.3164\n",
      "Epoch [50/250], Training Loss: 481250.5243, Validation Loss: 145038.9531\n",
      "Epoch [100/250], Training Loss: 461851.4201, Validation Loss: 86046.8164\n",
      "Epoch [150/250], Training Loss: 382874.9028, Validation Loss: 56106.2852\n",
      "Epoch [200/250], Training Loss: 296353.7240, Validation Loss: 47951.9746\n",
      "Early stopping after 207 epochs. Best validation loss: 47755.5020\n",
      "Epoch [50/250], Training Loss: 431092.5243, Validation Loss: 84975.5469\n",
      "Epoch [100/250], Training Loss: 307466.5174, Validation Loss: 48076.9883\n",
      "Early stopping after 120 epochs. Best validation loss: 47115.8457\n",
      "Epoch [50/250], Training Loss: 431195.1389, Validation Loss: 84903.3828\n",
      "Epoch [100/250], Training Loss: 307527.0538, Validation Loss: 53203.8652\n",
      "Early stopping after 113 epochs. Best validation loss: 50625.1895\n",
      "Epoch [50/250], Training Loss: 431123.9965, Validation Loss: 84964.0039\n",
      "Epoch [100/250], Training Loss: 307503.8802, Validation Loss: 48639.0938\n",
      "Early stopping after 111 epochs. Best validation loss: 48329.1211\n",
      "Epoch [50/250], Training Loss: 432041.5278, Validation Loss: 86437.8281\n",
      "Epoch [100/250], Training Loss: 308420.0833, Validation Loss: 46826.1523\n",
      "Early stopping after 114 epochs. Best validation loss: 46739.0156\n",
      "Epoch [50/250], Training Loss: 430074.6667, Validation Loss: 85150.2656\n",
      "Epoch [100/250], Training Loss: 306652.0556, Validation Loss: 50770.5762\n",
      "Early stopping after 119 epochs. Best validation loss: 48534.7324\n",
      "Epoch [50/250], Training Loss: 430545.7812, Validation Loss: 85295.9688\n",
      "Epoch [100/250], Training Loss: 306580.5069, Validation Loss: 46956.9883\n",
      "Early stopping after 109 epochs. Best validation loss: 46956.9883\n",
      "Epoch [50/250], Training Loss: 437484.7847, Validation Loss: 86967.6250\n",
      "Epoch [100/250], Training Loss: 307509.6128, Validation Loss: 48185.0391\n",
      "Early stopping after 112 epochs. Best validation loss: 48045.2715\n",
      "Epoch [50/250], Training Loss: 437495.5729, Validation Loss: 86959.4609\n",
      "Epoch [100/250], Training Loss: 308969.5990, Validation Loss: 47213.9180\n",
      "Early stopping after 113 epochs. Best validation loss: 46584.9258\n",
      "Epoch [50/250], Training Loss: 437513.8611, Validation Loss: 86973.3047\n",
      "Epoch [100/250], Training Loss: 307649.6510, Validation Loss: 49424.4609\n",
      "Early stopping after 116 epochs. Best validation loss: 48995.5273\n",
      "Epoch [50/250], Training Loss: 334857.7812, Validation Loss: 50465.1836\n",
      "Early stopping after 62 epochs. Best validation loss: 47013.8984\n",
      "Epoch [50/250], Training Loss: 335490.7153, Validation Loss: 49120.8887\n",
      "Early stopping after 63 epochs. Best validation loss: 47960.5430\n",
      "Epoch [50/250], Training Loss: 334189.0712, Validation Loss: 50521.0586\n",
      "Early stopping after 61 epochs. Best validation loss: 49653.5098\n",
      "Epoch [50/250], Training Loss: 332974.2014, Validation Loss: 49039.2656\n",
      "Early stopping after 55 epochs. Best validation loss: 48560.3125\n",
      "Epoch [50/250], Training Loss: 332614.8646, Validation Loss: 46327.6875\n",
      "Early stopping after 59 epochs. Best validation loss: 46327.6875\n",
      "Epoch [50/250], Training Loss: 334874.3108, Validation Loss: 47573.7441\n",
      "Early stopping after 64 epochs. Best validation loss: 47346.6406\n",
      "Epoch [50/250], Training Loss: 338489.7413, Validation Loss: 50259.6309\n",
      "Early stopping after 66 epochs. Best validation loss: 49677.4746\n",
      "Epoch [50/250], Training Loss: 341504.1476, Validation Loss: 49740.2246\n",
      "Early stopping after 59 epochs. Best validation loss: 49740.2246\n",
      "Epoch [50/250], Training Loss: 338905.4948, Validation Loss: 49010.2676\n",
      "Early stopping after 58 epochs. Best validation loss: 48917.0195\n",
      "Training model for hour 1\n",
      "Epoch [50/250], Training Loss: 455465.3854, Validation Loss: 136212.1016\n",
      "Epoch [100/250], Training Loss: 436036.0365, Validation Loss: 80725.3672\n",
      "Epoch [150/250], Training Loss: 363542.8368, Validation Loss: 55876.6973\n",
      "Early stopping after 177 epochs. Best validation loss: 52890.6562\n",
      "Epoch [50/250], Training Loss: 455464.9340, Validation Loss: 136212.4609\n",
      "Epoch [100/250], Training Loss: 436117.5260, Validation Loss: 80622.0898\n",
      "Epoch [150/250], Training Loss: 363248.5660, Validation Loss: 55640.4258\n",
      "Epoch [200/250], Training Loss: 280231.2396, Validation Loss: 53045.4141\n",
      "Early stopping after 205 epochs. Best validation loss: 51327.3750\n",
      "Epoch [50/250], Training Loss: 455464.8507, Validation Loss: 136212.5234\n",
      "Epoch [100/250], Training Loss: 436031.6354, Validation Loss: 80506.3047\n",
      "Epoch [150/250], Training Loss: 363366.0069, Validation Loss: 54856.7598\n",
      "Early stopping after 173 epochs. Best validation loss: 51552.5254\n",
      "Epoch [50/250], Training Loss: 455550.5972, Validation Loss: 136459.4062\n",
      "Epoch [100/250], Training Loss: 435656.9236, Validation Loss: 80994.0195\n",
      "Epoch [150/250], Training Loss: 362814.1736, Validation Loss: 54872.8574\n",
      "Early stopping after 198 epochs. Best validation loss: 49982.2812\n",
      "Epoch [50/250], Training Loss: 455550.4861, Validation Loss: 136459.5469\n",
      "Epoch [100/250], Training Loss: 434990.5035, Validation Loss: 80568.0000\n",
      "Epoch [150/250], Training Loss: 362796.4444, Validation Loss: 54775.3672\n",
      "Early stopping after 171 epochs. Best validation loss: 51150.1836\n",
      "Epoch [50/250], Training Loss: 455550.3993, Validation Loss: 136459.5312\n",
      "Epoch [100/250], Training Loss: 435493.4253, Validation Loss: 80947.4102\n",
      "Epoch [150/250], Training Loss: 362692.5347, Validation Loss: 54484.5469\n",
      "Epoch [200/250], Training Loss: 280066.4028, Validation Loss: 46411.4473\n",
      "Early stopping after 220 epochs. Best validation loss: 45339.4219\n",
      "Epoch [50/250], Training Loss: 455511.0486, Validation Loss: 136463.3828\n",
      "Epoch [100/250], Training Loss: 435551.3837, Validation Loss: 81415.7891\n",
      "Epoch [150/250], Training Loss: 362848.5590, Validation Loss: 55939.9902\n",
      "Early stopping after 196 epochs. Best validation loss: 50539.6328\n",
      "Epoch [50/250], Training Loss: 455510.2014, Validation Loss: 136463.2812\n",
      "Epoch [100/250], Training Loss: 435856.6597, Validation Loss: 81176.1992\n",
      "Epoch [150/250], Training Loss: 362870.6979, Validation Loss: 56908.8027\n",
      "Early stopping after 186 epochs. Best validation loss: 51471.2793\n",
      "Epoch [50/250], Training Loss: 455510.1910, Validation Loss: 136463.3281\n",
      "Epoch [100/250], Training Loss: 435295.6198, Validation Loss: 81053.2344\n",
      "Epoch [150/250], Training Loss: 363227.3958, Validation Loss: 54343.5449\n",
      "Early stopping after 191 epochs. Best validation loss: 49125.2676\n",
      "Epoch [50/250], Training Loss: 407322.5312, Validation Loss: 80229.3477\n",
      "Epoch [100/250], Training Loss: 289866.3490, Validation Loss: 51085.7773\n",
      "Early stopping after 106 epochs. Best validation loss: 49324.9922\n",
      "Epoch [50/250], Training Loss: 407376.3611, Validation Loss: 80100.8789\n",
      "Epoch [100/250], Training Loss: 289963.3889, Validation Loss: 49405.6699\n",
      "Early stopping after 111 epochs. Best validation loss: 48519.1387\n",
      "Epoch [50/250], Training Loss: 407798.7153, Validation Loss: 80627.6953\n",
      "Epoch [100/250], Training Loss: 290833.1719, Validation Loss: 49967.0273\n",
      "Early stopping after 114 epochs. Best validation loss: 48562.2363\n",
      "Epoch [50/250], Training Loss: 405949.6840, Validation Loss: 80223.7500\n",
      "Epoch [100/250], Training Loss: 289306.5174, Validation Loss: 48343.8809\n",
      "Early stopping after 109 epochs. Best validation loss: 48343.8809\n",
      "Epoch [50/250], Training Loss: 406352.8264, Validation Loss: 80299.4766\n",
      "Epoch [100/250], Training Loss: 289504.7778, Validation Loss: 48662.6250\n",
      "Early stopping after 109 epochs. Best validation loss: 48662.6250\n",
      "Epoch [50/250], Training Loss: 405959.6875, Validation Loss: 80077.5039\n",
      "Epoch [100/250], Training Loss: 289266.8420, Validation Loss: 50309.6230\n",
      "Early stopping after 108 epochs. Best validation loss: 49608.1133\n",
      "Epoch [50/250], Training Loss: 414362.2674, Validation Loss: 83103.7969\n",
      "Epoch [100/250], Training Loss: 289307.5191, Validation Loss: 48750.0781\n",
      "Early stopping after 106 epochs. Best validation loss: 48100.5703\n",
      "Epoch [50/250], Training Loss: 413190.1111, Validation Loss: 82114.9492\n",
      "Epoch [100/250], Training Loss: 290724.2969, Validation Loss: 51961.2715\n",
      "Early stopping after 111 epochs. Best validation loss: 51232.5098\n",
      "Epoch [50/250], Training Loss: 410276.0590, Validation Loss: 81854.3008\n",
      "Epoch [100/250], Training Loss: 289143.2049, Validation Loss: 47401.2734\n",
      "Early stopping after 109 epochs. Best validation loss: 47401.2734\n",
      "Epoch [50/250], Training Loss: 318419.3212, Validation Loss: 49908.3965\n",
      "Early stopping after 56 epochs. Best validation loss: 48935.7480\n",
      "Epoch [50/250], Training Loss: 317935.8455, Validation Loss: 48656.9785\n",
      "Early stopping after 57 epochs. Best validation loss: 47930.5566\n",
      "Epoch [50/250], Training Loss: 317863.6042, Validation Loss: 47584.1348\n",
      "Early stopping after 58 epochs. Best validation loss: 47275.3320\n",
      "Epoch [50/250], Training Loss: 317504.7500, Validation Loss: 50193.9688\n",
      "Early stopping after 56 epochs. Best validation loss: 49388.7871\n",
      "Epoch [50/250], Training Loss: 316711.1337, Validation Loss: 50440.9219\n",
      "Early stopping after 52 epochs. Best validation loss: 48985.4941\n",
      "Epoch [50/250], Training Loss: 315906.2101, Validation Loss: 48669.8320\n",
      "Early stopping after 59 epochs. Best validation loss: 48669.8320\n",
      "Epoch [50/250], Training Loss: 321482.7622, Validation Loss: 48460.5859\n",
      "Early stopping after 60 epochs. Best validation loss: 48361.2422\n",
      "Epoch [50/250], Training Loss: 316795.6771, Validation Loss: 49626.5449\n",
      "Early stopping after 57 epochs. Best validation loss: 49316.8711\n",
      "Epoch [50/250], Training Loss: 323876.0000, Validation Loss: 49773.3262\n",
      "Early stopping after 62 epochs. Best validation loss: 49039.7422\n",
      "Training model for hour 2\n",
      "Epoch [50/250], Training Loss: 448108.1979, Validation Loss: 133363.8203\n",
      "Epoch [100/250], Training Loss: 435742.6562, Validation Loss: 79605.3828\n",
      "Epoch [150/250], Training Loss: 360957.6979, Validation Loss: 56209.1094\n",
      "Early stopping after 184 epochs. Best validation loss: 52550.8359\n",
      "Epoch [50/250], Training Loss: 448093.6806, Validation Loss: 133378.6250\n",
      "Epoch [100/250], Training Loss: 435318.9340, Validation Loss: 79769.0586\n",
      "Epoch [150/250], Training Loss: 360453.4271, Validation Loss: 56528.6602\n",
      "Epoch [200/250], Training Loss: 276287.3924, Validation Loss: 50108.7305\n",
      "Early stopping after 205 epochs. Best validation loss: 48977.5703\n",
      "Epoch [50/250], Training Loss: 448088.4896, Validation Loss: 133378.0312\n",
      "Epoch [100/250], Training Loss: 436110.8611, Validation Loss: 79692.5156\n",
      "Epoch [150/250], Training Loss: 360342.4323, Validation Loss: 57410.6289\n",
      "Early stopping after 171 epochs. Best validation loss: 55742.3438\n",
      "Epoch [50/250], Training Loss: 448023.0556, Validation Loss: 133518.5781\n",
      "Epoch [100/250], Training Loss: 434726.5799, Validation Loss: 79901.4336\n",
      "Epoch [150/250], Training Loss: 360079.1597, Validation Loss: 56792.3203\n",
      "Epoch [200/250], Training Loss: 275744.8333, Validation Loss: 50576.1270\n",
      "Early stopping after 206 epochs. Best validation loss: 50260.9219\n",
      "Epoch [50/250], Training Loss: 448022.5347, Validation Loss: 133518.5156\n",
      "Epoch [100/250], Training Loss: 434970.8368, Validation Loss: 80203.6094\n",
      "Epoch [150/250], Training Loss: 359908.5920, Validation Loss: 58050.7520\n",
      "Epoch [200/250], Training Loss: 275940.1597, Validation Loss: 49987.7422\n",
      "Early stopping after 209 epochs. Best validation loss: 49987.7422\n",
      "Epoch [50/250], Training Loss: 448022.4757, Validation Loss: 133518.5234\n",
      "Epoch [100/250], Training Loss: 434461.3750, Validation Loss: 79680.6172\n",
      "Epoch [150/250], Training Loss: 359971.1319, Validation Loss: 58160.5020\n",
      "Epoch [200/250], Training Loss: 275704.5503, Validation Loss: 54323.2031\n",
      "Early stopping after 202 epochs. Best validation loss: 52371.7383\n",
      "Epoch [50/250], Training Loss: 447989.4236, Validation Loss: 133528.4375\n",
      "Epoch [100/250], Training Loss: 435111.5764, Validation Loss: 79824.1445\n",
      "Epoch [150/250], Training Loss: 360074.1580, Validation Loss: 57563.9375\n",
      "Early stopping after 196 epochs. Best validation loss: 51747.7754\n",
      "Epoch [50/250], Training Loss: 447988.3264, Validation Loss: 133528.1172\n",
      "Epoch [100/250], Training Loss: 435379.4062, Validation Loss: 79878.0352\n",
      "Epoch [150/250], Training Loss: 359980.4722, Validation Loss: 57044.0449\n",
      "Early stopping after 185 epochs. Best validation loss: 52190.3906\n",
      "Epoch [50/250], Training Loss: 447988.2153, Validation Loss: 133528.0938\n",
      "Epoch [100/250], Training Loss: 434939.5556, Validation Loss: 79913.9922\n",
      "Epoch [150/250], Training Loss: 360307.3385, Validation Loss: 58933.1504\n",
      "Early stopping after 169 epochs. Best validation loss: 56219.6816\n",
      "Epoch [50/250], Training Loss: 404084.9062, Validation Loss: 78860.5117\n",
      "Epoch [100/250], Training Loss: 286317.1424, Validation Loss: 50605.0273\n",
      "Early stopping after 107 epochs. Best validation loss: 49768.3438\n",
      "Epoch [50/250], Training Loss: 404277.2917, Validation Loss: 78890.1719\n",
      "Early stopping after 98 epochs. Best validation loss: 52056.2402\n",
      "Epoch [50/250], Training Loss: 404024.8681, Validation Loss: 78861.3828\n",
      "Early stopping after 94 epochs. Best validation loss: 51210.4160\n",
      "Epoch [50/250], Training Loss: 403634.8819, Validation Loss: 79038.6133\n",
      "Epoch [100/250], Training Loss: 285711.6059, Validation Loss: 51869.7012\n",
      "Early stopping after 112 epochs. Best validation loss: 51486.8926\n",
      "Epoch [50/250], Training Loss: 403719.8403, Validation Loss: 79044.0469\n",
      "Early stopping after 98 epochs. Best validation loss: 49916.3008\n",
      "Epoch [50/250], Training Loss: 403688.0972, Validation Loss: 79079.4023\n",
      "Epoch [100/250], Training Loss: 285520.3247, Validation Loss: 52120.1543\n",
      "Early stopping after 107 epochs. Best validation loss: 50558.2832\n",
      "Epoch [50/250], Training Loss: 407882.3299, Validation Loss: 80862.7734\n",
      "Epoch [100/250], Training Loss: 285548.6337, Validation Loss: 51839.5430\n",
      "Early stopping after 105 epochs. Best validation loss: 50384.1875\n",
      "Epoch [50/250], Training Loss: 406982.3229, Validation Loss: 80455.8086\n",
      "Epoch [100/250], Training Loss: 285312.4358, Validation Loss: 50584.4160\n",
      "Early stopping after 105 epochs. Best validation loss: 50168.1484\n",
      "Epoch [50/250], Training Loss: 406563.0417, Validation Loss: 80599.2891\n",
      "Epoch [100/250], Training Loss: 285495.3594, Validation Loss: 53191.3223\n",
      "Early stopping after 99 epochs. Best validation loss: 53097.7891\n",
      "Epoch [50/250], Training Loss: 315950.9844, Validation Loss: 48421.6211\n",
      "Early stopping after 59 epochs. Best validation loss: 48421.6211\n",
      "Epoch [50/250], Training Loss: 319146.1111, Validation Loss: 49441.5352\n",
      "Early stopping after 58 epochs. Best validation loss: 49123.3418\n",
      "Epoch [50/250], Training Loss: 317157.3542, Validation Loss: 48560.5312\n",
      "Early stopping after 58 epochs. Best validation loss: 48349.0449\n",
      "Epoch [50/250], Training Loss: 314291.3368, Validation Loss: 52566.4043\n",
      "Early stopping after 57 epochs. Best validation loss: 50966.9062\n",
      "Epoch [50/250], Training Loss: 315935.6858, Validation Loss: 50521.3438\n",
      "Early stopping after 58 epochs. Best validation loss: 50252.1973\n",
      "Epoch [50/250], Training Loss: 317281.7083, Validation Loss: 50081.0996\n",
      "Early stopping after 59 epochs. Best validation loss: 50081.0996\n",
      "Epoch [50/250], Training Loss: 313104.8819, Validation Loss: 55648.4297\n",
      "Early stopping after 57 epochs. Best validation loss: 52401.7910\n",
      "Epoch [50/250], Training Loss: 338554.5417, Validation Loss: 50757.1523\n",
      "Early stopping after 58 epochs. Best validation loss: 50277.0840\n",
      "Epoch [50/250], Training Loss: 320730.1667, Validation Loss: 51007.4531\n",
      "Early stopping after 60 epochs. Best validation loss: 50313.1582\n",
      "Training model for hour 3\n",
      "Epoch [50/250], Training Loss: 490197.0972, Validation Loss: 147429.8516\n",
      "Epoch [100/250], Training Loss: 476790.9618, Validation Loss: 89886.4648\n",
      "Epoch [150/250], Training Loss: 402318.6181, Validation Loss: 63315.0254\n",
      "Early stopping after 197 epochs. Best validation loss: 57994.8242\n",
      "Epoch [50/250], Training Loss: 489977.5556, Validation Loss: 147345.2891\n",
      "Epoch [100/250], Training Loss: 477607.3854, Validation Loss: 89927.3984\n",
      "Epoch [150/250], Training Loss: 402228.8785, Validation Loss: 63942.6504\n",
      "Epoch [200/250], Training Loss: 308407.7326, Validation Loss: 58295.9551\n",
      "Early stopping after 203 epochs. Best validation loss: 56367.2285\n",
      "Epoch [50/250], Training Loss: 490224.8785, Validation Loss: 147503.9297\n",
      "Epoch [100/250], Training Loss: 476725.0069, Validation Loss: 90062.6250\n",
      "Epoch [150/250], Training Loss: 402457.4201, Validation Loss: 64092.4629\n",
      "Early stopping after 195 epochs. Best validation loss: 56541.5469\n",
      "Epoch [50/250], Training Loss: 490296.1944, Validation Loss: 147805.8516\n",
      "Epoch [100/250], Training Loss: 476715.2986, Validation Loss: 90199.6914\n",
      "Epoch [150/250], Training Loss: 401814.0938, Validation Loss: 64119.4551\n",
      "Epoch [200/250], Training Loss: 308359.3646, Validation Loss: 60905.6367\n",
      "Early stopping after 207 epochs. Best validation loss: 56420.1504\n",
      "Epoch [50/250], Training Loss: 490295.9201, Validation Loss: 147805.8750\n",
      "Epoch [100/250], Training Loss: 477225.3611, Validation Loss: 90085.7852\n",
      "Epoch [150/250], Training Loss: 402074.7674, Validation Loss: 62600.8574\n",
      "Epoch [200/250], Training Loss: 308884.3958, Validation Loss: 58858.4238\n",
      "Early stopping after 200 epochs. Best validation loss: 55680.7422\n",
      "Epoch [50/250], Training Loss: 490295.9062, Validation Loss: 147805.8906\n",
      "Epoch [100/250], Training Loss: 476575.2708, Validation Loss: 90085.4062\n",
      "Epoch [150/250], Training Loss: 401839.3472, Validation Loss: 64261.7539\n",
      "Early stopping after 186 epochs. Best validation loss: 56466.0664\n",
      "Epoch [50/250], Training Loss: 490256.5000, Validation Loss: 147810.4688\n",
      "Epoch [100/250], Training Loss: 477130.5729, Validation Loss: 90256.0586\n",
      "Epoch [150/250], Training Loss: 402128.3472, Validation Loss: 62071.2344\n",
      "Early stopping after 198 epochs. Best validation loss: 56377.5605\n",
      "Epoch [50/250], Training Loss: 490255.6736, Validation Loss: 147810.3750\n",
      "Epoch [100/250], Training Loss: 477290.2500, Validation Loss: 90311.8672\n",
      "Epoch [150/250], Training Loss: 402299.0660, Validation Loss: 61669.5293\n",
      "Epoch [200/250], Training Loss: 308225.6250, Validation Loss: 57654.2266\n",
      "Early stopping after 210 epochs. Best validation loss: 57386.3867\n",
      "Epoch [50/250], Training Loss: 490255.5938, Validation Loss: 147810.3906\n",
      "Epoch [100/250], Training Loss: 476913.9757, Validation Loss: 90253.6055\n",
      "Epoch [150/250], Training Loss: 402165.7500, Validation Loss: 62126.9297\n",
      "Early stopping after 195 epochs. Best validation loss: 55811.9434\n",
      "Epoch [50/250], Training Loss: 448123.7743, Validation Loss: 89816.4570\n",
      "Epoch [100/250], Training Loss: 320799.4844, Validation Loss: 60454.9395\n",
      "Early stopping after 102 epochs. Best validation loss: 58514.4297\n",
      "Epoch [50/250], Training Loss: 447241.1458, Validation Loss: 89349.4570\n",
      "Epoch [100/250], Training Loss: 320375.5816, Validation Loss: 58744.8535\n",
      "Early stopping after 103 epochs. Best validation loss: 56634.7480\n",
      "Epoch [50/250], Training Loss: 449360.3646, Validation Loss: 91300.8477\n",
      "Epoch [100/250], Training Loss: 321873.9670, Validation Loss: 57339.8125\n",
      "Early stopping after 108 epochs. Best validation loss: 56590.6836\n",
      "Epoch [50/250], Training Loss: 447222.2014, Validation Loss: 90120.3125\n",
      "Epoch [100/250], Training Loss: 318323.6719, Validation Loss: 55265.4082\n",
      "Early stopping after 108 epochs. Best validation loss: 54896.0527\n",
      "Epoch [50/250], Training Loss: 447356.6042, Validation Loss: 90066.0273\n",
      "Epoch [100/250], Training Loss: 319313.8090, Validation Loss: 56973.7734\n",
      "Early stopping after 104 epochs. Best validation loss: 56540.6172\n",
      "Epoch [50/250], Training Loss: 446681.4167, Validation Loss: 89842.4609\n",
      "Epoch [100/250], Training Loss: 320416.4740, Validation Loss: 55867.9512\n",
      "Early stopping after 106 epochs. Best validation loss: 55545.1387\n",
      "Epoch [50/250], Training Loss: 452694.9444, Validation Loss: 90664.9727\n",
      "Epoch [100/250], Training Loss: 320702.9740, Validation Loss: 56905.4160\n",
      "Early stopping after 108 epochs. Best validation loss: 56549.5469\n",
      "Epoch [50/250], Training Loss: 453309.4931, Validation Loss: 91084.7773\n",
      "Epoch [100/250], Training Loss: 321268.2726, Validation Loss: 55027.9688\n",
      "Early stopping after 113 epochs. Best validation loss: 54500.9121\n",
      "Epoch [50/250], Training Loss: 453187.6701, Validation Loss: 90984.8828\n",
      "Epoch [100/250], Training Loss: 320507.5156, Validation Loss: 56883.1270\n",
      "Early stopping after 107 epochs. Best validation loss: 56171.0527\n",
      "Epoch [50/250], Training Loss: 349419.1319, Validation Loss: 55558.8867\n",
      "Early stopping after 58 epochs. Best validation loss: 55120.4062\n",
      "Epoch [50/250], Training Loss: 348784.1944, Validation Loss: 56407.4551\n",
      "Early stopping after 56 epochs. Best validation loss: 55812.7246\n",
      "Epoch [50/250], Training Loss: 348103.5920, Validation Loss: 56179.3594\n",
      "Early stopping after 59 epochs. Best validation loss: 56179.3594\n",
      "Epoch [50/250], Training Loss: 351417.9705, Validation Loss: 57211.6699\n",
      "Early stopping after 57 epochs. Best validation loss: 55888.7012\n",
      "Epoch [50/250], Training Loss: 350755.8767, Validation Loss: 58243.9336\n",
      "Early stopping after 60 epochs. Best validation loss: 56325.5762\n",
      "Epoch [50/250], Training Loss: 349406.0434, Validation Loss: 56677.0781\n",
      "Early stopping after 57 epochs. Best validation loss: 56321.6504\n",
      "Epoch [50/250], Training Loss: 349856.6389, Validation Loss: 57925.2383\n",
      "Early stopping after 57 epochs. Best validation loss: 57073.5391\n",
      "Epoch [50/250], Training Loss: 349852.9722, Validation Loss: 55667.6484\n",
      "Early stopping after 57 epochs. Best validation loss: 55633.2305\n",
      "Epoch [50/250], Training Loss: 350126.2639, Validation Loss: 56807.6758\n",
      "Early stopping after 57 epochs. Best validation loss: 55829.9043\n",
      "Training model for hour 4\n",
      "Epoch [50/250], Training Loss: 670133.4028, Validation Loss: 222347.1641\n",
      "Epoch [100/250], Training Loss: 668915.9410, Validation Loss: 146159.3125\n",
      "Epoch [150/250], Training Loss: 578612.5938, Validation Loss: 101098.9414\n",
      "Epoch [200/250], Training Loss: 438926.4774, Validation Loss: 80748.7344\n",
      "Early stopping after 243 epochs. Best validation loss: 76349.5059\n",
      "Epoch [50/250], Training Loss: 670133.3472, Validation Loss: 222347.2812\n",
      "Epoch [100/250], Training Loss: 668760.9618, Validation Loss: 145908.4062\n",
      "Epoch [150/250], Training Loss: 578750.8056, Validation Loss: 101976.9961\n",
      "Epoch [200/250], Training Loss: 440163.3438, Validation Loss: 82681.1641\n",
      "Early stopping after 241 epochs. Best validation loss: 78160.2188\n",
      "Epoch [50/250], Training Loss: 670133.3125, Validation Loss: 222347.2969\n",
      "Epoch [100/250], Training Loss: 669432.0833, Validation Loss: 146187.5234\n",
      "Epoch [150/250], Training Loss: 578821.5278, Validation Loss: 102257.0117\n",
      "Epoch [200/250], Training Loss: 439472.0295, Validation Loss: 81154.0352\n",
      "Epoch [250/250], Training Loss: 462581.9514, Validation Loss: 77793.8203\n",
      "Training stopped after 249 epochs. Best validation loss: 75687.1797\n",
      "Epoch [50/250], Training Loss: 670079.3715, Validation Loss: 222489.6406\n",
      "Epoch [100/250], Training Loss: 667854.0104, Validation Loss: 146067.2578\n",
      "Epoch [150/250], Training Loss: 578249.5938, Validation Loss: 101247.3672\n",
      "Epoch [200/250], Training Loss: 439046.0903, Validation Loss: 78892.8789\n",
      "Early stopping after 245 epochs. Best validation loss: 73586.2539\n",
      "Epoch [50/250], Training Loss: 670079.0660, Validation Loss: 222489.6328\n",
      "Epoch [100/250], Training Loss: 668597.4167, Validation Loss: 146150.8672\n",
      "Epoch [150/250], Training Loss: 577938.4479, Validation Loss: 101237.9219\n",
      "Epoch [200/250], Training Loss: 438390.5903, Validation Loss: 79302.8945\n",
      "Early stopping after 241 epochs. Best validation loss: 76060.4766\n",
      "Epoch [50/250], Training Loss: 670078.9236, Validation Loss: 222489.5312\n",
      "Epoch [100/250], Training Loss: 668346.2674, Validation Loss: 146154.3594\n",
      "Epoch [150/250], Training Loss: 578014.9479, Validation Loss: 101395.4336\n",
      "Epoch [200/250], Training Loss: 438948.2604, Validation Loss: 79286.0703\n",
      "Early stopping after 246 epochs. Best validation loss: 77039.8203\n",
      "Epoch [50/250], Training Loss: 670038.8090, Validation Loss: 222496.5703\n",
      "Epoch [100/250], Training Loss: 668627.0208, Validation Loss: 146291.7422\n",
      "Epoch [150/250], Training Loss: 578717.0833, Validation Loss: 101270.6016\n",
      "Epoch [200/250], Training Loss: 439603.4757, Validation Loss: 82241.7422\n",
      "Early stopping after 228 epochs. Best validation loss: 78487.8594\n",
      "Epoch [50/250], Training Loss: 670037.8368, Validation Loss: 222496.3828\n",
      "Epoch [100/250], Training Loss: 668979.7569, Validation Loss: 146369.9922\n",
      "Epoch [150/250], Training Loss: 578158.1667, Validation Loss: 102880.6406\n",
      "Epoch [200/250], Training Loss: 438579.0938, Validation Loss: 80005.5312\n",
      "Epoch [250/250], Training Loss: 460661.4184, Validation Loss: 73850.3672\n",
      "Training stopped after 249 epochs. Best validation loss: 73850.3672\n",
      "Epoch [50/250], Training Loss: 670037.7014, Validation Loss: 222496.3516\n",
      "Epoch [100/250], Training Loss: 668872.7778, Validation Loss: 146357.8906\n",
      "Epoch [150/250], Training Loss: 577947.4410, Validation Loss: 102341.6172\n",
      "Epoch [200/250], Training Loss: 436642.4601, Validation Loss: 79352.2852\n",
      "Epoch [250/250], Training Loss: 457144.6042, Validation Loss: 75960.7383\n",
      "Training stopped after 249 epochs. Best validation loss: 74688.7031\n",
      "Epoch [50/250], Training Loss: 624457.7639, Validation Loss: 145238.7812\n",
      "Epoch [100/250], Training Loss: 458801.1771, Validation Loss: 81273.9258\n",
      "Early stopping after 138 epochs. Best validation loss: 76857.5293\n",
      "Epoch [50/250], Training Loss: 622637.3854, Validation Loss: 144916.9375\n",
      "Epoch [100/250], Training Loss: 458093.5486, Validation Loss: 81192.9805\n",
      "Early stopping after 130 epochs. Best validation loss: 73394.9902\n",
      "Epoch [50/250], Training Loss: 623143.9375, Validation Loss: 144977.2734\n",
      "Epoch [100/250], Training Loss: 457379.3194, Validation Loss: 82052.1562\n",
      "Early stopping after 139 epochs. Best validation loss: 76063.7734\n",
      "Epoch [50/250], Training Loss: 625584.3507, Validation Loss: 146658.9062\n",
      "Epoch [100/250], Training Loss: 458681.2604, Validation Loss: 80648.7930\n",
      "Early stopping after 143 epochs. Best validation loss: 73948.5195\n",
      "Epoch [50/250], Training Loss: 622705.1424, Validation Loss: 145618.7031\n",
      "Epoch [100/250], Training Loss: 457285.0972, Validation Loss: 82967.9766\n",
      "Early stopping after 136 epochs. Best validation loss: 77453.6953\n",
      "Epoch [50/250], Training Loss: 624697.3021, Validation Loss: 146511.5078\n",
      "Epoch [100/250], Training Loss: 459491.9201, Validation Loss: 81993.2148\n",
      "Early stopping after 134 epochs. Best validation loss: 77213.9375\n",
      "Epoch [50/250], Training Loss: 625847.5729, Validation Loss: 145576.6016\n",
      "Epoch [100/250], Training Loss: 460817.5868, Validation Loss: 82654.5391\n",
      "Early stopping after 123 epochs. Best validation loss: 78971.5938\n",
      "Epoch [50/250], Training Loss: 626402.9826, Validation Loss: 146002.2891\n",
      "Epoch [100/250], Training Loss: 474745.7431, Validation Loss: 84805.9453\n",
      "Early stopping after 130 epochs. Best validation loss: 79857.2852\n",
      "Epoch [50/250], Training Loss: 624215.4028, Validation Loss: 145798.0469\n",
      "Epoch [100/250], Training Loss: 458052.0382, Validation Loss: 81299.2617\n",
      "Early stopping after 122 epochs. Best validation loss: 76989.1172\n",
      "Epoch [50/250], Training Loss: 503514.1771, Validation Loss: 81070.6523\n",
      "Early stopping after 69 epochs. Best validation loss: 76477.0898\n",
      "Epoch [50/250], Training Loss: 501845.9618, Validation Loss: 79871.2812\n",
      "Early stopping after 70 epochs. Best validation loss: 74863.6836\n",
      "Epoch [50/250], Training Loss: 501036.6250, Validation Loss: 80162.6328\n",
      "Early stopping after 72 epochs. Best validation loss: 75684.9688\n",
      "Epoch [50/250], Training Loss: 502981.0833, Validation Loss: 82347.4258\n",
      "Early stopping after 67 epochs. Best validation loss: 77992.3711\n",
      "Epoch [50/250], Training Loss: 499018.6354, Validation Loss: 82506.8672\n",
      "Early stopping after 66 epochs. Best validation loss: 79429.7148\n",
      "Epoch [50/250], Training Loss: 498707.0139, Validation Loss: 81963.5469\n",
      "Early stopping after 78 epochs. Best validation loss: 73608.9395\n",
      "Epoch [50/250], Training Loss: 499776.1042, Validation Loss: 81182.2930\n",
      "Early stopping after 68 epochs. Best validation loss: 75998.3281\n",
      "Epoch [50/250], Training Loss: 509694.1319, Validation Loss: 85238.0273\n",
      "Early stopping after 70 epochs. Best validation loss: 79111.8125\n",
      "Epoch [50/250], Training Loss: 508077.1597, Validation Loss: 84427.9883\n",
      "Early stopping after 68 epochs. Best validation loss: 78198.6836\n",
      "Training model for hour 5\n",
      "Epoch [50/250], Training Loss: 876123.6667, Validation Loss: 310263.9219\n",
      "Epoch [100/250], Training Loss: 854591.5556, Validation Loss: 215389.6484\n",
      "Epoch [150/250], Training Loss: 744361.0799, Validation Loss: 155326.7500\n",
      "Epoch [200/250], Training Loss: 577115.0903, Validation Loss: 119159.6289\n",
      "Epoch [250/250], Training Loss: 598400.7326, Validation Loss: 104325.9375\n",
      "Training stopped after 249 epochs. Best validation loss: 104288.4453\n",
      "Epoch [50/250], Training Loss: 876123.5000, Validation Loss: 310263.9219\n",
      "Epoch [100/250], Training Loss: 855072.2431, Validation Loss: 215706.0312\n",
      "Epoch [150/250], Training Loss: 744513.9826, Validation Loss: 155561.2969\n",
      "Epoch [200/250], Training Loss: 574301.6597, Validation Loss: 121937.8203\n",
      "Epoch [250/250], Training Loss: 597285.0660, Validation Loss: 101500.6914\n",
      "Training stopped after 249 epochs. Best validation loss: 101500.6914\n",
      "Epoch [50/250], Training Loss: 876123.4514, Validation Loss: 310263.9531\n",
      "Epoch [100/250], Training Loss: 855338.0764, Validation Loss: 215664.8828\n",
      "Epoch [150/250], Training Loss: 744048.4271, Validation Loss: 156155.6016\n",
      "Epoch [200/250], Training Loss: 575527.5660, Validation Loss: 122968.2422\n",
      "Epoch [250/250], Training Loss: 597460.8507, Validation Loss: 110163.6523\n",
      "Training stopped after 249 epochs. Best validation loss: 107755.1836\n",
      "Epoch [50/250], Training Loss: 876149.4514, Validation Loss: 310482.1875\n",
      "Epoch [100/250], Training Loss: 854588.6667, Validation Loss: 215776.1875\n",
      "Epoch [150/250], Training Loss: 743517.2292, Validation Loss: 154845.0000\n",
      "Epoch [200/250], Training Loss: 575072.3056, Validation Loss: 119731.3945\n",
      "Early stopping after 234 epochs. Best validation loss: 108982.1562\n",
      "Epoch [50/250], Training Loss: 876148.8819, Validation Loss: 310482.0000\n",
      "Epoch [100/250], Training Loss: 857768.0972, Validation Loss: 216225.9688\n",
      "Epoch [150/250], Training Loss: 744617.1181, Validation Loss: 155621.1328\n",
      "Epoch [200/250], Training Loss: 576337.0764, Validation Loss: 122365.2734\n",
      "Epoch [250/250], Training Loss: 599388.8125, Validation Loss: 107559.6484\n",
      "Training stopped after 249 epochs. Best validation loss: 105244.3672\n",
      "Epoch [50/250], Training Loss: 876148.8056, Validation Loss: 310481.9531\n",
      "Epoch [100/250], Training Loss: 854578.1736, Validation Loss: 215805.4844\n",
      "Epoch [150/250], Training Loss: 743259.7292, Validation Loss: 154744.1641\n",
      "Epoch [200/250], Training Loss: 574914.0903, Validation Loss: 119181.5859\n",
      "Epoch [250/250], Training Loss: 598041.3889, Validation Loss: 102038.0742\n",
      "Training stopped after 249 epochs. Best validation loss: 102038.0742\n",
      "Epoch [50/250], Training Loss: 876097.4167, Validation Loss: 310482.1094\n",
      "Epoch [100/250], Training Loss: 856966.5208, Validation Loss: 216201.0156\n",
      "Epoch [150/250], Training Loss: 744040.7431, Validation Loss: 155714.3750\n",
      "Epoch [200/250], Training Loss: 573823.8194, Validation Loss: 122846.1523\n",
      "Epoch [250/250], Training Loss: 595984.8785, Validation Loss: 105709.3672\n",
      "Training stopped after 249 epochs. Best validation loss: 105709.3672\n",
      "Epoch [50/250], Training Loss: 876096.4514, Validation Loss: 310481.9688\n",
      "Epoch [100/250], Training Loss: 857635.0417, Validation Loss: 216226.3516\n",
      "Epoch [150/250], Training Loss: 743366.9826, Validation Loss: 155523.4922\n",
      "Epoch [200/250], Training Loss: 574800.1181, Validation Loss: 120065.7500\n",
      "Epoch [250/250], Training Loss: 597415.4826, Validation Loss: 100552.4922\n",
      "Training stopped after 249 epochs. Best validation loss: 100552.4922\n",
      "Epoch [50/250], Training Loss: 876096.3472, Validation Loss: 310481.9844\n",
      "Epoch [100/250], Training Loss: 857640.4236, Validation Loss: 216224.8516\n",
      "Epoch [150/250], Training Loss: 743911.3299, Validation Loss: 155137.3516\n",
      "Epoch [200/250], Training Loss: 573666.9965, Validation Loss: 124642.8359\n",
      "Epoch [250/250], Training Loss: 595386.1111, Validation Loss: 108311.0234\n",
      "Training stopped after 249 epochs. Best validation loss: 107569.1133\n",
      "Epoch [50/250], Training Loss: 811942.5000, Validation Loss: 214185.4531\n",
      "Epoch [100/250], Training Loss: 607313.0347, Validation Loss: 121296.4180\n",
      "Epoch [150/250], Training Loss: 528808.2674, Validation Loss: 104417.6406\n",
      "Early stopping after 157 epochs. Best validation loss: 101604.0898\n",
      "Epoch [50/250], Training Loss: 812088.0347, Validation Loss: 214495.5469\n",
      "Epoch [100/250], Training Loss: 606519.3924, Validation Loss: 121378.6914\n",
      "Epoch [150/250], Training Loss: 524758.3576, Validation Loss: 97019.8125\n",
      "Early stopping after 168 epochs. Best validation loss: 91173.7500\n",
      "Epoch [50/250], Training Loss: 812422.4861, Validation Loss: 214204.5234\n",
      "Epoch [100/250], Training Loss: 606444.8889, Validation Loss: 122007.2500\n",
      "Early stopping after 146 epochs. Best validation loss: 100146.9883\n",
      "Epoch [50/250], Training Loss: 812672.8542, Validation Loss: 214532.3906\n",
      "Epoch [100/250], Training Loss: 613095.6285, Validation Loss: 126061.8672\n",
      "Epoch [150/250], Training Loss: 534726.5174, Validation Loss: 105501.6211\n",
      "Early stopping after 154 epochs. Best validation loss: 100551.5508\n",
      "Epoch [50/250], Training Loss: 810217.2569, Validation Loss: 214276.0234\n",
      "Epoch [100/250], Training Loss: 605816.6319, Validation Loss: 120304.8320\n",
      "Epoch [150/250], Training Loss: 525457.9479, Validation Loss: 103144.2227\n",
      "Early stopping after 161 epochs. Best validation loss: 98699.9922\n",
      "Epoch [50/250], Training Loss: 811342.1806, Validation Loss: 215090.0000\n",
      "Epoch [100/250], Training Loss: 606104.9236, Validation Loss: 120820.7617\n",
      "Epoch [150/250], Training Loss: 526363.7153, Validation Loss: 98083.1172\n",
      "Early stopping after 179 epochs. Best validation loss: 96048.6172\n",
      "Epoch [50/250], Training Loss: 812629.0833, Validation Loss: 215162.2656\n",
      "Epoch [100/250], Training Loss: 610771.9861, Validation Loss: 122449.6250\n",
      "Epoch [150/250], Training Loss: 530457.5972, Validation Loss: 102996.3516\n",
      "Early stopping after 168 epochs. Best validation loss: 95728.6797\n",
      "Epoch [50/250], Training Loss: 812216.2500, Validation Loss: 214859.8047\n",
      "Epoch [100/250], Training Loss: 607805.5139, Validation Loss: 122796.5703\n",
      "Epoch [150/250], Training Loss: 527225.3854, Validation Loss: 106241.1914\n",
      "Early stopping after 152 epochs. Best validation loss: 104888.5352\n",
      "Epoch [50/250], Training Loss: 812202.9097, Validation Loss: 214848.7656\n",
      "Epoch [100/250], Training Loss: 608085.0208, Validation Loss: 121669.2969\n",
      "Epoch [150/250], Training Loss: 527382.1111, Validation Loss: 102853.7344\n",
      "Early stopping after 164 epochs. Best validation loss: 96002.5078\n",
      "Epoch [50/250], Training Loss: 656941.3854, Validation Loss: 121543.7422\n",
      "Early stopping after 81 epochs. Best validation loss: 102105.8516\n",
      "Epoch [50/250], Training Loss: 648917.2986, Validation Loss: 120538.5039\n",
      "Early stopping after 84 epochs. Best validation loss: 100257.3984\n",
      "Epoch [50/250], Training Loss: 651893.7708, Validation Loss: 122905.6328\n",
      "Epoch [100/250], Training Loss: 460297.1337, Validation Loss: 115692.5508\n",
      "Early stopping after 105 epochs. Best validation loss: 100591.2383\n",
      "Epoch [50/250], Training Loss: 646441.8021, Validation Loss: 120683.3828\n",
      "Early stopping after 88 epochs. Best validation loss: 101798.8008\n",
      "Epoch [50/250], Training Loss: 646367.2604, Validation Loss: 122176.6055\n",
      "Early stopping after 97 epochs. Best validation loss: 100731.7383\n",
      "Epoch [50/250], Training Loss: 648248.8819, Validation Loss: 122467.6289\n",
      "Early stopping after 85 epochs. Best validation loss: 104304.9492\n",
      "Epoch [50/250], Training Loss: 645701.9062, Validation Loss: 120875.8594\n",
      "Epoch [100/250], Training Loss: 450778.1233, Validation Loss: 102680.5547\n",
      "Early stopping after 101 epochs. Best validation loss: 96519.1250\n",
      "Epoch [50/250], Training Loss: 646877.9861, Validation Loss: 121570.4141\n",
      "Early stopping after 77 epochs. Best validation loss: 103804.5742\n",
      "Epoch [50/250], Training Loss: 650696.4965, Validation Loss: 123992.3320\n",
      "Early stopping after 79 epochs. Best validation loss: 104218.8750\n",
      "Training model for hour 6\n",
      "Epoch [50/250], Training Loss: 1019157.3542, Validation Loss: 276445.8203\n",
      "Epoch [100/250], Training Loss: 976901.5833, Validation Loss: 184923.9219\n",
      "Epoch [150/250], Training Loss: 851484.7569, Validation Loss: 127605.6328\n",
      "Epoch [200/250], Training Loss: 666347.1424, Validation Loss: 93645.2734\n",
      "Epoch [250/250], Training Loss: 689482.5556, Validation Loss: 78390.4766\n",
      "Training stopped after 249 epochs. Best validation loss: 78076.2324\n",
      "Epoch [50/250], Training Loss: 1019165.4514, Validation Loss: 276446.1406\n",
      "Epoch [100/250], Training Loss: 976899.3194, Validation Loss: 184924.6641\n",
      "Epoch [150/250], Training Loss: 851815.6250, Validation Loss: 127853.2891\n",
      "Epoch [200/250], Training Loss: 665828.9410, Validation Loss: 93674.0625\n",
      "Epoch [250/250], Training Loss: 688195.4722, Validation Loss: 81349.2539\n",
      "Training stopped after 249 epochs. Best validation loss: 81032.3281\n",
      "Epoch [50/250], Training Loss: 1019165.3333, Validation Loss: 276446.1406\n",
      "Epoch [100/250], Training Loss: 976900.1944, Validation Loss: 184924.6406\n",
      "Epoch [150/250], Training Loss: 852403.1458, Validation Loss: 128694.3750\n",
      "Epoch [200/250], Training Loss: 665901.6736, Validation Loss: 95112.6328\n",
      "Epoch [250/250], Training Loss: 688547.8056, Validation Loss: 81074.2070\n",
      "Training stopped after 249 epochs. Best validation loss: 80043.7070\n",
      "Epoch [50/250], Training Loss: 1019001.2986, Validation Loss: 276568.6719\n",
      "Epoch [100/250], Training Loss: 975994.1111, Validation Loss: 184978.7266\n",
      "Epoch [150/250], Training Loss: 850106.8125, Validation Loss: 127462.9805\n",
      "Epoch [200/250], Training Loss: 665472.2257, Validation Loss: 94620.7109\n",
      "Epoch [250/250], Training Loss: 687927.0972, Validation Loss: 81429.6562\n",
      "Training stopped after 249 epochs. Best validation loss: 81429.6562\n",
      "Epoch [50/250], Training Loss: 1019001.2083, Validation Loss: 276568.8281\n",
      "Epoch [100/250], Training Loss: 975726.8194, Validation Loss: 184971.2344\n",
      "Epoch [150/250], Training Loss: 850677.7083, Validation Loss: 127750.4492\n",
      "Epoch [200/250], Training Loss: 665833.2292, Validation Loss: 95093.7109\n",
      "Epoch [250/250], Training Loss: 688440.4688, Validation Loss: 78733.5801\n",
      "Training stopped after 249 epochs. Best validation loss: 78559.9453\n",
      "Epoch [50/250], Training Loss: 1019001.2431, Validation Loss: 276568.8750\n",
      "Epoch [100/250], Training Loss: 975843.3333, Validation Loss: 185772.2578\n",
      "Epoch [150/250], Training Loss: 850159.5347, Validation Loss: 126037.1875\n",
      "Epoch [200/250], Training Loss: 664928.7882, Validation Loss: 95644.3320\n",
      "Epoch [250/250], Training Loss: 688067.2049, Validation Loss: 82006.0586\n",
      "Training stopped after 249 epochs. Best validation loss: 81725.0195\n",
      "Epoch [50/250], Training Loss: 1018947.0556, Validation Loss: 276568.2656\n",
      "Epoch [100/250], Training Loss: 976713.2778, Validation Loss: 185024.4453\n",
      "Epoch [150/250], Training Loss: 849927.1944, Validation Loss: 127248.0430\n",
      "Epoch [200/250], Training Loss: 664159.8715, Validation Loss: 93459.2227\n",
      "Epoch [250/250], Training Loss: 686290.7361, Validation Loss: 77311.3223\n",
      "Training stopped after 249 epochs. Best validation loss: 77311.3223\n",
      "Epoch [50/250], Training Loss: 1018946.0278, Validation Loss: 276568.1484\n",
      "Epoch [100/250], Training Loss: 976712.3958, Validation Loss: 185024.2344\n",
      "Epoch [150/250], Training Loss: 850089.6458, Validation Loss: 126546.5781\n",
      "Epoch [200/250], Training Loss: 664271.0625, Validation Loss: 92991.9023\n",
      "Epoch [250/250], Training Loss: 686200.0451, Validation Loss: 77699.7734\n",
      "Training stopped after 249 epochs. Best validation loss: 77699.7734\n",
      "Epoch [50/250], Training Loss: 1018946.0069, Validation Loss: 276568.1797\n",
      "Epoch [100/250], Training Loss: 976712.3472, Validation Loss: 185024.2578\n",
      "Epoch [150/250], Training Loss: 850337.6458, Validation Loss: 127489.1602\n",
      "Epoch [200/250], Training Loss: 664598.0000, Validation Loss: 93217.0039\n",
      "Epoch [250/250], Training Loss: 687614.2396, Validation Loss: 78265.5957\n",
      "Training stopped after 249 epochs. Best validation loss: 77672.6699\n",
      "Epoch [50/250], Training Loss: 913487.2222, Validation Loss: 183033.1172\n",
      "Epoch [100/250], Training Loss: 705607.2292, Validation Loss: 96055.7344\n",
      "Epoch [150/250], Training Loss: 613747.7708, Validation Loss: 82637.6445\n",
      "Early stopping after 154 epochs. Best validation loss: 79167.2891\n",
      "Epoch [50/250], Training Loss: 913035.3819, Validation Loss: 182877.3047\n",
      "Epoch [100/250], Training Loss: 704745.6042, Validation Loss: 95765.3789\n",
      "Epoch [150/250], Training Loss: 613005.9757, Validation Loss: 77596.9785\n",
      "Early stopping after 150 epochs. Best validation loss: 75327.0117\n",
      "Epoch [50/250], Training Loss: 913170.0972, Validation Loss: 183013.1094\n",
      "Epoch [100/250], Training Loss: 710132.3403, Validation Loss: 95189.3594\n",
      "Epoch [150/250], Training Loss: 615706.0278, Validation Loss: 78744.3789\n",
      "Early stopping after 154 epochs. Best validation loss: 77847.0703\n",
      "Epoch [50/250], Training Loss: 913300.8611, Validation Loss: 183368.9375\n",
      "Epoch [100/250], Training Loss: 705914.4444, Validation Loss: 94104.7500\n",
      "Epoch [150/250], Training Loss: 613757.6250, Validation Loss: 74752.8301\n",
      "Early stopping after 151 epochs. Best validation loss: 74470.0156\n",
      "Epoch [50/250], Training Loss: 913292.3125, Validation Loss: 183365.9062\n",
      "Epoch [100/250], Training Loss: 704560.3333, Validation Loss: 94932.8242\n",
      "Early stopping after 147 epochs. Best validation loss: 74206.7246\n",
      "Epoch [50/250], Training Loss: 913304.0972, Validation Loss: 183372.5625\n",
      "Epoch [100/250], Training Loss: 705032.7569, Validation Loss: 96720.3906\n",
      "Epoch [150/250], Training Loss: 612861.2500, Validation Loss: 75989.5801\n",
      "Early stopping after 153 epochs. Best validation loss: 75794.9805\n",
      "Epoch [50/250], Training Loss: 914593.3542, Validation Loss: 184232.5781\n",
      "Epoch [100/250], Training Loss: 705880.8958, Validation Loss: 94574.1016\n",
      "Epoch [150/250], Training Loss: 612257.4792, Validation Loss: 72708.4570\n",
      "Early stopping after 163 epochs. Best validation loss: 72263.3281\n",
      "Epoch [50/250], Training Loss: 914108.7778, Validation Loss: 183932.4766\n",
      "Epoch [100/250], Training Loss: 707451.5417, Validation Loss: 95522.3984\n",
      "Epoch [150/250], Training Loss: 614166.4931, Validation Loss: 74979.9453\n",
      "Early stopping after 176 epochs. Best validation loss: 70673.1953\n",
      "Epoch [50/250], Training Loss: 914080.2778, Validation Loss: 183914.8438\n",
      "Epoch [100/250], Training Loss: 707530.5069, Validation Loss: 95817.8047\n",
      "Epoch [150/250], Training Loss: 613470.6042, Validation Loss: 75261.6348\n",
      "Early stopping after 162 epochs. Best validation loss: 73143.3633\n",
      "Epoch [50/250], Training Loss: 749326.0069, Validation Loss: 97529.8516\n",
      "Early stopping after 93 epochs. Best validation loss: 79594.3789\n",
      "Epoch [50/250], Training Loss: 739635.8576, Validation Loss: 94470.4961\n",
      "Early stopping after 92 epochs. Best validation loss: 71368.0977\n",
      "Epoch [50/250], Training Loss: 742318.2708, Validation Loss: 93994.6719\n",
      "Early stopping after 90 epochs. Best validation loss: 74712.8945\n",
      "Epoch [50/250], Training Loss: 744111.7153, Validation Loss: 96375.7539\n",
      "Early stopping after 91 epochs. Best validation loss: 72035.8398\n",
      "Epoch [50/250], Training Loss: 744944.6424, Validation Loss: 95242.4180\n",
      "Early stopping after 88 epochs. Best validation loss: 73767.0605\n",
      "Epoch [50/250], Training Loss: 739445.6667, Validation Loss: 95634.3555\n",
      "Early stopping after 97 epochs. Best validation loss: 73400.7168\n",
      "Epoch [50/250], Training Loss: 744345.2431, Validation Loss: 96871.1562\n",
      "Early stopping after 95 epochs. Best validation loss: 72233.2148\n",
      "Epoch [50/250], Training Loss: 767757.6667, Validation Loss: 103415.6172\n",
      "Early stopping after 73 epochs. Best validation loss: 80100.7090\n",
      "Epoch [50/250], Training Loss: 780715.5451, Validation Loss: 104780.5742\n",
      "Early stopping after 87 epochs. Best validation loss: 77316.3164\n",
      "Training model for hour 7\n",
      "Epoch [50/250], Training Loss: 939738.9792, Validation Loss: 213630.4531\n",
      "Epoch [100/250], Training Loss: 882104.3681, Validation Loss: 140696.4180\n",
      "Epoch [150/250], Training Loss: 764793.5764, Validation Loss: 99331.6758\n",
      "Epoch [200/250], Training Loss: 602431.8576, Validation Loss: 78418.0195\n",
      "Early stopping after 243 epochs. Best validation loss: 73069.7051\n",
      "Epoch [50/250], Training Loss: 939738.9236, Validation Loss: 213630.5547\n",
      "Epoch [100/250], Training Loss: 882849.9931, Validation Loss: 140865.5898\n",
      "Epoch [150/250], Training Loss: 764539.9167, Validation Loss: 99082.9648\n",
      "Epoch [200/250], Training Loss: 601223.8021, Validation Loss: 75674.6973\n",
      "Early stopping after 227 epochs. Best validation loss: 71148.2207\n",
      "Epoch [50/250], Training Loss: 939738.8611, Validation Loss: 213630.5312\n",
      "Epoch [100/250], Training Loss: 883578.1597, Validation Loss: 141002.8633\n",
      "Epoch [150/250], Training Loss: 764659.2083, Validation Loss: 100129.4414\n",
      "Epoch [200/250], Training Loss: 601981.2708, Validation Loss: 80200.7246\n",
      "Early stopping after 244 epochs. Best validation loss: 73291.0117\n",
      "Epoch [50/250], Training Loss: 939710.6319, Validation Loss: 213760.6016\n",
      "Epoch [100/250], Training Loss: 883152.0972, Validation Loss: 141072.1719\n",
      "Epoch [150/250], Training Loss: 763609.8264, Validation Loss: 99575.5762\n",
      "Epoch [200/250], Training Loss: 601322.9028, Validation Loss: 79835.7402\n",
      "Epoch [250/250], Training Loss: 602351.1944, Validation Loss: 71266.6309\n",
      "Training stopped after 249 epochs. Best validation loss: 71044.7891\n",
      "Epoch [50/250], Training Loss: 939710.1458, Validation Loss: 213760.4531\n",
      "Epoch [100/250], Training Loss: 884138.1597, Validation Loss: 141128.7578\n",
      "Epoch [150/250], Training Loss: 765323.7847, Validation Loss: 100467.1934\n",
      "Epoch [200/250], Training Loss: 601940.5833, Validation Loss: 81776.8477\n",
      "Early stopping after 222 epochs. Best validation loss: 80607.7148\n",
      "Epoch [50/250], Training Loss: 939709.9931, Validation Loss: 213760.4297\n",
      "Epoch [100/250], Training Loss: 884394.5069, Validation Loss: 141146.9023\n",
      "Epoch [150/250], Training Loss: 764644.2986, Validation Loss: 100882.8652\n",
      "Epoch [200/250], Training Loss: 602546.9479, Validation Loss: 81377.5371\n",
      "Early stopping after 213 epochs. Best validation loss: 77908.1289\n",
      "Epoch [50/250], Training Loss: 939658.1319, Validation Loss: 213760.5703\n",
      "Epoch [100/250], Training Loss: 884434.0833, Validation Loss: 141157.5234\n",
      "Epoch [150/250], Training Loss: 763816.3819, Validation Loss: 99273.7598\n",
      "Epoch [200/250], Training Loss: 600441.5625, Validation Loss: 80023.6641\n",
      "Epoch [250/250], Training Loss: 601307.2396, Validation Loss: 69899.7285\n",
      "Training stopped after 249 epochs. Best validation loss: 69594.2305\n",
      "Epoch [50/250], Training Loss: 939657.1944, Validation Loss: 213760.5156\n",
      "Epoch [100/250], Training Loss: 884439.6528, Validation Loss: 141156.2461\n",
      "Epoch [150/250], Training Loss: 763323.4028, Validation Loss: 99116.8984\n",
      "Epoch [200/250], Training Loss: 601141.9444, Validation Loss: 77799.6309\n",
      "Early stopping after 238 epochs. Best validation loss: 69885.2988\n",
      "Epoch [50/250], Training Loss: 939657.1111, Validation Loss: 213760.5312\n",
      "Epoch [100/250], Training Loss: 884439.6944, Validation Loss: 141156.2539\n",
      "Epoch [150/250], Training Loss: 764085.6389, Validation Loss: 100129.3379\n",
      "Epoch [200/250], Training Loss: 601371.8056, Validation Loss: 75741.4609\n",
      "Epoch [250/250], Training Loss: 601761.9201, Validation Loss: 71470.8945\n",
      "Early stopping after 249 epochs. Best validation loss: 70667.1973\n",
      "Epoch [50/250], Training Loss: 818605.3194, Validation Loss: 139921.9453\n",
      "Epoch [100/250], Training Loss: 639844.2500, Validation Loss: 78514.0137\n",
      "Early stopping after 131 epochs. Best validation loss: 70871.7051\n",
      "Epoch [50/250], Training Loss: 818604.5972, Validation Loss: 139921.8867\n",
      "Epoch [100/250], Training Loss: 639246.6424, Validation Loss: 78891.6523\n",
      "Early stopping after 121 epochs. Best validation loss: 71669.6582\n",
      "Epoch [50/250], Training Loss: 818604.6875, Validation Loss: 139921.8945\n",
      "Epoch [100/250], Training Loss: 638868.1354, Validation Loss: 76789.8555\n",
      "Early stopping after 130 epochs. Best validation loss: 70147.7676\n",
      "Epoch [50/250], Training Loss: 818050.1875, Validation Loss: 140466.3789\n",
      "Epoch [100/250], Training Loss: 637609.0278, Validation Loss: 78717.4590\n",
      "Early stopping after 138 epochs. Best validation loss: 69940.4648\n",
      "Epoch [50/250], Training Loss: 817685.3889, Validation Loss: 139614.4961\n",
      "Epoch [100/250], Training Loss: 638452.3229, Validation Loss: 77801.9258\n",
      "Early stopping after 113 epochs. Best validation loss: 76574.7500\n",
      "Epoch [50/250], Training Loss: 815246.5000, Validation Loss: 138365.1133\n",
      "Epoch [100/250], Training Loss: 635368.3854, Validation Loss: 77086.1270\n",
      "Early stopping after 138 epochs. Best validation loss: 69932.8223\n",
      "Epoch [50/250], Training Loss: 818926.1181, Validation Loss: 140351.3398\n",
      "Epoch [100/250], Training Loss: 639525.6354, Validation Loss: 79468.9219\n",
      "Early stopping after 137 epochs. Best validation loss: 72894.2070\n",
      "Epoch [50/250], Training Loss: 818172.6806, Validation Loss: 139727.9961\n",
      "Epoch [100/250], Training Loss: 641098.0729, Validation Loss: 79762.9805\n",
      "Early stopping after 130 epochs. Best validation loss: 68153.0488\n",
      "Epoch [50/250], Training Loss: 818949.8403, Validation Loss: 140363.1562\n",
      "Epoch [100/250], Training Loss: 640562.1875, Validation Loss: 81981.9922\n",
      "Early stopping after 145 epochs. Best validation loss: 73620.9707\n",
      "Epoch [50/250], Training Loss: 683191.2604, Validation Loss: 83603.7129\n",
      "Early stopping after 74 epochs. Best validation loss: 75322.6680\n",
      "Epoch [50/250], Training Loss: 670651.4583, Validation Loss: 80756.5996\n",
      "Early stopping after 71 epochs. Best validation loss: 71133.6953\n",
      "Epoch [50/250], Training Loss: 670671.7917, Validation Loss: 79112.8613\n",
      "Early stopping after 71 epochs. Best validation loss: 69607.1191\n",
      "Epoch [50/250], Training Loss: 672494.2951, Validation Loss: 81782.4629\n",
      "Early stopping after 62 epochs. Best validation loss: 78538.3340\n",
      "Epoch [50/250], Training Loss: 673791.7569, Validation Loss: 82443.1934\n",
      "Early stopping after 78 epochs. Best validation loss: 70275.8477\n",
      "Epoch [50/250], Training Loss: 674624.4444, Validation Loss: 80404.6133\n",
      "Early stopping after 65 epochs. Best validation loss: 74524.1797\n",
      "Epoch [50/250], Training Loss: 699225.5799, Validation Loss: 88118.3906\n",
      "Early stopping after 76 epochs. Best validation loss: 72167.5527\n",
      "Epoch [50/250], Training Loss: 683281.1840, Validation Loss: 84808.4375\n",
      "Early stopping after 72 epochs. Best validation loss: 76508.4121\n",
      "Epoch [50/250], Training Loss: 669173.6215, Validation Loss: 81063.5508\n",
      "Early stopping after 74 epochs. Best validation loss: 73521.8672\n",
      "Training model for hour 8\n",
      "Epoch [50/250], Training Loss: 805068.3750, Validation Loss: 162869.7031\n",
      "Epoch [100/250], Training Loss: 734208.5590, Validation Loss: 110253.2656\n",
      "Epoch [150/250], Training Loss: 630122.7257, Validation Loss: 82807.2168\n",
      "Early stopping after 197 epochs. Best validation loss: 74249.6914\n",
      "Epoch [50/250], Training Loss: 805024.4792, Validation Loss: 162855.1602\n",
      "Epoch [100/250], Training Loss: 733144.3993, Validation Loss: 110196.9512\n",
      "Epoch [150/250], Training Loss: 629905.6007, Validation Loss: 84186.5078\n",
      "Early stopping after 184 epochs. Best validation loss: 78306.1855\n",
      "Epoch [50/250], Training Loss: 804978.6250, Validation Loss: 162858.9922\n",
      "Epoch [100/250], Training Loss: 731567.7986, Validation Loss: 109940.1348\n",
      "Epoch [150/250], Training Loss: 629417.5590, Validation Loss: 82913.8945\n",
      "Epoch [200/250], Training Loss: 505134.1424, Validation Loss: 72842.5820\n",
      "Early stopping after 204 epochs. Best validation loss: 72393.3477\n",
      "Epoch [50/250], Training Loss: 805028.1493, Validation Loss: 163007.0117\n",
      "Epoch [100/250], Training Loss: 731734.1007, Validation Loss: 109952.9199\n",
      "Epoch [150/250], Training Loss: 629434.7396, Validation Loss: 83817.6641\n",
      "Epoch [200/250], Training Loss: 505066.0764, Validation Loss: 75043.1582\n",
      "Early stopping after 221 epochs. Best validation loss: 71594.1113\n",
      "Epoch [50/250], Training Loss: 805027.7431, Validation Loss: 163006.9648\n",
      "Epoch [100/250], Training Loss: 731570.4583, Validation Loss: 109915.2402\n",
      "Epoch [150/250], Training Loss: 628810.1007, Validation Loss: 83443.6172\n",
      "Epoch [200/250], Training Loss: 504466.1701, Validation Loss: 72316.1543\n",
      "Early stopping after 217 epochs. Best validation loss: 69750.5742\n",
      "Epoch [50/250], Training Loss: 805027.8194, Validation Loss: 163006.9805\n",
      "Epoch [100/250], Training Loss: 731729.7361, Validation Loss: 110159.3906\n",
      "Epoch [150/250], Training Loss: 629773.2083, Validation Loss: 85434.5000\n",
      "Epoch [200/250], Training Loss: 505251.8750, Validation Loss: 77368.5469\n",
      "Early stopping after 224 epochs. Best validation loss: 73917.6699\n",
      "Epoch [50/250], Training Loss: 804973.9792, Validation Loss: 163008.2344\n",
      "Epoch [100/250], Training Loss: 732552.7118, Validation Loss: 110284.0469\n",
      "Epoch [150/250], Training Loss: 629792.2188, Validation Loss: 86017.8906\n",
      "Early stopping after 193 epochs. Best validation loss: 78290.1504\n",
      "Epoch [50/250], Training Loss: 804973.2674, Validation Loss: 163008.2812\n",
      "Epoch [100/250], Training Loss: 732898.4028, Validation Loss: 110296.3848\n",
      "Epoch [150/250], Training Loss: 629427.1215, Validation Loss: 82006.8574\n",
      "Early stopping after 184 epochs. Best validation loss: 76090.3457\n",
      "Epoch [50/250], Training Loss: 804973.1042, Validation Loss: 163008.2422\n",
      "Epoch [100/250], Training Loss: 732413.1354, Validation Loss: 110330.4238\n",
      "Epoch [150/250], Training Loss: 629107.0139, Validation Loss: 84697.1016\n",
      "Epoch [200/250], Training Loss: 504280.7465, Validation Loss: 72141.6309\n",
      "Early stopping after 223 epochs. Best validation loss: 71164.7363\n",
      "Epoch [50/250], Training Loss: 682777.4757, Validation Loss: 109596.9980\n",
      "Early stopping after 97 epochs. Best validation loss: 75475.0449\n",
      "Epoch [50/250], Training Loss: 682784.4410, Validation Loss: 109597.3066\n",
      "Epoch [100/250], Training Loss: 537790.8368, Validation Loss: 70263.2012\n",
      "Early stopping after 113 epochs. Best validation loss: 67237.3496\n",
      "Epoch [50/250], Training Loss: 682781.6285, Validation Loss: 109597.1719\n",
      "Epoch [100/250], Training Loss: 535963.4826, Validation Loss: 73666.8848\n",
      "Early stopping after 121 epochs. Best validation loss: 69806.0488\n",
      "Epoch [50/250], Training Loss: 682947.9167, Validation Loss: 109716.0137\n",
      "Epoch [100/250], Training Loss: 534335.2257, Validation Loss: 72628.3652\n",
      "Early stopping after 109 epochs. Best validation loss: 72628.3652\n",
      "Epoch [50/250], Training Loss: 682911.4896, Validation Loss: 109803.1973\n",
      "Epoch [100/250], Training Loss: 534281.7361, Validation Loss: 74878.8223\n",
      "Early stopping after 115 epochs. Best validation loss: 73043.1973\n",
      "Epoch [50/250], Training Loss: 683135.9479, Validation Loss: 109865.4160\n",
      "Epoch [100/250], Training Loss: 534754.5486, Validation Loss: 75765.9336\n",
      "Early stopping after 102 epochs. Best validation loss: 75107.3867\n",
      "Epoch [50/250], Training Loss: 682576.8576, Validation Loss: 109722.9883\n",
      "Epoch [100/250], Training Loss: 570151.9826, Validation Loss: 86496.8125\n",
      "Early stopping after 102 epochs. Best validation loss: 85641.4023\n",
      "Epoch [50/250], Training Loss: 682155.5104, Validation Loss: 109570.8203\n",
      "Epoch [100/250], Training Loss: 537342.5799, Validation Loss: 72873.6074\n",
      "Early stopping after 111 epochs. Best validation loss: 69701.2305\n",
      "Epoch [50/250], Training Loss: 682116.4062, Validation Loss: 109713.9668\n",
      "Epoch [100/250], Training Loss: 539229.7361, Validation Loss: 76156.3359\n",
      "Early stopping after 121 epochs. Best validation loss: 75251.6172\n",
      "Epoch [50/250], Training Loss: 549872.0694, Validation Loss: 76395.7500\n",
      "Early stopping after 78 epochs. Best validation loss: 69630.6914\n",
      "Epoch [50/250], Training Loss: 550622.6562, Validation Loss: 75408.9688\n",
      "Early stopping after 71 epochs. Best validation loss: 67482.2500\n",
      "Epoch [50/250], Training Loss: 552809.3750, Validation Loss: 77626.4297\n",
      "Early stopping after 71 epochs. Best validation loss: 64354.8516\n",
      "Epoch [50/250], Training Loss: 548791.0417, Validation Loss: 75608.9883\n",
      "Early stopping after 61 epochs. Best validation loss: 74456.7227\n",
      "Epoch [50/250], Training Loss: 555905.8750, Validation Loss: 72745.6914\n",
      "Early stopping after 65 epochs. Best validation loss: 72712.9238\n",
      "Epoch [50/250], Training Loss: 553686.8333, Validation Loss: 74751.5293\n",
      "Early stopping after 61 epochs. Best validation loss: 69984.3340\n",
      "Epoch [50/250], Training Loss: 560255.2604, Validation Loss: 81887.2617\n",
      "Early stopping after 58 epochs. Best validation loss: 75397.3047\n",
      "Epoch [50/250], Training Loss: 554492.2188, Validation Loss: 78601.8594\n",
      "Early stopping after 71 epochs. Best validation loss: 71597.9570\n",
      "Epoch [50/250], Training Loss: 589650.2639, Validation Loss: 86833.1445\n",
      "Early stopping after 79 epochs. Best validation loss: 71029.4219\n",
      "Training model for hour 9\n",
      "Epoch [50/250], Training Loss: 701248.3715, Validation Loss: 132795.9297\n",
      "Epoch [100/250], Training Loss: 628009.9340, Validation Loss: 93508.7715\n",
      "Epoch [150/250], Training Loss: 530926.9410, Validation Loss: 77723.0078\n",
      "Early stopping after 194 epochs. Best validation loss: 74951.1641\n",
      "Epoch [50/250], Training Loss: 701248.5625, Validation Loss: 132796.0254\n",
      "Epoch [100/250], Training Loss: 627714.7396, Validation Loss: 93469.2695\n",
      "Epoch [150/250], Training Loss: 531928.0590, Validation Loss: 77125.7246\n",
      "Early stopping after 195 epochs. Best validation loss: 73823.7812\n",
      "Epoch [50/250], Training Loss: 701248.7257, Validation Loss: 132796.0332\n",
      "Epoch [100/250], Training Loss: 628635.5174, Validation Loss: 93614.3691\n",
      "Epoch [150/250], Training Loss: 531829.8542, Validation Loss: 76005.9004\n",
      "Early stopping after 171 epochs. Best validation loss: 72815.0625\n",
      "Epoch [50/250], Training Loss: 701214.7812, Validation Loss: 132891.0645\n",
      "Epoch [100/250], Training Loss: 627693.6285, Validation Loss: 93569.4297\n",
      "Epoch [150/250], Training Loss: 530857.5486, Validation Loss: 79542.1699\n",
      "Early stopping after 194 epochs. Best validation loss: 67904.6562\n",
      "Epoch [50/250], Training Loss: 701214.5174, Validation Loss: 132891.1055\n",
      "Epoch [100/250], Training Loss: 627530.1632, Validation Loss: 93064.9238\n",
      "Epoch [150/250], Training Loss: 531167.8681, Validation Loss: 76867.0391\n",
      "Early stopping after 193 epochs. Best validation loss: 72257.6973\n",
      "Epoch [50/250], Training Loss: 701214.4688, Validation Loss: 132891.1035\n",
      "Epoch [100/250], Training Loss: 627573.7431, Validation Loss: 93562.5312\n",
      "Epoch [150/250], Training Loss: 530585.7917, Validation Loss: 76873.5430\n",
      "Early stopping after 195 epochs. Best validation loss: 72729.5840\n",
      "Epoch [50/250], Training Loss: 701167.1493, Validation Loss: 132891.9316\n",
      "Epoch [100/250], Training Loss: 628344.9514, Validation Loss: 93668.6738\n",
      "Epoch [150/250], Training Loss: 531852.5174, Validation Loss: 79662.7012\n",
      "Early stopping after 181 epochs. Best validation loss: 72337.0020\n",
      "Epoch [50/250], Training Loss: 701166.3021, Validation Loss: 132891.8926\n",
      "Epoch [100/250], Training Loss: 628329.6528, Validation Loss: 93663.8281\n",
      "Epoch [150/250], Training Loss: 530584.9826, Validation Loss: 77530.8164\n",
      "Epoch [200/250], Training Loss: 430791.4549, Validation Loss: 72758.4980\n",
      "Early stopping after 202 epochs. Best validation loss: 70342.8457\n",
      "Epoch [50/250], Training Loss: 701166.1146, Validation Loss: 132891.8730\n",
      "Epoch [100/250], Training Loss: 628236.6875, Validation Loss: 93663.7988\n",
      "Epoch [150/250], Training Loss: 530838.8507, Validation Loss: 79421.9609\n",
      "Early stopping after 189 epochs. Best validation loss: 72689.4609\n",
      "Epoch [50/250], Training Loss: 586778.7778, Validation Loss: 93246.0156\n",
      "Early stopping after 98 epochs. Best validation loss: 71996.8633\n",
      "Epoch [50/250], Training Loss: 584028.1042, Validation Loss: 93099.6855\n",
      "Epoch [100/250], Training Loss: 457262.7465, Validation Loss: 72691.4766\n",
      "Early stopping after 107 epochs. Best validation loss: 71262.0820\n",
      "Epoch [50/250], Training Loss: 584326.3021, Validation Loss: 93128.1465\n",
      "Epoch [100/250], Training Loss: 457139.7292, Validation Loss: 74526.9531\n",
      "Early stopping after 116 epochs. Best validation loss: 69411.4707\n",
      "Epoch [50/250], Training Loss: 585006.1042, Validation Loss: 93364.5215\n",
      "Epoch [100/250], Training Loss: 456222.6806, Validation Loss: 77914.8594\n",
      "Early stopping after 104 epochs. Best validation loss: 74803.5039\n",
      "Epoch [50/250], Training Loss: 585859.7639, Validation Loss: 92940.9355\n",
      "Early stopping after 98 epochs. Best validation loss: 72264.7129\n",
      "Epoch [50/250], Training Loss: 584495.0069, Validation Loss: 92596.4590\n",
      "Epoch [100/250], Training Loss: 455732.9097, Validation Loss: 74909.1758\n",
      "Early stopping after 103 epochs. Best validation loss: 72681.0137\n",
      "Epoch [50/250], Training Loss: 587556.2049, Validation Loss: 93911.5723\n",
      "Epoch [100/250], Training Loss: 460940.8333, Validation Loss: 74499.5352\n",
      "Early stopping after 105 epochs. Best validation loss: 71940.3184\n",
      "Epoch [50/250], Training Loss: 587225.0972, Validation Loss: 93815.4609\n",
      "Epoch [100/250], Training Loss: 459449.1389, Validation Loss: 76087.8984\n",
      "Early stopping after 112 epochs. Best validation loss: 70536.7500\n",
      "Epoch [50/250], Training Loss: 587505.2326, Validation Loss: 93895.3535\n",
      "Epoch [100/250], Training Loss: 459382.2292, Validation Loss: 74450.8555\n",
      "Early stopping after 100 epochs. Best validation loss: 74086.2969\n",
      "Epoch [50/250], Training Loss: 468393.6910, Validation Loss: 78602.8242\n",
      "Early stopping after 78 epochs. Best validation loss: 68062.6250\n",
      "Epoch [50/250], Training Loss: 468413.3837, Validation Loss: 78505.2852\n",
      "Early stopping after 54 epochs. Best validation loss: 73144.2695\n",
      "Epoch [50/250], Training Loss: 469984.1997, Validation Loss: 86744.6758\n",
      "Early stopping after 56 epochs. Best validation loss: 76918.5547\n",
      "Epoch [50/250], Training Loss: 472022.0712, Validation Loss: 79002.9023\n",
      "Early stopping after 71 epochs. Best validation loss: 75677.4727\n",
      "Epoch [50/250], Training Loss: 465424.2205, Validation Loss: 75042.4219\n",
      "Early stopping after 51 epochs. Best validation loss: 73857.0898\n",
      "Epoch [50/250], Training Loss: 467841.5833, Validation Loss: 70978.1602\n",
      "Early stopping after 55 epochs. Best validation loss: 68175.1348\n",
      "Epoch [50/250], Training Loss: 471714.9757, Validation Loss: 80235.6680\n",
      "Early stopping after 55 epochs. Best validation loss: 75350.5312\n",
      "Epoch [50/250], Training Loss: 480992.8507, Validation Loss: 81866.9844\n",
      "Early stopping after 52 epochs. Best validation loss: 79773.3516\n",
      "Epoch [50/250], Training Loss: 467155.2118, Validation Loss: 77192.0156\n",
      "Early stopping after 65 epochs. Best validation loss: 71116.3203\n",
      "Training model for hour 10\n",
      "Epoch [50/250], Training Loss: 623204.4792, Validation Loss: 116679.5234\n",
      "Epoch [100/250], Training Loss: 554616.8854, Validation Loss: 86531.4609\n",
      "Epoch [150/250], Training Loss: 472951.1042, Validation Loss: 74860.1367\n",
      "Early stopping after 158 epochs. Best validation loss: 73605.8691\n",
      "Epoch [50/250], Training Loss: 623204.5729, Validation Loss: 116679.6699\n",
      "Epoch [100/250], Training Loss: 554856.7778, Validation Loss: 86602.4609\n",
      "Epoch [150/250], Training Loss: 473311.9792, Validation Loss: 77398.0469\n",
      "Early stopping after 153 epochs. Best validation loss: 75692.4844\n",
      "Epoch [50/250], Training Loss: 623204.5243, Validation Loss: 116679.6699\n",
      "Epoch [100/250], Training Loss: 555139.6910, Validation Loss: 86543.7773\n",
      "Epoch [150/250], Training Loss: 472606.2569, Validation Loss: 74685.4062\n",
      "Early stopping after 176 epochs. Best validation loss: 72112.5605\n",
      "Epoch [50/250], Training Loss: 623163.1042, Validation Loss: 116755.2812\n",
      "Epoch [100/250], Training Loss: 553482.7431, Validation Loss: 85864.3984\n",
      "Epoch [150/250], Training Loss: 473106.9444, Validation Loss: 79541.3164\n",
      "Early stopping after 165 epochs. Best validation loss: 75639.7656\n",
      "Epoch [50/250], Training Loss: 623162.7986, Validation Loss: 116755.2832\n",
      "Epoch [100/250], Training Loss: 556332.8681, Validation Loss: 86649.2324\n",
      "Early stopping after 142 epochs. Best validation loss: 73282.3867\n",
      "Epoch [50/250], Training Loss: 623162.7604, Validation Loss: 116755.2832\n",
      "Epoch [100/250], Training Loss: 558377.9965, Validation Loss: 86797.3145\n",
      "Epoch [150/250], Training Loss: 478339.1667, Validation Loss: 76444.8711\n",
      "Early stopping after 195 epochs. Best validation loss: 70605.5137\n",
      "Epoch [50/250], Training Loss: 623112.1181, Validation Loss: 116753.9453\n",
      "Epoch [100/250], Training Loss: 554938.1181, Validation Loss: 86646.8496\n",
      "Epoch [150/250], Training Loss: 472621.8438, Validation Loss: 71102.1738\n",
      "Early stopping after 152 epochs. Best validation loss: 65683.8867\n",
      "Epoch [50/250], Training Loss: 623110.9792, Validation Loss: 116753.7852\n",
      "Epoch [100/250], Training Loss: 555459.9271, Validation Loss: 86673.0938\n",
      "Epoch [150/250], Training Loss: 472329.0104, Validation Loss: 75179.9121\n",
      "Early stopping after 170 epochs. Best validation loss: 72779.4141\n",
      "Epoch [50/250], Training Loss: 623110.8993, Validation Loss: 116753.7930\n",
      "Epoch [100/250], Training Loss: 555711.1319, Validation Loss: 86708.7305\n",
      "Epoch [150/250], Training Loss: 473111.8924, Validation Loss: 79919.6250\n",
      "Early stopping after 149 epochs. Best validation loss: 78834.6914\n",
      "Epoch [50/250], Training Loss: 518893.1319, Validation Loss: 86645.8574\n",
      "Early stopping after 78 epochs. Best validation loss: 74747.6309\n",
      "Epoch [50/250], Training Loss: 522035.4375, Validation Loss: 86380.2441\n",
      "Early stopping after 86 epochs. Best validation loss: 77499.4375\n",
      "Epoch [50/250], Training Loss: 519859.8819, Validation Loss: 86279.0723\n",
      "Early stopping after 82 epochs. Best validation loss: 75827.2559\n",
      "Epoch [50/250], Training Loss: 517810.1771, Validation Loss: 86023.2715\n",
      "Epoch [100/250], Training Loss: 400902.6076, Validation Loss: 73526.3867\n",
      "Early stopping after 113 epochs. Best validation loss: 65934.1738\n",
      "Epoch [50/250], Training Loss: 518888.8264, Validation Loss: 86433.5566\n",
      "Early stopping after 82 epochs. Best validation loss: 72430.5605\n",
      "Epoch [50/250], Training Loss: 518745.7049, Validation Loss: 86380.1973\n",
      "Early stopping after 97 epochs. Best validation loss: 69649.3340\n",
      "Epoch [50/250], Training Loss: 522451.6111, Validation Loss: 86680.4746\n",
      "Epoch [100/250], Training Loss: 404441.6944, Validation Loss: 75432.6172\n",
      "Early stopping after 115 epochs. Best validation loss: 75014.0273\n",
      "Epoch [50/250], Training Loss: 519894.9861, Validation Loss: 86579.0918\n",
      "Epoch [100/250], Training Loss: 403453.6302, Validation Loss: 72975.0625\n",
      "Early stopping after 105 epochs. Best validation loss: 69142.0645\n",
      "Epoch [50/250], Training Loss: 522597.6979, Validation Loss: 86716.7402\n",
      "Early stopping after 80 epochs. Best validation loss: 75258.6523\n",
      "Epoch [50/250], Training Loss: 419342.9931, Validation Loss: 75042.2930\n",
      "Early stopping after 77 epochs. Best validation loss: 62438.6621\n",
      "Epoch [50/250], Training Loss: 415562.0052, Validation Loss: 81479.8398\n",
      "Early stopping after 55 epochs. Best validation loss: 69917.7637\n",
      "Epoch [50/250], Training Loss: 414439.9184, Validation Loss: 77850.8828\n",
      "Early stopping after 66 epochs. Best validation loss: 68562.5547\n",
      "Early stopping after 44 epochs. Best validation loss: 79644.1582\n",
      "Epoch [50/250], Training Loss: 413905.3681, Validation Loss: 77395.1367\n",
      "Early stopping after 51 epochs. Best validation loss: 74616.3203\n",
      "Epoch [50/250], Training Loss: 412822.9896, Validation Loss: 79872.9844\n",
      "Early stopping after 50 epochs. Best validation loss: 73246.3770\n",
      "Epoch [50/250], Training Loss: 428467.9219, Validation Loss: 79604.9609\n",
      "Early stopping after 74 epochs. Best validation loss: 74915.6641\n",
      "Epoch [50/250], Training Loss: 422904.0747, Validation Loss: 80983.9766\n",
      "Early stopping after 62 epochs. Best validation loss: 75523.3555\n",
      "Epoch [50/250], Training Loss: 420668.8681, Validation Loss: 70335.2188\n",
      "Early stopping after 80 epochs. Best validation loss: 63810.3926\n",
      "Training model for hour 11\n",
      "Epoch [50/250], Training Loss: 563511.4062, Validation Loss: 104881.5273\n",
      "Epoch [100/250], Training Loss: 499312.0417, Validation Loss: 81736.5801\n",
      "Early stopping after 131 epochs. Best validation loss: 70998.6230\n",
      "Epoch [50/250], Training Loss: 563787.5486, Validation Loss: 104882.4180\n",
      "Epoch [100/250], Training Loss: 504265.6181, Validation Loss: 81295.3496\n",
      "Early stopping after 124 epochs. Best validation loss: 73877.4648\n",
      "Epoch [50/250], Training Loss: 563750.3368, Validation Loss: 104881.7812\n",
      "Epoch [100/250], Training Loss: 501539.0625, Validation Loss: 81656.7012\n",
      "Early stopping after 142 epochs. Best validation loss: 73445.4688\n",
      "Epoch [50/250], Training Loss: 563162.0417, Validation Loss: 105120.3320\n",
      "Epoch [100/250], Training Loss: 498740.2083, Validation Loss: 82217.9180\n",
      "Early stopping after 132 epochs. Best validation loss: 75282.1855\n",
      "Epoch [50/250], Training Loss: 563027.3819, Validation Loss: 105099.6016\n",
      "Epoch [100/250], Training Loss: 499232.8056, Validation Loss: 81746.4766\n",
      "Epoch [150/250], Training Loss: 427197.9514, Validation Loss: 67304.4551\n",
      "Early stopping after 156 epochs. Best validation loss: 66862.7012\n",
      "Epoch [50/250], Training Loss: 563079.7083, Validation Loss: 104924.1914\n",
      "Epoch [100/250], Training Loss: 499025.9757, Validation Loss: 81743.7793\n",
      "Early stopping after 131 epochs. Best validation loss: 76320.5469\n",
      "Epoch [50/250], Training Loss: 563406.3472, Validation Loss: 104944.6562\n",
      "Epoch [100/250], Training Loss: 499479.2500, Validation Loss: 81699.5625\n",
      "Epoch [150/250], Training Loss: 425989.6562, Validation Loss: 70011.7500\n",
      "Early stopping after 184 epochs. Best validation loss: 65772.5391\n",
      "Epoch [50/250], Training Loss: 563405.2188, Validation Loss: 104944.4941\n",
      "Epoch [100/250], Training Loss: 500425.7812, Validation Loss: 81829.4453\n",
      "Early stopping after 123 epochs. Best validation loss: 78063.7637\n",
      "Epoch [50/250], Training Loss: 563405.0764, Validation Loss: 104944.4863\n",
      "Epoch [100/250], Training Loss: 500579.8403, Validation Loss: 81831.3281\n",
      "Early stopping after 142 epochs. Best validation loss: 69917.2910\n",
      "Epoch [50/250], Training Loss: 470851.6493, Validation Loss: 81639.8770\n",
      "Early stopping after 79 epochs. Best validation loss: 71386.7578\n",
      "Epoch [50/250], Training Loss: 468706.9826, Validation Loss: 81584.7031\n",
      "Epoch [100/250], Training Loss: 360664.2135, Validation Loss: 66129.9414\n",
      "Early stopping after 105 epochs. Best validation loss: 65231.3184\n",
      "Epoch [50/250], Training Loss: 470000.4757, Validation Loss: 83215.6973\n",
      "Epoch [100/250], Training Loss: 360397.5243, Validation Loss: 66083.3457\n",
      "Early stopping after 103 epochs. Best validation loss: 62351.5449\n",
      "Epoch [50/250], Training Loss: 469178.0729, Validation Loss: 81608.7285\n",
      "Early stopping after 80 epochs. Best validation loss: 71737.9199\n",
      "Epoch [50/250], Training Loss: 468920.2014, Validation Loss: 81679.9785\n",
      "Early stopping after 97 epochs. Best validation loss: 66330.4648\n",
      "Epoch [50/250], Training Loss: 470931.9896, Validation Loss: 81758.4414\n",
      "Early stopping after 86 epochs. Best validation loss: 70253.3691\n",
      "Epoch [50/250], Training Loss: 474212.9688, Validation Loss: 81943.9180\n",
      "Early stopping after 85 epochs. Best validation loss: 67999.7832\n",
      "Epoch [50/250], Training Loss: 474605.3264, Validation Loss: 82004.9023\n",
      "Early stopping after 85 epochs. Best validation loss: 69339.5586\n",
      "Epoch [50/250], Training Loss: 474259.3229, Validation Loss: 81953.8301\n",
      "Early stopping after 78 epochs. Best validation loss: 67971.6250\n",
      "Epoch [50/250], Training Loss: 375241.4028, Validation Loss: 72217.8203\n",
      "Early stopping after 69 epochs. Best validation loss: 59873.9414\n",
      "Early stopping after 47 epochs. Best validation loss: 68674.8887\n",
      "Early stopping after 47 epochs. Best validation loss: 69843.1465\n",
      "Epoch [50/250], Training Loss: 370109.7049, Validation Loss: 71769.2539\n",
      "Early stopping after 57 epochs. Best validation loss: 66027.5684\n",
      "Epoch [50/250], Training Loss: 372615.8611, Validation Loss: 76913.1211\n",
      "Early stopping after 52 epochs. Best validation loss: 70129.5801\n",
      "Early stopping after 46 epochs. Best validation loss: 69005.7129\n",
      "Epoch [50/250], Training Loss: 374594.3056, Validation Loss: 68250.6777\n",
      "Early stopping after 64 epochs. Best validation loss: 64322.4004\n",
      "Epoch [50/250], Training Loss: 379696.8785, Validation Loss: 83570.9062\n",
      "Early stopping after 51 epochs. Best validation loss: 77366.3359\n",
      "Epoch [50/250], Training Loss: 386235.8906, Validation Loss: 83789.0977\n",
      "Early stopping after 61 epochs. Best validation loss: 70174.0156\n",
      "Training model for hour 12\n",
      "Epoch [50/250], Training Loss: 540810.4896, Validation Loss: 103528.3086\n",
      "Epoch [100/250], Training Loss: 476290.7257, Validation Loss: 81837.7969\n",
      "Epoch [150/250], Training Loss: 411826.7812, Validation Loss: 77009.5977\n",
      "Early stopping after 158 epochs. Best validation loss: 72422.9746\n",
      "Epoch [50/250], Training Loss: 541655.2361, Validation Loss: 103566.9707\n",
      "Epoch [100/250], Training Loss: 477682.7326, Validation Loss: 80857.3398\n",
      "Early stopping after 130 epochs. Best validation loss: 72775.8633\n",
      "Epoch [50/250], Training Loss: 541658.1319, Validation Loss: 103567.1348\n",
      "Epoch [100/250], Training Loss: 478090.9097, Validation Loss: 82966.2930\n",
      "Early stopping after 120 epochs. Best validation loss: 81173.9805\n",
      "Epoch [50/250], Training Loss: 540433.9618, Validation Loss: 103522.0781\n",
      "Epoch [100/250], Training Loss: 477222.4965, Validation Loss: 83561.4434\n",
      "Early stopping after 124 epochs. Best validation loss: 72924.9766\n",
      "Epoch [50/250], Training Loss: 540185.7118, Validation Loss: 103546.8613\n",
      "Epoch [100/250], Training Loss: 477024.8924, Validation Loss: 83213.6758\n",
      "Early stopping after 139 epochs. Best validation loss: 74994.9688\n",
      "Epoch [50/250], Training Loss: 539957.3681, Validation Loss: 103825.1035\n",
      "Epoch [100/250], Training Loss: 476903.0799, Validation Loss: 83031.9590\n",
      "Early stopping after 137 epochs. Best validation loss: 70410.0781\n",
      "Epoch [50/250], Training Loss: 539899.8576, Validation Loss: 103545.8027\n",
      "Epoch [100/250], Training Loss: 477777.1007, Validation Loss: 83117.8281\n",
      "Early stopping after 141 epochs. Best validation loss: 73714.2969\n",
      "Epoch [50/250], Training Loss: 540098.5868, Validation Loss: 103502.6367\n",
      "Epoch [100/250], Training Loss: 477565.2361, Validation Loss: 83610.7578\n",
      "Early stopping after 134 epochs. Best validation loss: 76033.4043\n",
      "Epoch [50/250], Training Loss: 540163.2292, Validation Loss: 103514.6992\n",
      "Epoch [100/250], Training Loss: 478291.7188, Validation Loss: 83026.2480\n",
      "Early stopping after 142 epochs. Best validation loss: 72101.5059\n",
      "Epoch [50/250], Training Loss: 453784.2917, Validation Loss: 82392.6035\n",
      "Early stopping after 91 epochs. Best validation loss: 68081.7637\n",
      "Epoch [50/250], Training Loss: 456360.0000, Validation Loss: 82853.7090\n",
      "Early stopping after 91 epochs. Best validation loss: 66168.0488\n",
      "Epoch [50/250], Training Loss: 456199.9132, Validation Loss: 83109.8535\n",
      "Early stopping after 87 epochs. Best validation loss: 69116.4648\n",
      "Epoch [50/250], Training Loss: 453235.5868, Validation Loss: 82049.1562\n",
      "Early stopping after 91 epochs. Best validation loss: 73155.1523\n",
      "Epoch [50/250], Training Loss: 453548.2014, Validation Loss: 83089.3242\n",
      "Early stopping after 98 epochs. Best validation loss: 67348.2539\n",
      "Epoch [50/250], Training Loss: 454308.3056, Validation Loss: 82701.3047\n",
      "Early stopping after 66 epochs. Best validation loss: 75364.0430\n",
      "Epoch [50/250], Training Loss: 457856.8368, Validation Loss: 83028.4805\n",
      "Early stopping after 75 epochs. Best validation loss: 73203.3379\n",
      "Epoch [50/250], Training Loss: 458945.2674, Validation Loss: 83182.8066\n",
      "Early stopping after 75 epochs. Best validation loss: 73042.7500\n",
      "Epoch [50/250], Training Loss: 458946.5590, Validation Loss: 83182.9590\n",
      "Epoch [100/250], Training Loss: 350294.3316, Validation Loss: 71505.4492\n",
      "Early stopping after 101 epochs. Best validation loss: 67186.9688\n",
      "Early stopping after 45 epochs. Best validation loss: 68582.1133\n",
      "Epoch [50/250], Training Loss: 360454.4774, Validation Loss: 69234.5898\n",
      "Early stopping after 70 epochs. Best validation loss: 56303.1250\n",
      "Epoch [50/250], Training Loss: 361199.4740, Validation Loss: 73820.6953\n",
      "Early stopping after 71 epochs. Best validation loss: 66111.5449\n",
      "Epoch [50/250], Training Loss: 358341.9201, Validation Loss: 72896.6406\n",
      "Early stopping after 56 epochs. Best validation loss: 65493.8711\n",
      "Epoch [50/250], Training Loss: 362178.5399, Validation Loss: 77777.9688\n",
      "Early stopping after 62 epochs. Best validation loss: 66014.2402\n",
      "Early stopping after 47 epochs. Best validation loss: 73647.6992\n",
      "Epoch [50/250], Training Loss: 363062.8142, Validation Loss: 73677.3555\n",
      "Early stopping after 51 epochs. Best validation loss: 67008.4824\n",
      "Epoch [50/250], Training Loss: 361866.6719, Validation Loss: 75100.8242\n",
      "Early stopping after 52 epochs. Best validation loss: 66576.7520\n",
      "Early stopping after 38 epochs. Best validation loss: 82312.6934\n",
      "Training model for hour 13\n",
      "Epoch [50/250], Training Loss: 586411.4861, Validation Loss: 114750.8672\n",
      "Epoch [100/250], Training Loss: 513855.0556, Validation Loss: 87613.2930\n",
      "Early stopping after 144 epochs. Best validation loss: 78105.1660\n",
      "Epoch [50/250], Training Loss: 586411.3229, Validation Loss: 114750.8730\n",
      "Epoch [100/250], Training Loss: 513326.0729, Validation Loss: 88018.6621\n",
      "Early stopping after 148 epochs. Best validation loss: 77436.1914\n",
      "Epoch [50/250], Training Loss: 586412.5486, Validation Loss: 114750.7949\n",
      "Epoch [100/250], Training Loss: 513357.3542, Validation Loss: 88004.8984\n",
      "Early stopping after 127 epochs. Best validation loss: 78414.6758\n",
      "Epoch [50/250], Training Loss: 586281.6944, Validation Loss: 114825.7168\n",
      "Epoch [100/250], Training Loss: 513498.5174, Validation Loss: 87732.9551\n",
      "Epoch [150/250], Training Loss: 451769.1944, Validation Loss: 78304.9922\n",
      "Early stopping after 151 epochs. Best validation loss: 77383.6777\n",
      "Epoch [50/250], Training Loss: 586281.3333, Validation Loss: 114825.7578\n",
      "Epoch [100/250], Training Loss: 514753.3715, Validation Loss: 87085.9707\n",
      "Early stopping after 143 epochs. Best validation loss: 76933.3730\n",
      "Epoch [50/250], Training Loss: 586281.2604, Validation Loss: 114825.7480\n",
      "Epoch [100/250], Training Loss: 512468.9549, Validation Loss: 86746.6289\n",
      "Epoch [150/250], Training Loss: 451373.3299, Validation Loss: 76755.7949\n",
      "Early stopping after 157 epochs. Best validation loss: 75968.3398\n",
      "Epoch [50/250], Training Loss: 586229.0694, Validation Loss: 114823.1855\n",
      "Epoch [100/250], Training Loss: 512245.7257, Validation Loss: 87243.1387\n",
      "Epoch [150/250], Training Loss: 452145.5660, Validation Loss: 76304.8359\n",
      "Early stopping after 191 epochs. Best validation loss: 71679.4199\n",
      "Epoch [50/250], Training Loss: 586228.1840, Validation Loss: 114823.1074\n",
      "Epoch [100/250], Training Loss: 515171.1910, Validation Loss: 88162.6816\n",
      "Epoch [150/250], Training Loss: 450867.0035, Validation Loss: 77367.8008\n",
      "Early stopping after 160 epochs. Best validation loss: 77033.3652\n",
      "Epoch [50/250], Training Loss: 586228.0625, Validation Loss: 114823.0996\n",
      "Epoch [100/250], Training Loss: 515935.4271, Validation Loss: 88191.6152\n",
      "Early stopping after 134 epochs. Best validation loss: 77671.7988\n",
      "Epoch [50/250], Training Loss: 488137.3542, Validation Loss: 87726.6406\n",
      "Early stopping after 86 epochs. Best validation loss: 74574.8457\n",
      "Epoch [50/250], Training Loss: 490454.6944, Validation Loss: 87913.3086\n",
      "Early stopping after 91 epochs. Best validation loss: 74468.9961\n",
      "Epoch [50/250], Training Loss: 489196.4410, Validation Loss: 87808.8828\n",
      "Early stopping after 80 epochs. Best validation loss: 75844.2676\n",
      "Epoch [50/250], Training Loss: 488468.7083, Validation Loss: 88018.7461\n",
      "Early stopping after 87 epochs. Best validation loss: 74903.9766\n",
      "Epoch [50/250], Training Loss: 488276.7083, Validation Loss: 87841.3691\n",
      "Early stopping after 90 epochs. Best validation loss: 76164.8555\n",
      "Epoch [50/250], Training Loss: 490679.2465, Validation Loss: 88096.5703\n",
      "Early stopping after 84 epochs. Best validation loss: 75597.2754\n",
      "Epoch [50/250], Training Loss: 493810.3090, Validation Loss: 88307.4082\n",
      "Early stopping after 92 epochs. Best validation loss: 73521.6875\n",
      "Epoch [50/250], Training Loss: 494779.9861, Validation Loss: 88497.9395\n",
      "Early stopping after 82 epochs. Best validation loss: 78609.1621\n",
      "Epoch [50/250], Training Loss: 495283.8542, Validation Loss: 88600.1992\n",
      "Early stopping after 98 epochs. Best validation loss: 73504.9141\n",
      "Epoch [50/250], Training Loss: 383086.8420, Validation Loss: 69559.2852\n",
      "Early stopping after 55 epochs. Best validation loss: 65969.9883\n",
      "Epoch [50/250], Training Loss: 389370.0799, Validation Loss: 77059.5898\n",
      "Early stopping after 55 epochs. Best validation loss: 70265.4551\n",
      "Epoch [50/250], Training Loss: 384797.9097, Validation Loss: 79038.3555\n",
      "Early stopping after 61 epochs. Best validation loss: 71693.8281\n",
      "Epoch [50/250], Training Loss: 386460.5000, Validation Loss: 73479.8828\n",
      "Early stopping after 56 epochs. Best validation loss: 71312.8086\n",
      "Epoch [50/250], Training Loss: 403351.4740, Validation Loss: 79388.7578\n",
      "Early stopping after 52 epochs. Best validation loss: 75869.9902\n",
      "Epoch [50/250], Training Loss: 383809.5955, Validation Loss: 79371.4141\n",
      "Early stopping after 49 epochs. Best validation loss: 74090.9648\n",
      "Epoch [50/250], Training Loss: 388983.8351, Validation Loss: 74998.2500\n",
      "Early stopping after 53 epochs. Best validation loss: 69333.6719\n",
      "Epoch [50/250], Training Loss: 387596.3056, Validation Loss: 74912.1875\n",
      "Early stopping after 56 epochs. Best validation loss: 73103.7930\n",
      "Epoch [50/250], Training Loss: 397945.2378, Validation Loss: 78542.3828\n",
      "Early stopping after 79 epochs. Best validation loss: 69472.3594\n",
      "Training model for hour 14\n",
      "Epoch [50/250], Training Loss: 667358.3160, Validation Loss: 140600.4062\n",
      "Epoch [100/250], Training Loss: 583385.1319, Validation Loss: 98634.9980\n",
      "Epoch [150/250], Training Loss: 518477.7465, Validation Loss: 75014.0176\n",
      "Epoch [200/250], Training Loss: 406061.9931, Validation Loss: 70921.1992\n",
      "Early stopping after 205 epochs. Best validation loss: 68572.6641\n",
      "Epoch [50/250], Training Loss: 667282.2083, Validation Loss: 140601.8711\n",
      "Epoch [100/250], Training Loss: 583428.3368, Validation Loss: 99077.1016\n",
      "Epoch [150/250], Training Loss: 518812.0035, Validation Loss: 81069.3281\n",
      "Early stopping after 192 epochs. Best validation loss: 75714.3711\n",
      "Epoch [50/250], Training Loss: 667356.5243, Validation Loss: 140604.0312\n",
      "Epoch [100/250], Training Loss: 583178.5799, Validation Loss: 99074.2285\n",
      "Epoch [150/250], Training Loss: 518692.0972, Validation Loss: 79354.0195\n",
      "Early stopping after 186 epochs. Best validation loss: 76353.4492\n",
      "Epoch [50/250], Training Loss: 667407.7292, Validation Loss: 140707.7207\n",
      "Epoch [100/250], Training Loss: 583490.5903, Validation Loss: 99182.6602\n",
      "Epoch [150/250], Training Loss: 517822.1319, Validation Loss: 76826.5000\n",
      "Early stopping after 189 epochs. Best validation loss: 70692.5234\n",
      "Epoch [50/250], Training Loss: 667407.4236, Validation Loss: 140707.7090\n",
      "Epoch [100/250], Training Loss: 583237.5868, Validation Loss: 99173.4766\n",
      "Epoch [150/250], Training Loss: 517848.6424, Validation Loss: 78537.3945\n",
      "Early stopping after 180 epochs. Best validation loss: 73241.4375\n",
      "Epoch [50/250], Training Loss: 667407.3958, Validation Loss: 140707.7129\n",
      "Epoch [100/250], Training Loss: 583329.6771, Validation Loss: 99185.0898\n",
      "Epoch [150/250], Training Loss: 517367.8924, Validation Loss: 75896.1074\n",
      "Epoch [200/250], Training Loss: 404931.5382, Validation Loss: 69634.7305\n",
      "Early stopping after 213 epochs. Best validation loss: 67670.6035\n",
      "Epoch [50/250], Training Loss: 667357.1215, Validation Loss: 140706.0723\n",
      "Epoch [100/250], Training Loss: 582942.7049, Validation Loss: 99564.0430\n",
      "Epoch [150/250], Training Loss: 517446.9757, Validation Loss: 79634.8789\n",
      "Epoch [200/250], Training Loss: 404831.0694, Validation Loss: 74200.2812\n",
      "Early stopping after 200 epochs. Best validation loss: 73924.9023\n",
      "Epoch [50/250], Training Loss: 667356.2778, Validation Loss: 140706.0059\n",
      "Epoch [100/250], Training Loss: 583611.3576, Validation Loss: 99279.6406\n",
      "Epoch [150/250], Training Loss: 518410.5000, Validation Loss: 80713.6855\n",
      "Epoch [200/250], Training Loss: 405283.0208, Validation Loss: 74984.7188\n",
      "Early stopping after 201 epochs. Best validation loss: 72477.8477\n",
      "Epoch [50/250], Training Loss: 667356.1389, Validation Loss: 140705.9805\n",
      "Epoch [100/250], Training Loss: 584128.1493, Validation Loss: 99268.0547\n",
      "Early stopping after 132 epochs. Best validation loss: 85099.3711\n",
      "Epoch [50/250], Training Loss: 567568.3542, Validation Loss: 98631.7109\n",
      "Epoch [100/250], Training Loss: 434878.1840, Validation Loss: 70572.3242\n",
      "Early stopping after 109 epochs. Best validation loss: 70572.3242\n",
      "Epoch [50/250], Training Loss: 567531.3750, Validation Loss: 98926.0449\n",
      "Epoch [100/250], Training Loss: 434970.7431, Validation Loss: 71281.6621\n",
      "Early stopping after 99 epochs. Best validation loss: 69452.7793\n",
      "Epoch [50/250], Training Loss: 569703.1910, Validation Loss: 98834.0918\n",
      "Epoch [100/250], Training Loss: 435565.8889, Validation Loss: 81122.0391\n",
      "Early stopping after 102 epochs. Best validation loss: 74940.5176\n",
      "Epoch [50/250], Training Loss: 571877.9444, Validation Loss: 99270.8848\n",
      "Epoch [100/250], Training Loss: 435205.6215, Validation Loss: 73572.5156\n",
      "Early stopping after 109 epochs. Best validation loss: 73572.5156\n",
      "Epoch [50/250], Training Loss: 567764.2083, Validation Loss: 98841.4434\n",
      "Epoch [100/250], Training Loss: 433155.9323, Validation Loss: 73091.3086\n",
      "Early stopping after 112 epochs. Best validation loss: 71853.5352\n",
      "Epoch [50/250], Training Loss: 569145.3576, Validation Loss: 98873.4375\n",
      "Epoch [100/250], Training Loss: 435273.7604, Validation Loss: 75133.3242\n",
      "Early stopping after 113 epochs. Best validation loss: 73849.6641\n",
      "Epoch [50/250], Training Loss: 571967.0278, Validation Loss: 99007.9805\n",
      "Epoch [100/250], Training Loss: 439301.2274, Validation Loss: 70879.7461\n",
      "Early stopping after 105 epochs. Best validation loss: 69171.4453\n",
      "Epoch [50/250], Training Loss: 574200.0938, Validation Loss: 100149.1895\n",
      "Epoch [100/250], Training Loss: 438962.4097, Validation Loss: 71092.3262\n",
      "Early stopping after 111 epochs. Best validation loss: 69268.7227\n",
      "Epoch [50/250], Training Loss: 574200.6632, Validation Loss: 100149.4336\n",
      "Epoch [100/250], Training Loss: 439043.5347, Validation Loss: 70490.0566\n",
      "Early stopping after 110 epochs. Best validation loss: 68966.3086\n",
      "Epoch [50/250], Training Loss: 438283.6788, Validation Loss: 68672.1270\n",
      "Early stopping after 78 epochs. Best validation loss: 64624.1875\n",
      "Epoch [50/250], Training Loss: 435662.6076, Validation Loss: 71770.5254\n",
      "Early stopping after 52 epochs. Best validation loss: 69518.2832\n",
      "Epoch [50/250], Training Loss: 435690.1424, Validation Loss: 72921.7422\n",
      "Early stopping after 60 epochs. Best validation loss: 72043.2461\n",
      "Epoch [50/250], Training Loss: 434468.6042, Validation Loss: 69107.8203\n",
      "Early stopping after 59 epochs. Best validation loss: 69107.8203\n",
      "Epoch [50/250], Training Loss: 438460.7396, Validation Loss: 71883.0195\n",
      "Early stopping after 80 epochs. Best validation loss: 66218.6855\n",
      "Epoch [50/250], Training Loss: 436859.2569, Validation Loss: 73271.5977\n",
      "Early stopping after 57 epochs. Best validation loss: 70386.8906\n",
      "Epoch [50/250], Training Loss: 437498.4427, Validation Loss: 75428.5039\n",
      "Early stopping after 75 epochs. Best validation loss: 65049.9043\n",
      "Epoch [50/250], Training Loss: 439031.8628, Validation Loss: 71212.5566\n",
      "Early stopping after 77 epochs. Best validation loss: 65050.9785\n",
      "Epoch [50/250], Training Loss: 443709.0087, Validation Loss: 74379.2930\n",
      "Early stopping after 66 epochs. Best validation loss: 68781.4688\n",
      "Training model for hour 15\n",
      "Epoch [50/250], Training Loss: 852511.4306, Validation Loss: 217653.4297\n",
      "Epoch [100/250], Training Loss: 783197.9653, Validation Loss: 142777.1211\n",
      "Epoch [150/250], Training Loss: 709051.7118, Validation Loss: 101216.3262\n",
      "Epoch [200/250], Training Loss: 540786.9757, Validation Loss: 81334.3770\n",
      "Epoch [250/250], Training Loss: 553680.0799, Validation Loss: 76298.5410\n",
      "Training stopped after 249 epochs. Best validation loss: 74433.8496\n",
      "Epoch [50/250], Training Loss: 852509.4514, Validation Loss: 217653.3320\n",
      "Epoch [100/250], Training Loss: 783647.9583, Validation Loss: 142878.7930\n",
      "Epoch [150/250], Training Loss: 708841.4340, Validation Loss: 103183.0625\n",
      "Epoch [200/250], Training Loss: 540367.6458, Validation Loss: 81686.8867\n",
      "Epoch [250/250], Training Loss: 553856.4201, Validation Loss: 71744.8203\n",
      "Training stopped after 249 epochs. Best validation loss: 70907.7051\n",
      "Epoch [50/250], Training Loss: 852509.6181, Validation Loss: 217653.3789\n",
      "Epoch [100/250], Training Loss: 783328.1875, Validation Loss: 142834.8164\n",
      "Epoch [150/250], Training Loss: 708748.9826, Validation Loss: 100302.1133\n",
      "Epoch [200/250], Training Loss: 540662.6146, Validation Loss: 82838.8652\n",
      "Early stopping after 247 epochs. Best validation loss: 75276.0059\n",
      "Epoch [50/250], Training Loss: 852458.2708, Validation Loss: 217777.9844\n",
      "Epoch [100/250], Training Loss: 783237.5139, Validation Loss: 143048.3203\n",
      "Epoch [150/250], Training Loss: 708375.4306, Validation Loss: 100910.8730\n",
      "Epoch [200/250], Training Loss: 539676.9306, Validation Loss: 79671.8672\n",
      "Epoch [250/250], Training Loss: 552584.2604, Validation Loss: 74562.7031\n",
      "Training stopped after 249 epochs. Best validation loss: 73981.4863\n",
      "Epoch [50/250], Training Loss: 852457.9097, Validation Loss: 217778.0000\n",
      "Epoch [100/250], Training Loss: 783371.7917, Validation Loss: 143084.1953\n",
      "Epoch [150/250], Training Loss: 707976.7812, Validation Loss: 102222.0000\n",
      "Epoch [200/250], Training Loss: 539547.8889, Validation Loss: 80931.6074\n",
      "Early stopping after 238 epochs. Best validation loss: 76120.5312\n",
      "Epoch [50/250], Training Loss: 852457.8819, Validation Loss: 217778.0039\n",
      "Epoch [100/250], Training Loss: 783445.5417, Validation Loss: 143137.8828\n",
      "Epoch [150/250], Training Loss: 707718.7882, Validation Loss: 98604.9551\n",
      "Epoch [200/250], Training Loss: 539520.3368, Validation Loss: 78744.4102\n",
      "Epoch [250/250], Training Loss: 552705.6840, Validation Loss: 72641.4102\n",
      "Training stopped after 249 epochs. Best validation loss: 72364.2500\n",
      "Epoch [50/250], Training Loss: 852403.3125, Validation Loss: 217775.1406\n",
      "Epoch [100/250], Training Loss: 783559.3333, Validation Loss: 143244.8984\n",
      "Epoch [150/250], Training Loss: 708423.3785, Validation Loss: 100354.6250\n",
      "Epoch [200/250], Training Loss: 540015.3090, Validation Loss: 77906.6289\n",
      "Epoch [250/250], Training Loss: 552766.5000, Validation Loss: 69665.4004\n",
      "Training stopped after 249 epochs. Best validation loss: 69162.3301\n",
      "Epoch [50/250], Training Loss: 852402.2778, Validation Loss: 217774.9844\n",
      "Epoch [100/250], Training Loss: 784141.9167, Validation Loss: 143284.0742\n",
      "Epoch [150/250], Training Loss: 708330.9271, Validation Loss: 99534.7891\n",
      "Epoch [200/250], Training Loss: 540210.6528, Validation Loss: 76762.7734\n",
      "Epoch [250/250], Training Loss: 552802.7292, Validation Loss: 68456.7656\n",
      "Training stopped after 249 epochs. Best validation loss: 68456.7656\n",
      "Epoch [50/250], Training Loss: 852402.2014, Validation Loss: 217774.9844\n",
      "Epoch [100/250], Training Loss: 783969.4861, Validation Loss: 143281.2422\n",
      "Epoch [150/250], Training Loss: 709838.6215, Validation Loss: 101685.4590\n",
      "Epoch [200/250], Training Loss: 540662.5868, Validation Loss: 83340.5645\n",
      "Early stopping after 241 epochs. Best validation loss: 79074.7246\n",
      "Epoch [50/250], Training Loss: 755270.6736, Validation Loss: 141821.1602\n",
      "Epoch [100/250], Training Loss: 570063.2500, Validation Loss: 80356.6250\n",
      "Epoch [150/250], Training Loss: 479357.2292, Validation Loss: 70671.9961\n",
      "Early stopping after 155 epochs. Best validation loss: 69714.4922\n",
      "Epoch [50/250], Training Loss: 755039.0312, Validation Loss: 141869.9688\n",
      "Epoch [100/250], Training Loss: 570241.9896, Validation Loss: 79042.9512\n",
      "Epoch [150/250], Training Loss: 479897.8368, Validation Loss: 70747.9629\n",
      "Early stopping after 179 epochs. Best validation loss: 67399.5723\n",
      "Epoch [50/250], Training Loss: 755686.6806, Validation Loss: 141946.2344\n",
      "Epoch [100/250], Training Loss: 569928.8993, Validation Loss: 83364.1934\n",
      "Early stopping after 122 epochs. Best validation loss: 76742.3320\n",
      "Epoch [50/250], Training Loss: 752745.8194, Validation Loss: 141988.9062\n",
      "Epoch [100/250], Training Loss: 569219.7326, Validation Loss: 79470.0645\n",
      "Epoch [150/250], Training Loss: 478216.6007, Validation Loss: 74583.5820\n",
      "Early stopping after 153 epochs. Best validation loss: 70082.8809\n",
      "Epoch [50/250], Training Loss: 753380.2118, Validation Loss: 141714.5195\n",
      "Epoch [100/250], Training Loss: 568310.0764, Validation Loss: 82206.4258\n",
      "Epoch [150/250], Training Loss: 478562.0312, Validation Loss: 76229.4219\n",
      "Early stopping after 154 epochs. Best validation loss: 72803.0742\n",
      "Epoch [50/250], Training Loss: 755162.1285, Validation Loss: 141701.1914\n",
      "Epoch [100/250], Training Loss: 568575.7708, Validation Loss: 81854.0469\n",
      "Epoch [150/250], Training Loss: 478156.9271, Validation Loss: 68526.6621\n",
      "Early stopping after 182 epochs. Best validation loss: 66348.9805\n",
      "Epoch [50/250], Training Loss: 754492.1979, Validation Loss: 142221.0547\n",
      "Epoch [100/250], Training Loss: 574862.3333, Validation Loss: 81707.5703\n",
      "Epoch [150/250], Training Loss: 480011.5590, Validation Loss: 68819.7656\n",
      "Early stopping after 164 epochs. Best validation loss: 68388.8145\n",
      "Epoch [50/250], Training Loss: 754530.4167, Validation Loss: 142244.2305\n",
      "Epoch [100/250], Training Loss: 572982.3646, Validation Loss: 82845.3184\n",
      "Early stopping after 133 epochs. Best validation loss: 75175.1875\n",
      "Epoch [50/250], Training Loss: 754479.4062, Validation Loss: 142215.2383\n",
      "Epoch [100/250], Training Loss: 571198.1319, Validation Loss: 78242.2773\n",
      "Early stopping after 136 epochs. Best validation loss: 69411.8418\n",
      "Epoch [50/250], Training Loss: 597009.5174, Validation Loss: 78617.1191\n",
      "Epoch [100/250], Training Loss: 407230.1424, Validation Loss: 64425.0586\n",
      "Early stopping after 99 epochs. Best validation loss: 62144.5586\n",
      "Epoch [50/250], Training Loss: 598303.0833, Validation Loss: 79330.9414\n",
      "Early stopping after 87 epochs. Best validation loss: 67242.4531\n",
      "Epoch [50/250], Training Loss: 595082.6424, Validation Loss: 80876.6680\n",
      "Early stopping after 84 epochs. Best validation loss: 66530.7441\n",
      "Epoch [50/250], Training Loss: 595205.3576, Validation Loss: 79653.2012\n",
      "Early stopping after 88 epochs. Best validation loss: 69839.1992\n",
      "Epoch [50/250], Training Loss: 590541.4028, Validation Loss: 82460.3184\n",
      "Early stopping after 80 epochs. Best validation loss: 73136.2227\n",
      "Epoch [50/250], Training Loss: 590925.0417, Validation Loss: 80139.8262\n",
      "Early stopping after 87 epochs. Best validation loss: 69754.4434\n",
      "Epoch [50/250], Training Loss: 601645.1250, Validation Loss: 79346.4805\n",
      "Epoch [100/250], Training Loss: 403037.7153, Validation Loss: 70408.8711\n",
      "Early stopping after 99 epochs. Best validation loss: 69855.4316\n",
      "Epoch [50/250], Training Loss: 593536.1111, Validation Loss: 81758.7109\n",
      "Early stopping after 69 epochs. Best validation loss: 74631.2715\n",
      "Epoch [50/250], Training Loss: 600477.5174, Validation Loss: 82264.2910\n",
      "Early stopping after 79 epochs. Best validation loss: 71465.4941\n",
      "Training model for hour 16\n",
      "Epoch [50/250], Training Loss: 1105502.1319, Validation Loss: 350600.2969\n",
      "Epoch [100/250], Training Loss: 1020788.3958, Validation Loss: 240389.7969\n",
      "Epoch [150/250], Training Loss: 918728.7292, Validation Loss: 167638.6953\n",
      "Epoch [200/250], Training Loss: 718786.2986, Validation Loss: 125971.8379\n",
      "Epoch [250/250], Training Loss: 738548.1458, Validation Loss: 107060.1660\n",
      "Training stopped after 249 epochs. Best validation loss: 105984.9883\n",
      "Epoch [50/250], Training Loss: 1105508.4028, Validation Loss: 350600.9453\n",
      "Epoch [100/250], Training Loss: 1020882.7708, Validation Loss: 240433.7891\n",
      "Epoch [150/250], Training Loss: 918904.3403, Validation Loss: 169405.5039\n",
      "Epoch [200/250], Training Loss: 718668.0278, Validation Loss: 127536.7539\n",
      "Epoch [250/250], Training Loss: 738129.6389, Validation Loss: 108874.5449\n",
      "Training stopped after 249 epochs. Best validation loss: 108874.5449\n",
      "Epoch [50/250], Training Loss: 1105508.5694, Validation Loss: 350600.9609\n",
      "Epoch [100/250], Training Loss: 1021017.5000, Validation Loss: 240431.0391\n",
      "Epoch [150/250], Training Loss: 919555.1389, Validation Loss: 170896.9805\n",
      "Epoch [200/250], Training Loss: 719036.3472, Validation Loss: 128631.6016\n",
      "Epoch [250/250], Training Loss: 738948.3090, Validation Loss: 109627.7480\n",
      "Training stopped after 249 epochs. Best validation loss: 108912.9043\n",
      "Epoch [50/250], Training Loss: 1105838.5903, Validation Loss: 350783.3906\n",
      "Epoch [100/250], Training Loss: 1021336.5139, Validation Loss: 240718.0938\n",
      "Epoch [150/250], Training Loss: 920196.2778, Validation Loss: 168024.7578\n",
      "Epoch [200/250], Training Loss: 718599.0764, Validation Loss: 127997.4941\n",
      "Epoch [250/250], Training Loss: 738234.0069, Validation Loss: 105171.8594\n",
      "Training stopped after 249 epochs. Best validation loss: 104152.5898\n",
      "Epoch [50/250], Training Loss: 1105838.0208, Validation Loss: 350783.1641\n",
      "Epoch [100/250], Training Loss: 1020917.6736, Validation Loss: 240680.7656\n",
      "Epoch [150/250], Training Loss: 918961.7153, Validation Loss: 168303.9570\n",
      "Epoch [200/250], Training Loss: 718395.4479, Validation Loss: 128473.2812\n",
      "Epoch [250/250], Training Loss: 737681.3507, Validation Loss: 107212.9785\n",
      "Training stopped after 249 epochs. Best validation loss: 107212.9785\n",
      "Epoch [50/250], Training Loss: 1105838.0000, Validation Loss: 350783.2266\n",
      "Epoch [100/250], Training Loss: 1020898.8889, Validation Loss: 240666.5859\n",
      "Epoch [150/250], Training Loss: 918226.3958, Validation Loss: 167804.6680\n",
      "Epoch [200/250], Training Loss: 717850.1562, Validation Loss: 130056.2969\n",
      "Epoch [250/250], Training Loss: 737484.9549, Validation Loss: 108522.6250\n",
      "Training stopped after 249 epochs. Best validation loss: 108417.3418\n",
      "Epoch [50/250], Training Loss: 1105337.3889, Validation Loss: 350725.0859\n",
      "Epoch [100/250], Training Loss: 1021764.9583, Validation Loss: 240730.4297\n",
      "Epoch [150/250], Training Loss: 917737.6667, Validation Loss: 168762.6172\n",
      "Epoch [200/250], Training Loss: 717975.5104, Validation Loss: 126946.8711\n",
      "Epoch [250/250], Training Loss: 737447.0590, Validation Loss: 105204.0723\n",
      "Training stopped after 249 epochs. Best validation loss: 105204.0723\n",
      "Epoch [50/250], Training Loss: 1105336.6597, Validation Loss: 350725.0625\n",
      "Epoch [100/250], Training Loss: 1021764.3681, Validation Loss: 240730.3281\n",
      "Epoch [150/250], Training Loss: 918277.0625, Validation Loss: 168790.8594\n",
      "Epoch [200/250], Training Loss: 718250.5069, Validation Loss: 127637.7188\n",
      "Epoch [250/250], Training Loss: 737702.4167, Validation Loss: 108458.5801\n",
      "Training stopped after 249 epochs. Best validation loss: 107420.0215\n",
      "Epoch [50/250], Training Loss: 1105337.2778, Validation Loss: 350725.5078\n",
      "Epoch [100/250], Training Loss: 1021765.0556, Validation Loss: 240730.7734\n",
      "Epoch [150/250], Training Loss: 919916.5208, Validation Loss: 167856.3633\n",
      "Epoch [200/250], Training Loss: 718459.3264, Validation Loss: 128990.9590\n",
      "Epoch [250/250], Training Loss: 738107.6458, Validation Loss: 113327.7363\n",
      "Training stopped after 249 epochs. Best validation loss: 109010.1367\n",
      "Epoch [50/250], Training Loss: 980617.5833, Validation Loss: 237995.3984\n",
      "Epoch [100/250], Training Loss: 754983.9340, Validation Loss: 130950.0156\n",
      "Epoch [150/250], Training Loss: 661748.2188, Validation Loss: 102076.2031\n",
      "Early stopping after 173 epochs. Best validation loss: 95288.5762\n",
      "Epoch [50/250], Training Loss: 980632.4028, Validation Loss: 238091.2578\n",
      "Epoch [100/250], Training Loss: 756107.7639, Validation Loss: 129506.6562\n",
      "Epoch [150/250], Training Loss: 662887.4340, Validation Loss: 104309.8984\n",
      "Early stopping after 164 epochs. Best validation loss: 100971.1543\n",
      "Epoch [50/250], Training Loss: 980683.1181, Validation Loss: 240008.3203\n",
      "Epoch [100/250], Training Loss: 755955.7569, Validation Loss: 127225.7812\n",
      "Epoch [150/250], Training Loss: 662818.6771, Validation Loss: 97915.6133\n",
      "Early stopping after 173 epochs. Best validation loss: 95220.3652\n",
      "Epoch [50/250], Training Loss: 981049.7986, Validation Loss: 239013.0000\n",
      "Epoch [100/250], Training Loss: 760206.8889, Validation Loss: 131129.8164\n",
      "Epoch [150/250], Training Loss: 662608.3056, Validation Loss: 100754.8672\n",
      "Early stopping after 184 epochs. Best validation loss: 96784.0078\n",
      "Epoch [50/250], Training Loss: 980394.5764, Validation Loss: 238442.1562\n",
      "Epoch [100/250], Training Loss: 755674.2569, Validation Loss: 127430.1016\n",
      "Epoch [150/250], Training Loss: 662338.5174, Validation Loss: 97234.1270\n",
      "Early stopping after 182 epochs. Best validation loss: 94053.0469\n",
      "Epoch [50/250], Training Loss: 980378.0694, Validation Loss: 238500.7188\n",
      "Epoch [100/250], Training Loss: 754562.3472, Validation Loss: 130555.5430\n",
      "Epoch [150/250], Training Loss: 661997.8681, Validation Loss: 95957.0996\n",
      "Early stopping after 186 epochs. Best validation loss: 92398.5352\n",
      "Epoch [50/250], Training Loss: 981934.7569, Validation Loss: 239753.0625\n",
      "Epoch [100/250], Training Loss: 755681.7292, Validation Loss: 125757.3184\n",
      "Epoch [150/250], Training Loss: 662487.5764, Validation Loss: 99315.4648\n",
      "Early stopping after 185 epochs. Best validation loss: 91750.3594\n",
      "Epoch [50/250], Training Loss: 982036.4792, Validation Loss: 239829.4844\n",
      "Epoch [100/250], Training Loss: 757434.8993, Validation Loss: 128464.4629\n",
      "Epoch [150/250], Training Loss: 663011.0903, Validation Loss: 97464.9531\n",
      "Early stopping after 183 epochs. Best validation loss: 94439.2773\n",
      "Epoch [50/250], Training Loss: 982201.8889, Validation Loss: 239955.0703\n",
      "Epoch [100/250], Training Loss: 759880.7535, Validation Loss: 126526.9727\n",
      "Epoch [150/250], Training Loss: 662807.8646, Validation Loss: 101018.8809\n",
      "Early stopping after 198 epochs. Best validation loss: 93223.0723\n",
      "Epoch [50/250], Training Loss: 788624.3056, Validation Loss: 127158.4375\n",
      "Early stopping after 80 epochs. Best validation loss: 100034.8438\n",
      "Epoch [50/250], Training Loss: 796775.6319, Validation Loss: 126670.9297\n",
      "Early stopping after 87 epochs. Best validation loss: 92997.9277\n",
      "Epoch [50/250], Training Loss: 794009.5833, Validation Loss: 130069.6914\n",
      "Epoch [100/250], Training Loss: 540408.7431, Validation Loss: 105646.6367\n",
      "Early stopping after 99 epochs. Best validation loss: 99848.0000\n",
      "Epoch [50/250], Training Loss: 793224.7361, Validation Loss: 130605.8086\n",
      "Early stopping after 87 epochs. Best validation loss: 98404.5840\n",
      "Epoch [50/250], Training Loss: 790274.0625, Validation Loss: 128893.3105\n",
      "Early stopping after 87 epochs. Best validation loss: 100500.4902\n",
      "Epoch [50/250], Training Loss: 790044.3681, Validation Loss: 128804.2305\n",
      "Epoch [100/250], Training Loss: 534185.9965, Validation Loss: 99279.8984\n",
      "Early stopping after 111 epochs. Best validation loss: 97718.2539\n",
      "Epoch [50/250], Training Loss: 803248.0625, Validation Loss: 134878.1484\n",
      "Epoch [100/250], Training Loss: 546094.2049, Validation Loss: 94408.9043\n",
      "Early stopping after 110 epochs. Best validation loss: 94389.7324\n",
      "Epoch [50/250], Training Loss: 823268.0417, Validation Loss: 132188.4648\n",
      "Early stopping after 96 epochs. Best validation loss: 97141.5840\n",
      "Epoch [50/250], Training Loss: 809096.4028, Validation Loss: 132643.3457\n",
      "Epoch [100/250], Training Loss: 544664.4444, Validation Loss: 94383.8008\n",
      "Early stopping after 103 epochs. Best validation loss: 93870.6094\n",
      "Training model for hour 17\n",
      "Epoch [50/250], Training Loss: 1251667.8681, Validation Loss: 554326.6719\n",
      "Epoch [100/250], Training Loss: 1179886.6597, Validation Loss: 410841.5625\n",
      "Epoch [150/250], Training Loss: 1086302.6458, Validation Loss: 308629.8906\n",
      "Epoch [200/250], Training Loss: 839283.7986, Validation Loss: 240432.2031\n",
      "Epoch [250/250], Training Loss: 877027.0903, Validation Loss: 198314.6484\n",
      "Training stopped after 249 epochs. Best validation loss: 197198.0664\n",
      "Epoch [50/250], Training Loss: 1251667.7153, Validation Loss: 554326.7656\n",
      "Epoch [100/250], Training Loss: 1179902.5556, Validation Loss: 410859.7344\n",
      "Epoch [150/250], Training Loss: 1085493.6667, Validation Loss: 307615.7656\n",
      "Epoch [200/250], Training Loss: 839081.9826, Validation Loss: 240110.3203\n",
      "Epoch [250/250], Training Loss: 877481.2153, Validation Loss: 189350.5938\n",
      "Training stopped after 249 epochs. Best validation loss: 189350.5938\n",
      "Epoch [50/250], Training Loss: 1251667.7222, Validation Loss: 554326.7656\n",
      "Epoch [100/250], Training Loss: 1180096.2569, Validation Loss: 410882.2188\n",
      "Epoch [150/250], Training Loss: 1086072.3750, Validation Loss: 308374.0625\n",
      "Epoch [200/250], Training Loss: 839175.7188, Validation Loss: 254351.2188\n",
      "Epoch [250/250], Training Loss: 877241.3889, Validation Loss: 211798.4492\n",
      "Training stopped after 249 epochs. Best validation loss: 211798.4492\n",
      "Epoch [50/250], Training Loss: 1251595.1597, Validation Loss: 554489.7656\n",
      "Epoch [100/250], Training Loss: 1179855.5069, Validation Loss: 411045.2812\n",
      "Epoch [150/250], Training Loss: 1086712.9583, Validation Loss: 309704.1875\n",
      "Epoch [200/250], Training Loss: 838819.4306, Validation Loss: 241015.3906\n",
      "Epoch [250/250], Training Loss: 876498.1667, Validation Loss: 200080.8359\n",
      "Training stopped after 249 epochs. Best validation loss: 200080.8359\n",
      "Epoch [50/250], Training Loss: 1251594.2569, Validation Loss: 554489.1719\n",
      "Epoch [100/250], Training Loss: 1179854.1667, Validation Loss: 411044.6406\n",
      "Epoch [150/250], Training Loss: 1086205.4236, Validation Loss: 307844.6719\n",
      "Epoch [200/250], Training Loss: 838812.7882, Validation Loss: 239946.0234\n",
      "Epoch [250/250], Training Loss: 876882.9236, Validation Loss: 194398.4258\n",
      "Training stopped after 249 epochs. Best validation loss: 194370.1055\n",
      "Epoch [50/250], Training Loss: 1251594.1181, Validation Loss: 554489.1406\n",
      "Epoch [100/250], Training Loss: 1179854.0139, Validation Loss: 411044.5781\n",
      "Epoch [150/250], Training Loss: 1085585.1042, Validation Loss: 309610.9531\n",
      "Epoch [200/250], Training Loss: 838660.9236, Validation Loss: 243520.5312\n",
      "Epoch [250/250], Training Loss: 876871.5486, Validation Loss: 194458.4922\n",
      "Training stopped after 249 epochs. Best validation loss: 188841.8789\n",
      "Epoch [50/250], Training Loss: 1251535.1181, Validation Loss: 554485.2500\n",
      "Epoch [100/250], Training Loss: 1179807.8056, Validation Loss: 411038.8906\n",
      "Epoch [150/250], Training Loss: 1085595.6111, Validation Loss: 310065.8906\n",
      "Epoch [200/250], Training Loss: 838662.7500, Validation Loss: 238490.8828\n",
      "Epoch [250/250], Training Loss: 877165.5278, Validation Loss: 200817.1562\n",
      "Training stopped after 249 epochs. Best validation loss: 198610.9180\n",
      "Epoch [50/250], Training Loss: 1251533.9167, Validation Loss: 554484.9688\n",
      "Epoch [100/250], Training Loss: 1179806.2639, Validation Loss: 411038.4062\n",
      "Epoch [150/250], Training Loss: 1085442.8333, Validation Loss: 307366.7109\n",
      "Epoch [200/250], Training Loss: 838413.7778, Validation Loss: 242606.9922\n",
      "Epoch [250/250], Training Loss: 876251.0833, Validation Loss: 201987.0781\n",
      "Training stopped after 249 epochs. Best validation loss: 201987.0781\n",
      "Epoch [50/250], Training Loss: 1251533.7500, Validation Loss: 554484.9688\n",
      "Epoch [100/250], Training Loss: 1179806.1319, Validation Loss: 411038.3594\n",
      "Epoch [150/250], Training Loss: 1085750.8194, Validation Loss: 307525.4688\n",
      "Epoch [200/250], Training Loss: 838380.4931, Validation Loss: 242105.2969\n",
      "Epoch [250/250], Training Loss: 876194.8681, Validation Loss: 201778.9258\n",
      "Training stopped after 249 epochs. Best validation loss: 201084.6328\n",
      "Epoch [50/250], Training Loss: 1163402.9167, Validation Loss: 408018.2500\n",
      "Epoch [100/250], Training Loss: 870481.9028, Validation Loss: 241461.6953\n",
      "Epoch [150/250], Training Loss: 798891.9653, Validation Loss: 178060.0742\n",
      "Early stopping after 193 epochs. Best validation loss: 159213.4727\n",
      "Epoch [50/250], Training Loss: 1163401.8889, Validation Loss: 408018.1875\n",
      "Epoch [100/250], Training Loss: 869961.5139, Validation Loss: 241139.0781\n",
      "Epoch [150/250], Training Loss: 798631.4931, Validation Loss: 178671.7617\n",
      "Epoch [200/250], Training Loss: 662334.8785, Validation Loss: 165248.1328\n",
      "Early stopping after 199 epochs. Best validation loss: 163889.5625\n",
      "Epoch [50/250], Training Loss: 1163401.6181, Validation Loss: 408018.1406\n",
      "Epoch [100/250], Training Loss: 881602.9514, Validation Loss: 240121.1562\n",
      "Epoch [150/250], Training Loss: 802286.8611, Validation Loss: 176205.6133\n",
      "Early stopping after 179 epochs. Best validation loss: 158640.6641\n",
      "Epoch [50/250], Training Loss: 1163103.2639, Validation Loss: 408154.3594\n",
      "Epoch [100/250], Training Loss: 868272.0139, Validation Loss: 240894.7188\n",
      "Epoch [150/250], Training Loss: 797082.1944, Validation Loss: 171342.2109\n",
      "Early stopping after 181 epochs. Best validation loss: 160094.7891\n",
      "Epoch [50/250], Training Loss: 1163101.0069, Validation Loss: 408156.2031\n",
      "Epoch [100/250], Training Loss: 868348.7917, Validation Loss: 243990.6641\n",
      "Epoch [150/250], Training Loss: 796720.7222, Validation Loss: 182622.1836\n",
      "Early stopping after 162 epochs. Best validation loss: 176002.9141\n",
      "Epoch [50/250], Training Loss: 1163099.9931, Validation Loss: 408155.6094\n",
      "Epoch [100/250], Training Loss: 876250.2917, Validation Loss: 244016.6484\n",
      "Epoch [150/250], Training Loss: 801362.0347, Validation Loss: 177098.6406\n",
      "Epoch [200/250], Training Loss: 661287.5972, Validation Loss: 156701.6406\n",
      "Early stopping after 202 epochs. Best validation loss: 152374.1719\n",
      "Epoch [50/250], Training Loss: 1165498.8333, Validation Loss: 410432.4062\n",
      "Epoch [100/250], Training Loss: 873503.0972, Validation Loss: 246671.7734\n",
      "Epoch [150/250], Training Loss: 800648.5833, Validation Loss: 167010.0625\n",
      "Early stopping after 192 epochs. Best validation loss: 155410.1289\n",
      "Epoch [50/250], Training Loss: 1165633.8403, Validation Loss: 410551.5625\n",
      "Epoch [100/250], Training Loss: 875174.2153, Validation Loss: 240595.2266\n",
      "Epoch [150/250], Training Loss: 800584.1181, Validation Loss: 173016.0234\n",
      "Early stopping after 177 epochs. Best validation loss: 159457.4688\n",
      "Epoch [50/250], Training Loss: 1165601.6042, Validation Loss: 410523.8438\n",
      "Epoch [100/250], Training Loss: 876792.9722, Validation Loss: 241820.7500\n",
      "Epoch [150/250], Training Loss: 801260.5347, Validation Loss: 179922.3086\n",
      "Early stopping after 171 epochs. Best validation loss: 168262.6289\n",
      "Epoch [50/250], Training Loss: 929358.7708, Validation Loss: 240571.7812\n",
      "Early stopping after 94 epochs. Best validation loss: 160093.0820\n",
      "Epoch [50/250], Training Loss: 934581.1042, Validation Loss: 238956.5234\n",
      "Epoch [100/250], Training Loss: 648062.7674, Validation Loss: 160817.8828\n",
      "Early stopping after 110 epochs. Best validation loss: 155454.8320\n",
      "Epoch [50/250], Training Loss: 929394.3472, Validation Loss: 239567.4453\n",
      "Early stopping after 96 epochs. Best validation loss: 153727.7031\n",
      "Epoch [50/250], Training Loss: 934203.2222, Validation Loss: 245046.3828\n",
      "Epoch [100/250], Training Loss: 655970.1215, Validation Loss: 174217.1992\n",
      "Early stopping after 110 epochs. Best validation loss: 162536.9297\n",
      "Epoch [50/250], Training Loss: 932016.3333, Validation Loss: 240116.9531\n",
      "Early stopping after 91 epochs. Best validation loss: 167514.6992\n",
      "Epoch [50/250], Training Loss: 928037.3681, Validation Loss: 239715.4766\n",
      "Early stopping after 98 epochs. Best validation loss: 158730.3828\n",
      "Epoch [50/250], Training Loss: 938395.0417, Validation Loss: 242635.0156\n",
      "Epoch [100/250], Training Loss: 644986.2882, Validation Loss: 166587.2656\n",
      "Early stopping after 103 epochs. Best validation loss: 164731.5586\n",
      "Epoch [50/250], Training Loss: 929741.4931, Validation Loss: 238578.3125\n",
      "Epoch [100/250], Training Loss: 644208.6597, Validation Loss: 165538.4688\n",
      "Early stopping after 108 epochs. Best validation loss: 164061.2109\n",
      "Epoch [50/250], Training Loss: 930832.5833, Validation Loss: 246622.1406\n",
      "Early stopping after 93 epochs. Best validation loss: 163909.8242\n",
      "Training model for hour 18\n",
      "Epoch [50/250], Training Loss: 1172781.3333, Validation Loss: 585319.7500\n",
      "Epoch [100/250], Training Loss: 1093726.9167, Validation Loss: 434537.3594\n",
      "Epoch [150/250], Training Loss: 1002271.9306, Validation Loss: 325805.9375\n",
      "Epoch [200/250], Training Loss: 783986.4514, Validation Loss: 253017.7969\n",
      "Epoch [250/250], Training Loss: 810032.9653, Validation Loss: 207092.1328\n",
      "Training stopped after 249 epochs. Best validation loss: 200645.2500\n",
      "Epoch [50/250], Training Loss: 1172781.0347, Validation Loss: 585319.7656\n",
      "Epoch [100/250], Training Loss: 1094546.3750, Validation Loss: 434707.2969\n",
      "Epoch [150/250], Training Loss: 1002181.0694, Validation Loss: 325494.8125\n",
      "Epoch [200/250], Training Loss: 783656.9965, Validation Loss: 249276.8281\n",
      "Epoch [250/250], Training Loss: 809911.4514, Validation Loss: 194394.7812\n",
      "Training stopped after 249 epochs. Best validation loss: 194394.7812\n",
      "Epoch [50/250], Training Loss: 1172781.0417, Validation Loss: 585319.7812\n",
      "Epoch [100/250], Training Loss: 1094328.4236, Validation Loss: 434691.9688\n",
      "Epoch [150/250], Training Loss: 1002548.8750, Validation Loss: 327626.1562\n",
      "Epoch [200/250], Training Loss: 783598.4097, Validation Loss: 248056.8672\n",
      "Epoch [250/250], Training Loss: 810047.2049, Validation Loss: 196184.3828\n",
      "Training stopped after 249 epochs. Best validation loss: 195694.7109\n",
      "Epoch [50/250], Training Loss: 1172711.3819, Validation Loss: 585498.3594\n",
      "Epoch [100/250], Training Loss: 1094326.5069, Validation Loss: 434914.4688\n",
      "Epoch [150/250], Training Loss: 1002131.3750, Validation Loss: 323841.2969\n",
      "Epoch [200/250], Training Loss: 783231.8819, Validation Loss: 249875.0078\n",
      "Epoch [250/250], Training Loss: 809495.4549, Validation Loss: 197613.8281\n",
      "Training stopped after 249 epochs. Best validation loss: 194477.5938\n",
      "Epoch [50/250], Training Loss: 1172711.0486, Validation Loss: 585498.3281\n",
      "Epoch [100/250], Training Loss: 1094325.7431, Validation Loss: 434914.2969\n",
      "Epoch [150/250], Training Loss: 1003588.8264, Validation Loss: 324337.8594\n",
      "Epoch [200/250], Training Loss: 783471.4688, Validation Loss: 249673.6094\n",
      "Epoch [250/250], Training Loss: 809764.0625, Validation Loss: 198832.7891\n",
      "Training stopped after 249 epochs. Best validation loss: 196266.6953\n",
      "Epoch [50/250], Training Loss: 1172710.9375, Validation Loss: 585498.3125\n",
      "Epoch [100/250], Training Loss: 1094325.5833, Validation Loss: 434914.2500\n",
      "Epoch [150/250], Training Loss: 1002332.6389, Validation Loss: 324074.7031\n",
      "Epoch [200/250], Training Loss: 783375.0625, Validation Loss: 246580.0391\n",
      "Epoch [250/250], Training Loss: 809451.7882, Validation Loss: 196748.7031\n",
      "Training stopped after 249 epochs. Best validation loss: 196748.7031\n",
      "Epoch [50/250], Training Loss: 1172658.1181, Validation Loss: 585500.0469\n",
      "Epoch [100/250], Training Loss: 1094285.2292, Validation Loss: 434913.2656\n",
      "Epoch [150/250], Training Loss: 1002896.2014, Validation Loss: 323858.6094\n",
      "Epoch [200/250], Training Loss: 783641.4653, Validation Loss: 243131.6797\n",
      "Epoch [250/250], Training Loss: 809774.5347, Validation Loss: 193577.8594\n",
      "Training stopped after 249 epochs. Best validation loss: 193577.8594\n",
      "Epoch [50/250], Training Loss: 1172657.4236, Validation Loss: 585500.2188\n",
      "Epoch [100/250], Training Loss: 1094284.2153, Validation Loss: 434913.2031\n",
      "Epoch [150/250], Training Loss: 1002566.7847, Validation Loss: 325197.3750\n",
      "Epoch [200/250], Training Loss: 783303.9479, Validation Loss: 253270.0469\n",
      "Epoch [250/250], Training Loss: 809631.1181, Validation Loss: 207328.0156\n",
      "Training stopped after 249 epochs. Best validation loss: 201716.4062\n",
      "Epoch [50/250], Training Loss: 1172657.2292, Validation Loss: 585500.0938\n",
      "Epoch [100/250], Training Loss: 1094284.0000, Validation Loss: 434913.1094\n",
      "Epoch [150/250], Training Loss: 1002780.9236, Validation Loss: 324590.0625\n",
      "Epoch [200/250], Training Loss: 783674.6215, Validation Loss: 245556.8125\n",
      "Epoch [250/250], Training Loss: 809632.4792, Validation Loss: 191782.3906\n",
      "Training stopped after 249 epochs. Best validation loss: 191782.3906\n",
      "Epoch [50/250], Training Loss: 1101541.8472, Validation Loss: 431632.5625\n",
      "Epoch [100/250], Training Loss: 812078.3056, Validation Loss: 251382.8125\n",
      "Epoch [150/250], Training Loss: 755083.7431, Validation Loss: 171899.1953\n",
      "Early stopping after 181 epochs. Best validation loss: 150551.6328\n",
      "Epoch [50/250], Training Loss: 1101541.3472, Validation Loss: 431632.5781\n",
      "Epoch [100/250], Training Loss: 808568.1528, Validation Loss: 255308.9062\n",
      "Epoch [150/250], Training Loss: 753718.9479, Validation Loss: 174850.7812\n",
      "Early stopping after 183 epochs. Best validation loss: 152648.8984\n",
      "Epoch [50/250], Training Loss: 1101541.3403, Validation Loss: 431632.5469\n",
      "Epoch [100/250], Training Loss: 807061.7847, Validation Loss: 248980.8047\n",
      "Epoch [150/250], Training Loss: 753266.4965, Validation Loss: 168618.8750\n",
      "Early stopping after 185 epochs. Best validation loss: 146115.9766\n",
      "Epoch [50/250], Training Loss: 1101445.1389, Validation Loss: 431956.3281\n",
      "Epoch [100/250], Training Loss: 809325.6806, Validation Loss: 251119.6172\n",
      "Epoch [150/250], Training Loss: 753135.8785, Validation Loss: 168464.0625\n",
      "Early stopping after 170 epochs. Best validation loss: 155346.9531\n",
      "Epoch [50/250], Training Loss: 1101378.1042, Validation Loss: 431889.8750\n",
      "Epoch [100/250], Training Loss: 810221.3472, Validation Loss: 252287.7891\n",
      "Epoch [150/250], Training Loss: 753349.4132, Validation Loss: 171425.3047\n",
      "Early stopping after 177 epochs. Best validation loss: 149480.3672\n",
      "Epoch [50/250], Training Loss: 1101376.2292, Validation Loss: 431888.1250\n",
      "Epoch [100/250], Training Loss: 806943.8889, Validation Loss: 252388.9531\n",
      "Epoch [150/250], Training Loss: 752692.4931, Validation Loss: 175358.8203\n",
      "Early stopping after 177 epochs. Best validation loss: 150999.9219\n",
      "Epoch [50/250], Training Loss: 1102670.4306, Validation Loss: 433280.1406\n",
      "Epoch [100/250], Training Loss: 809946.1181, Validation Loss: 252719.5859\n",
      "Epoch [150/250], Training Loss: 754316.5174, Validation Loss: 165624.3750\n",
      "Early stopping after 188 epochs. Best validation loss: 146007.9766\n",
      "Epoch [50/250], Training Loss: 1104534.0278, Validation Loss: 435209.4531\n",
      "Epoch [100/250], Training Loss: 818611.2361, Validation Loss: 253125.8047\n",
      "Epoch [150/250], Training Loss: 764452.5312, Validation Loss: 172936.0234\n",
      "Early stopping after 177 epochs. Best validation loss: 163282.2578\n",
      "Epoch [50/250], Training Loss: 1105171.2431, Validation Loss: 435879.8125\n",
      "Epoch [100/250], Training Loss: 813631.0208, Validation Loss: 254778.3516\n",
      "Epoch [150/250], Training Loss: 755129.7361, Validation Loss: 171237.2891\n",
      "Early stopping after 176 epochs. Best validation loss: 148756.0938\n",
      "Epoch [50/250], Training Loss: 861209.0139, Validation Loss: 253196.7109\n",
      "Epoch [100/250], Training Loss: 604543.3438, Validation Loss: 143240.2812\n",
      "Early stopping after 113 epochs. Best validation loss: 137754.1602\n",
      "Epoch [50/250], Training Loss: 854687.2292, Validation Loss: 245167.5000\n",
      "Epoch [100/250], Training Loss: 602348.5243, Validation Loss: 134588.3438\n",
      "Early stopping after 115 epochs. Best validation loss: 134582.3320\n",
      "Epoch [50/250], Training Loss: 861419.3403, Validation Loss: 252089.0156\n",
      "Epoch [100/250], Training Loss: 604320.3854, Validation Loss: 140641.0000\n",
      "Early stopping after 117 epochs. Best validation loss: 137569.2266\n",
      "Epoch [50/250], Training Loss: 856476.9722, Validation Loss: 254541.9531\n",
      "Epoch [100/250], Training Loss: 610762.1493, Validation Loss: 146122.9375\n",
      "Early stopping after 106 epochs. Best validation loss: 140911.3828\n",
      "Epoch [50/250], Training Loss: 849948.5104, Validation Loss: 246698.0625\n",
      "Epoch [100/250], Training Loss: 598536.8333, Validation Loss: 152972.6875\n",
      "Early stopping after 104 epochs. Best validation loss: 147773.0234\n",
      "Epoch [50/250], Training Loss: 853644.2778, Validation Loss: 248421.6094\n",
      "Epoch [100/250], Training Loss: 600887.5729, Validation Loss: 149780.2734\n",
      "Early stopping after 105 epochs. Best validation loss: 142095.1719\n",
      "Epoch [50/250], Training Loss: 868361.5486, Validation Loss: 249027.2812\n",
      "Epoch [100/250], Training Loss: 598200.2396, Validation Loss: 151798.9922\n",
      "Early stopping after 114 epochs. Best validation loss: 149680.6484\n",
      "Epoch [50/250], Training Loss: 862091.8056, Validation Loss: 251509.2969\n",
      "Epoch [100/250], Training Loss: 599114.1979, Validation Loss: 151897.9922\n",
      "Early stopping after 105 epochs. Best validation loss: 144603.2734\n",
      "Epoch [50/250], Training Loss: 852424.2014, Validation Loss: 245120.7812\n",
      "Epoch [100/250], Training Loss: 603542.5382, Validation Loss: 158536.6406\n",
      "Early stopping after 108 epochs. Best validation loss: 150573.6094\n",
      "Training model for hour 19\n",
      "Epoch [50/250], Training Loss: 973082.9306, Validation Loss: 418903.8281\n",
      "Epoch [100/250], Training Loss: 912114.2778, Validation Loss: 292661.2578\n",
      "Epoch [150/250], Training Loss: 820792.2083, Validation Loss: 204118.3359\n",
      "Epoch [200/250], Training Loss: 640475.0104, Validation Loss: 146926.3711\n",
      "Epoch [250/250], Training Loss: 660500.8264, Validation Loss: 108332.5352\n",
      "Training stopped after 249 epochs. Best validation loss: 107558.9727\n",
      "Epoch [50/250], Training Loss: 973082.8542, Validation Loss: 418903.9375\n",
      "Epoch [100/250], Training Loss: 911018.9931, Validation Loss: 292363.9375\n",
      "Epoch [150/250], Training Loss: 820655.0972, Validation Loss: 206932.5938\n",
      "Epoch [200/250], Training Loss: 640155.0104, Validation Loss: 147549.8672\n",
      "Epoch [250/250], Training Loss: 660131.2431, Validation Loss: 113587.1953\n",
      "Training stopped after 249 epochs. Best validation loss: 113587.1953\n",
      "Epoch [50/250], Training Loss: 973082.8542, Validation Loss: 418903.9688\n",
      "Epoch [100/250], Training Loss: 911409.5903, Validation Loss: 292442.7500\n",
      "Epoch [150/250], Training Loss: 820744.8611, Validation Loss: 204806.7969\n",
      "Epoch [200/250], Training Loss: 640323.7743, Validation Loss: 147763.4727\n",
      "Epoch [250/250], Training Loss: 660268.5833, Validation Loss: 112133.2461\n",
      "Training stopped after 249 epochs. Best validation loss: 112133.2461\n",
      "Epoch [50/250], Training Loss: 973027.5833, Validation Loss: 419065.0781\n",
      "Epoch [100/250], Training Loss: 912895.8611, Validation Loss: 292937.4219\n",
      "Epoch [150/250], Training Loss: 820779.0417, Validation Loss: 203968.1328\n",
      "Epoch [200/250], Training Loss: 639781.7882, Validation Loss: 144086.1641\n",
      "Epoch [250/250], Training Loss: 659810.5312, Validation Loss: 109430.9727\n",
      "Training stopped after 249 epochs. Best validation loss: 109430.9727\n",
      "Epoch [50/250], Training Loss: 973474.8611, Validation Loss: 419156.6250\n",
      "Epoch [100/250], Training Loss: 911386.1875, Validation Loss: 292874.9141\n",
      "Epoch [150/250], Training Loss: 819795.5764, Validation Loss: 204266.5938\n",
      "Epoch [200/250], Training Loss: 639741.9306, Validation Loss: 142904.9414\n",
      "Epoch [250/250], Training Loss: 659680.1111, Validation Loss: 107206.0000\n",
      "Training stopped after 249 epochs. Best validation loss: 107206.0000\n",
      "Epoch [50/250], Training Loss: 973475.0069, Validation Loss: 419156.7031\n",
      "Epoch [100/250], Training Loss: 912172.5903, Validation Loss: 293011.8750\n",
      "Epoch [150/250], Training Loss: 819929.0694, Validation Loss: 203554.6562\n",
      "Epoch [200/250], Training Loss: 639555.4514, Validation Loss: 144114.1797\n",
      "Epoch [250/250], Training Loss: 659772.7153, Validation Loss: 108088.7266\n",
      "Training stopped after 249 epochs. Best validation loss: 108088.7266\n",
      "Epoch [50/250], Training Loss: 972988.2083, Validation Loss: 419096.5000\n",
      "Epoch [100/250], Training Loss: 913011.2847, Validation Loss: 293092.8281\n",
      "Epoch [150/250], Training Loss: 820741.7222, Validation Loss: 204056.0156\n",
      "Epoch [200/250], Training Loss: 639920.3160, Validation Loss: 145867.0547\n",
      "Epoch [250/250], Training Loss: 659607.5208, Validation Loss: 113962.4531\n",
      "Training stopped after 249 epochs. Best validation loss: 113503.7266\n",
      "Epoch [50/250], Training Loss: 972987.6528, Validation Loss: 419096.8750\n",
      "Epoch [100/250], Training Loss: 913010.2361, Validation Loss: 293092.9766\n",
      "Epoch [150/250], Training Loss: 820665.3681, Validation Loss: 204750.8047\n",
      "Epoch [200/250], Training Loss: 639905.6424, Validation Loss: 144681.1406\n",
      "Epoch [250/250], Training Loss: 659531.2431, Validation Loss: 106310.4062\n",
      "Training stopped after 249 epochs. Best validation loss: 106310.4062\n",
      "Epoch [50/250], Training Loss: 972987.4514, Validation Loss: 419096.7969\n",
      "Epoch [100/250], Training Loss: 913010.0347, Validation Loss: 293092.8906\n",
      "Epoch [150/250], Training Loss: 820951.3472, Validation Loss: 204382.7422\n",
      "Epoch [200/250], Training Loss: 640040.6493, Validation Loss: 144239.1719\n",
      "Epoch [250/250], Training Loss: 659999.4549, Validation Loss: 109853.6172\n",
      "Training stopped after 249 epochs. Best validation loss: 109853.6172\n",
      "Epoch [50/250], Training Loss: 905778.3681, Validation Loss: 290358.2812\n",
      "Epoch [100/250], Training Loss: 663269.3194, Validation Loss: 148002.9062\n",
      "Epoch [150/250], Training Loss: 602866.9167, Validation Loss: 93404.3477\n",
      "Early stopping after 169 epochs. Best validation loss: 87247.8711\n",
      "Epoch [50/250], Training Loss: 905779.6597, Validation Loss: 290358.9922\n",
      "Epoch [100/250], Training Loss: 660296.0243, Validation Loss: 148181.4375\n",
      "Epoch [150/250], Training Loss: 602037.5625, Validation Loss: 94064.1133\n",
      "Early stopping after 167 epochs. Best validation loss: 89518.0000\n",
      "Epoch [50/250], Training Loss: 905779.6875, Validation Loss: 290359.0156\n",
      "Epoch [100/250], Training Loss: 660402.0382, Validation Loss: 148244.8789\n",
      "Epoch [150/250], Training Loss: 602136.6597, Validation Loss: 97739.3594\n",
      "Early stopping after 157 epochs. Best validation loss: 91861.5703\n",
      "Epoch [50/250], Training Loss: 905616.4236, Validation Loss: 290601.1094\n",
      "Epoch [100/250], Training Loss: 659300.6667, Validation Loss: 148803.8906\n",
      "Epoch [150/250], Training Loss: 601267.7118, Validation Loss: 96842.5547\n",
      "Early stopping after 176 epochs. Best validation loss: 91026.9688\n",
      "Epoch [50/250], Training Loss: 905614.3958, Validation Loss: 290600.2344\n",
      "Epoch [100/250], Training Loss: 659306.6389, Validation Loss: 144499.8438\n",
      "Epoch [150/250], Training Loss: 601164.0799, Validation Loss: 91564.5469\n",
      "Early stopping after 169 epochs. Best validation loss: 89004.9688\n",
      "Epoch [50/250], Training Loss: 905614.7431, Validation Loss: 290600.5312\n",
      "Epoch [100/250], Training Loss: 660383.5972, Validation Loss: 146283.8906\n",
      "Epoch [150/250], Training Loss: 602472.0729, Validation Loss: 93853.9961\n",
      "Early stopping after 160 epochs. Best validation loss: 91330.7383\n",
      "Epoch [50/250], Training Loss: 906846.9375, Validation Loss: 291873.0391\n",
      "Epoch [100/250], Training Loss: 660840.8194, Validation Loss: 146024.0625\n",
      "Epoch [150/250], Training Loss: 602180.1181, Validation Loss: 90482.5312\n",
      "Early stopping after 182 epochs. Best validation loss: 87547.4961\n",
      "Epoch [50/250], Training Loss: 906916.1875, Validation Loss: 291938.0000\n",
      "Epoch [100/250], Training Loss: 660883.6632, Validation Loss: 147277.3906\n",
      "Epoch [150/250], Training Loss: 602649.6285, Validation Loss: 92341.4766\n",
      "Early stopping after 168 epochs. Best validation loss: 89037.6445\n",
      "Epoch [50/250], Training Loss: 906919.7014, Validation Loss: 291941.3438\n",
      "Epoch [100/250], Training Loss: 660647.6944, Validation Loss: 145467.3359\n",
      "Epoch [150/250], Training Loss: 603982.7778, Validation Loss: 100130.2109\n",
      "Early stopping after 162 epochs. Best validation loss: 98520.6797\n",
      "Epoch [50/250], Training Loss: 700638.0243, Validation Loss: 145492.9922\n",
      "Early stopping after 96 epochs. Best validation loss: 91052.2461\n",
      "Epoch [50/250], Training Loss: 709414.3368, Validation Loss: 151097.1367\n",
      "Early stopping after 98 epochs. Best validation loss: 87630.6016\n",
      "Epoch [50/250], Training Loss: 701181.4826, Validation Loss: 147961.2500\n",
      "Early stopping after 94 epochs. Best validation loss: 88870.9258\n",
      "Epoch [50/250], Training Loss: 697861.8056, Validation Loss: 145933.5625\n",
      "Early stopping after 94 epochs. Best validation loss: 89399.5820\n",
      "Epoch [50/250], Training Loss: 703258.0347, Validation Loss: 149708.3516\n",
      "Early stopping after 89 epochs. Best validation loss: 93810.9492\n",
      "Epoch [50/250], Training Loss: 702332.2604, Validation Loss: 151383.2109\n",
      "Early stopping after 86 epochs. Best validation loss: 94622.0781\n",
      "Epoch [50/250], Training Loss: 720428.8681, Validation Loss: 161094.7109\n",
      "Epoch [100/250], Training Loss: 500058.8125, Validation Loss: 95470.5547\n",
      "Early stopping after 104 epochs. Best validation loss: 86864.5664\n",
      "Epoch [50/250], Training Loss: 712742.4965, Validation Loss: 154824.2500\n",
      "Early stopping after 96 epochs. Best validation loss: 92085.7266\n",
      "Epoch [50/250], Training Loss: 714517.1146, Validation Loss: 153370.5898\n",
      "Early stopping after 91 epochs. Best validation loss: 94584.1562\n",
      "Training model for hour 20\n",
      "Epoch [50/250], Training Loss: 820415.8681, Validation Loss: 287499.2188\n",
      "Epoch [100/250], Training Loss: 759112.2917, Validation Loss: 185313.9844\n",
      "Epoch [150/250], Training Loss: 666825.2014, Validation Loss: 119666.1367\n",
      "Epoch [200/250], Training Loss: 527275.8576, Validation Loss: 84344.5039\n",
      "Epoch [250/250], Training Loss: 546313.2344, Validation Loss: 67128.4883\n",
      "Training stopped after 249 epochs. Best validation loss: 67019.1289\n",
      "Epoch [50/250], Training Loss: 820415.7292, Validation Loss: 287499.3125\n",
      "Epoch [100/250], Training Loss: 759640.4479, Validation Loss: 185535.3047\n",
      "Epoch [150/250], Training Loss: 666929.8194, Validation Loss: 120243.2969\n",
      "Epoch [200/250], Training Loss: 527269.1285, Validation Loss: 82157.6758\n",
      "Epoch [250/250], Training Loss: 546268.6493, Validation Loss: 63347.4766\n",
      "Training stopped after 249 epochs. Best validation loss: 62011.7422\n",
      "Epoch [50/250], Training Loss: 820415.6875, Validation Loss: 287499.3281\n",
      "Epoch [100/250], Training Loss: 759536.9688, Validation Loss: 185522.5078\n",
      "Epoch [150/250], Training Loss: 666818.4861, Validation Loss: 119990.6719\n",
      "Epoch [200/250], Training Loss: 527128.0625, Validation Loss: 82953.6016\n",
      "Epoch [250/250], Training Loss: 545975.3698, Validation Loss: 64918.4395\n",
      "Training stopped after 249 epochs. Best validation loss: 64918.4395\n",
      "Epoch [50/250], Training Loss: 820379.7083, Validation Loss: 287676.3984\n",
      "Epoch [100/250], Training Loss: 759103.3160, Validation Loss: 185809.9844\n",
      "Epoch [150/250], Training Loss: 666432.4306, Validation Loss: 119239.7695\n",
      "Epoch [200/250], Training Loss: 526942.0451, Validation Loss: 81350.0547\n",
      "Epoch [250/250], Training Loss: 546076.3351, Validation Loss: 63186.8965\n",
      "Training stopped after 249 epochs. Best validation loss: 62924.5352\n",
      "Epoch [50/250], Training Loss: 820379.4097, Validation Loss: 287676.4375\n",
      "Epoch [100/250], Training Loss: 759039.9167, Validation Loss: 185740.3828\n",
      "Epoch [150/250], Training Loss: 666304.7812, Validation Loss: 117833.7578\n",
      "Epoch [200/250], Training Loss: 526844.1944, Validation Loss: 77503.7422\n",
      "Epoch [250/250], Training Loss: 545810.9913, Validation Loss: 57719.4453\n",
      "Training stopped after 249 epochs. Best validation loss: 57719.4453\n",
      "Epoch [50/250], Training Loss: 820379.3056, Validation Loss: 287676.3906\n",
      "Epoch [100/250], Training Loss: 758951.5104, Validation Loss: 185714.6328\n",
      "Epoch [150/250], Training Loss: 666401.8576, Validation Loss: 119286.9922\n",
      "Epoch [200/250], Training Loss: 526868.2743, Validation Loss: 78269.0938\n",
      "Epoch [250/250], Training Loss: 546144.5885, Validation Loss: 58693.1797\n",
      "Training stopped after 249 epochs. Best validation loss: 58693.1797\n",
      "Epoch [50/250], Training Loss: 820339.9514, Validation Loss: 287686.7969\n",
      "Epoch [100/250], Training Loss: 759567.1944, Validation Loss: 185985.0156\n",
      "Epoch [150/250], Training Loss: 666239.9028, Validation Loss: 117962.7500\n",
      "Epoch [200/250], Training Loss: 526747.9479, Validation Loss: 77734.5977\n",
      "Epoch [250/250], Training Loss: 545870.2847, Validation Loss: 59044.2324\n",
      "Training stopped after 249 epochs. Best validation loss: 59044.2324\n",
      "Epoch [50/250], Training Loss: 820339.0208, Validation Loss: 287686.6328\n",
      "Epoch [100/250], Training Loss: 760002.7882, Validation Loss: 186074.4844\n",
      "Epoch [150/250], Training Loss: 667341.6111, Validation Loss: 118133.2812\n",
      "Epoch [200/250], Training Loss: 527201.4688, Validation Loss: 77519.1797\n",
      "Epoch [250/250], Training Loss: 546195.0017, Validation Loss: 59526.7988\n",
      "Training stopped after 249 epochs. Best validation loss: 59526.7988\n",
      "Epoch [50/250], Training Loss: 820338.9236, Validation Loss: 287686.6484\n",
      "Epoch [100/250], Training Loss: 760524.3194, Validation Loss: 186097.9844\n",
      "Epoch [150/250], Training Loss: 666540.7500, Validation Loss: 118155.7188\n",
      "Epoch [200/250], Training Loss: 526881.4479, Validation Loss: 77899.2070\n",
      "Epoch [250/250], Training Loss: 545762.5226, Validation Loss: 59789.4336\n",
      "Training stopped after 249 epochs. Best validation loss: 59654.0762\n",
      "Epoch [50/250], Training Loss: 763442.0590, Validation Loss: 183911.9219\n",
      "Epoch [100/250], Training Loss: 545133.5035, Validation Loss: 79377.8398\n",
      "Epoch [150/250], Training Loss: 491882.5347, Validation Loss: 57944.6289\n",
      "Early stopping after 150 epochs. Best validation loss: 56856.4844\n",
      "Epoch [50/250], Training Loss: 763028.7708, Validation Loss: 183911.6719\n",
      "Epoch [100/250], Training Loss: 544440.2847, Validation Loss: 80376.8359\n",
      "Epoch [150/250], Training Loss: 491480.5972, Validation Loss: 62303.5996\n",
      "Early stopping after 149 epochs. Best validation loss: 60191.5625\n",
      "Epoch [50/250], Training Loss: 761418.0451, Validation Loss: 184285.6953\n",
      "Epoch [100/250], Training Loss: 543940.3819, Validation Loss: 78386.9336\n",
      "Epoch [150/250], Training Loss: 491377.4653, Validation Loss: 59392.3867\n",
      "Early stopping after 149 epochs. Best validation loss: 57781.7539\n",
      "Epoch [50/250], Training Loss: 761037.1319, Validation Loss: 184246.8281\n",
      "Epoch [100/250], Training Loss: 543057.9931, Validation Loss: 78141.9688\n",
      "Early stopping after 148 epochs. Best validation loss: 55677.6797\n",
      "Epoch [50/250], Training Loss: 764639.3889, Validation Loss: 184263.3281\n",
      "Epoch [100/250], Training Loss: 543127.3021, Validation Loss: 77904.8750\n",
      "Epoch [150/250], Training Loss: 490180.8715, Validation Loss: 56398.9336\n",
      "Early stopping after 151 epochs. Best validation loss: 54993.1523\n",
      "Epoch [50/250], Training Loss: 761152.6319, Validation Loss: 184248.2422\n",
      "Epoch [100/250], Training Loss: 542781.2361, Validation Loss: 80528.8125\n",
      "Early stopping after 148 epochs. Best validation loss: 56914.5137\n",
      "Epoch [50/250], Training Loss: 761971.1181, Validation Loss: 185123.7344\n",
      "Epoch [100/250], Training Loss: 544647.2708, Validation Loss: 79517.1016\n",
      "Epoch [150/250], Training Loss: 491514.9236, Validation Loss: 56746.4668\n",
      "Early stopping after 156 epochs. Best validation loss: 56128.9980\n",
      "Epoch [50/250], Training Loss: 762019.4757, Validation Loss: 185164.9688\n",
      "Epoch [100/250], Training Loss: 544179.1806, Validation Loss: 79429.3867\n",
      "Epoch [150/250], Training Loss: 491211.5590, Validation Loss: 56149.7344\n",
      "Early stopping after 152 epochs. Best validation loss: 54978.7715\n",
      "Epoch [50/250], Training Loss: 762064.5625, Validation Loss: 185202.9688\n",
      "Epoch [100/250], Training Loss: 544372.8472, Validation Loss: 80497.2617\n",
      "Epoch [150/250], Training Loss: 491280.1007, Validation Loss: 56733.7676\n",
      "Early stopping after 158 epochs. Best validation loss: 54532.5508\n",
      "Epoch [50/250], Training Loss: 578239.8194, Validation Loss: 81186.4688\n",
      "Early stopping after 83 epochs. Best validation loss: 56567.4551\n",
      "Epoch [50/250], Training Loss: 578681.7639, Validation Loss: 81135.1172\n",
      "Early stopping after 80 epochs. Best validation loss: 57284.9883\n",
      "Epoch [50/250], Training Loss: 578870.4653, Validation Loss: 80313.6016\n",
      "Early stopping after 79 epochs. Best validation loss: 54682.1191\n",
      "Epoch [50/250], Training Loss: 574421.6146, Validation Loss: 81340.1602\n",
      "Early stopping after 83 epochs. Best validation loss: 58818.4551\n",
      "Epoch [50/250], Training Loss: 583262.7535, Validation Loss: 82035.7227\n",
      "Early stopping after 86 epochs. Best validation loss: 54914.9434\n",
      "Epoch [50/250], Training Loss: 579418.1285, Validation Loss: 81005.7617\n",
      "Early stopping after 81 epochs. Best validation loss: 55592.7422\n",
      "Epoch [50/250], Training Loss: 584811.9028, Validation Loss: 88845.5625\n",
      "Early stopping after 83 epochs. Best validation loss: 60813.5449\n",
      "Epoch [50/250], Training Loss: 582465.4479, Validation Loss: 84104.6914\n",
      "Early stopping after 82 epochs. Best validation loss: 58005.2363\n",
      "Epoch [50/250], Training Loss: 586869.0694, Validation Loss: 82706.8789\n",
      "Early stopping after 85 epochs. Best validation loss: 55161.6152\n",
      "Training model for hour 21\n",
      "Epoch [50/250], Training Loss: 666513.2083, Validation Loss: 210318.3359\n",
      "Epoch [100/250], Training Loss: 614000.7812, Validation Loss: 126708.6641\n",
      "Epoch [150/250], Training Loss: 529971.8194, Validation Loss: 77066.7070\n",
      "Epoch [200/250], Training Loss: 415016.1892, Validation Loss: 51909.8926\n",
      "Early stopping after 248 epochs. Best validation loss: 43980.9551\n",
      "Epoch [50/250], Training Loss: 666513.0000, Validation Loss: 210318.4453\n",
      "Epoch [100/250], Training Loss: 614052.7569, Validation Loss: 126694.8984\n",
      "Epoch [150/250], Training Loss: 529876.0278, Validation Loss: 76721.9492\n",
      "Epoch [200/250], Training Loss: 415013.7708, Validation Loss: 51374.0605\n",
      "Epoch [250/250], Training Loss: 413312.4115, Validation Loss: 45682.0332\n",
      "Training stopped after 249 epochs. Best validation loss: 42961.6963\n",
      "Epoch [50/250], Training Loss: 666512.9549, Validation Loss: 210318.4453\n",
      "Epoch [100/250], Training Loss: 613909.3403, Validation Loss: 126688.5547\n",
      "Epoch [150/250], Training Loss: 529916.7396, Validation Loss: 79217.9062\n",
      "Epoch [200/250], Training Loss: 414959.9201, Validation Loss: 54381.9219\n",
      "Early stopping after 226 epochs. Best validation loss: 48590.9570\n",
      "Epoch [50/250], Training Loss: 666425.7361, Validation Loss: 210479.1406\n",
      "Epoch [100/250], Training Loss: 613742.1806, Validation Loss: 126812.5078\n",
      "Epoch [150/250], Training Loss: 528990.9514, Validation Loss: 77035.6719\n",
      "Epoch [200/250], Training Loss: 414244.9774, Validation Loss: 51739.4219\n",
      "Epoch [250/250], Training Loss: 412414.9948, Validation Loss: 44455.8086\n",
      "Training stopped after 249 epochs. Best validation loss: 44359.2539\n",
      "Epoch [50/250], Training Loss: 666425.6771, Validation Loss: 210479.4062\n",
      "Epoch [100/250], Training Loss: 613651.8576, Validation Loss: 126845.4883\n",
      "Epoch [150/250], Training Loss: 529305.4965, Validation Loss: 75121.8828\n",
      "Epoch [200/250], Training Loss: 414601.5087, Validation Loss: 51023.2188\n",
      "Early stopping after 241 epochs. Best validation loss: 44927.9961\n",
      "Epoch [50/250], Training Loss: 666425.6424, Validation Loss: 210479.4062\n",
      "Epoch [100/250], Training Loss: 613510.1424, Validation Loss: 126703.4570\n",
      "Epoch [150/250], Training Loss: 529178.9965, Validation Loss: 76494.9688\n",
      "Epoch [200/250], Training Loss: 414642.0694, Validation Loss: 50406.2090\n",
      "Epoch [250/250], Training Loss: 412898.5642, Validation Loss: 41966.4219\n",
      "Training stopped after 249 epochs. Best validation loss: 41966.4219\n",
      "Epoch [50/250], Training Loss: 666458.2500, Validation Loss: 210495.6094\n",
      "Epoch [100/250], Training Loss: 613443.8194, Validation Loss: 126846.4766\n",
      "Epoch [150/250], Training Loss: 529094.2049, Validation Loss: 74963.5859\n",
      "Epoch [200/250], Training Loss: 414503.5677, Validation Loss: 49182.1113\n",
      "Epoch [250/250], Training Loss: 412892.7448, Validation Loss: 42191.4502\n",
      "Training stopped after 249 epochs. Best validation loss: 41871.3838\n",
      "Epoch [50/250], Training Loss: 666457.5139, Validation Loss: 210495.6797\n",
      "Epoch [100/250], Training Loss: 613482.9444, Validation Loss: 126917.6055\n",
      "Epoch [150/250], Training Loss: 528822.2083, Validation Loss: 76073.3398\n",
      "Epoch [200/250], Training Loss: 414338.3524, Validation Loss: 49292.2617\n",
      "Epoch [250/250], Training Loss: 412817.8559, Validation Loss: 43181.6211\n",
      "Training stopped after 249 epochs. Best validation loss: 42972.3477\n",
      "Epoch [50/250], Training Loss: 666457.3229, Validation Loss: 210495.6016\n",
      "Epoch [100/250], Training Loss: 613510.0347, Validation Loss: 126923.6328\n",
      "Epoch [150/250], Training Loss: 528965.4236, Validation Loss: 76234.3477\n",
      "Epoch [200/250], Training Loss: 414395.5868, Validation Loss: 49643.5039\n",
      "Early stopping after 242 epochs. Best validation loss: 44246.9297\n",
      "Epoch [50/250], Training Loss: 613864.6250, Validation Loss: 125062.9219\n",
      "Epoch [100/250], Training Loss: 430414.5174, Validation Loss: 52353.2070\n",
      "Early stopping after 136 epochs. Best validation loss: 42984.8848\n",
      "Epoch [50/250], Training Loss: 613778.2083, Validation Loss: 125055.1523\n",
      "Epoch [100/250], Training Loss: 430297.6042, Validation Loss: 54372.6055\n",
      "Early stopping after 136 epochs. Best validation loss: 44801.3242\n",
      "Epoch [50/250], Training Loss: 613899.0972, Validation Loss: 125082.8281\n",
      "Epoch [100/250], Training Loss: 430374.1215, Validation Loss: 51953.4746\n",
      "Early stopping after 133 epochs. Best validation loss: 44209.8652\n",
      "Epoch [50/250], Training Loss: 613938.9792, Validation Loss: 125576.5000\n",
      "Epoch [100/250], Training Loss: 429707.6944, Validation Loss: 50123.3125\n",
      "Early stopping after 132 epochs. Best validation loss: 43092.2744\n",
      "Epoch [50/250], Training Loss: 613466.7465, Validation Loss: 125587.1406\n",
      "Epoch [100/250], Training Loss: 429603.6701, Validation Loss: 51411.3379\n",
      "Early stopping after 132 epochs. Best validation loss: 41963.5371\n",
      "Epoch [50/250], Training Loss: 614679.5278, Validation Loss: 126158.1992\n",
      "Epoch [100/250], Training Loss: 430495.5243, Validation Loss: 51171.1113\n",
      "Early stopping after 144 epochs. Best validation loss: 42226.8359\n",
      "Epoch [50/250], Training Loss: 616330.8576, Validation Loss: 126149.1094\n",
      "Epoch [100/250], Training Loss: 430920.9826, Validation Loss: 50622.9648\n",
      "Early stopping after 132 epochs. Best validation loss: 43766.0684\n",
      "Epoch [50/250], Training Loss: 616667.0000, Validation Loss: 126437.3516\n",
      "Epoch [100/250], Training Loss: 432925.0625, Validation Loss: 52118.2324\n",
      "Early stopping after 140 epochs. Best validation loss: 42807.3145\n",
      "Epoch [50/250], Training Loss: 616500.8681, Validation Loss: 126301.3594\n",
      "Epoch [100/250], Training Loss: 431643.3090, Validation Loss: 49915.0957\n",
      "Early stopping after 135 epochs. Best validation loss: 41525.0625\n",
      "Epoch [50/250], Training Loss: 458576.9948, Validation Loss: 51775.0527\n",
      "Early stopping after 73 epochs. Best validation loss: 42651.9512\n",
      "Epoch [50/250], Training Loss: 457709.4462, Validation Loss: 50638.1719\n",
      "Early stopping after 77 epochs. Best validation loss: 44352.8457\n",
      "Epoch [50/250], Training Loss: 459412.7899, Validation Loss: 53440.0625\n",
      "Early stopping after 68 epochs. Best validation loss: 45084.0410\n",
      "Epoch [50/250], Training Loss: 457535.6128, Validation Loss: 51829.6953\n",
      "Early stopping after 69 epochs. Best validation loss: 43994.4863\n",
      "Epoch [50/250], Training Loss: 457172.2795, Validation Loss: 50948.8770\n",
      "Early stopping after 72 epochs. Best validation loss: 42802.0010\n",
      "Epoch [50/250], Training Loss: 457480.6788, Validation Loss: 50316.4902\n",
      "Early stopping after 71 epochs. Best validation loss: 43252.9688\n",
      "Epoch [50/250], Training Loss: 464273.2188, Validation Loss: 51392.9062\n",
      "Early stopping after 75 epochs. Best validation loss: 42061.9355\n",
      "Epoch [50/250], Training Loss: 489611.0903, Validation Loss: 55541.3633\n",
      "Early stopping after 78 epochs. Best validation loss: 42780.3359\n",
      "Epoch [50/250], Training Loss: 487723.6111, Validation Loss: 56348.1523\n",
      "Early stopping after 72 epochs. Best validation loss: 45547.6348\n",
      "Training model for hour 22\n",
      "Epoch [50/250], Training Loss: 574764.5486, Validation Loss: 192832.6562\n",
      "Epoch [100/250], Training Loss: 532891.1771, Validation Loss: 117906.0195\n",
      "Epoch [150/250], Training Loss: 461429.7014, Validation Loss: 76124.1016\n",
      "Epoch [200/250], Training Loss: 361459.2743, Validation Loss: 56102.9668\n",
      "Early stopping after 239 epochs. Best validation loss: 51691.0469\n",
      "Epoch [50/250], Training Loss: 574764.4097, Validation Loss: 192832.7344\n",
      "Epoch [100/250], Training Loss: 533276.1181, Validation Loss: 117846.3594\n",
      "Epoch [150/250], Training Loss: 461913.9618, Validation Loss: 74436.1914\n",
      "Epoch [200/250], Training Loss: 361434.9392, Validation Loss: 53507.5430\n",
      "Early stopping after 244 epochs. Best validation loss: 48992.5293\n",
      "Epoch [50/250], Training Loss: 574764.3715, Validation Loss: 192832.7656\n",
      "Epoch [100/250], Training Loss: 532941.7604, Validation Loss: 117738.4219\n",
      "Epoch [150/250], Training Loss: 461753.3542, Validation Loss: 76716.9102\n",
      "Epoch [200/250], Training Loss: 361391.6163, Validation Loss: 56945.9980\n",
      "Early stopping after 227 epochs. Best validation loss: 54620.2637\n",
      "Epoch [50/250], Training Loss: 574736.8681, Validation Loss: 192998.7734\n",
      "Epoch [100/250], Training Loss: 532416.4757, Validation Loss: 117983.2461\n",
      "Epoch [150/250], Training Loss: 461647.3056, Validation Loss: 75267.0000\n",
      "Epoch [200/250], Training Loss: 361272.5712, Validation Loss: 56572.7734\n",
      "Early stopping after 228 epochs. Best validation loss: 52902.2480\n",
      "Epoch [50/250], Training Loss: 574736.8542, Validation Loss: 192998.7578\n",
      "Epoch [100/250], Training Loss: 532520.9375, Validation Loss: 117889.9102\n",
      "Epoch [150/250], Training Loss: 461040.7847, Validation Loss: 74500.5039\n",
      "Epoch [200/250], Training Loss: 361065.7326, Validation Loss: 55543.2559\n",
      "Early stopping after 218 epochs. Best validation loss: 54077.3301\n",
      "Epoch [50/250], Training Loss: 574737.0139, Validation Loss: 192998.7656\n",
      "Epoch [100/250], Training Loss: 532547.8021, Validation Loss: 117962.9414\n",
      "Epoch [150/250], Training Loss: 460939.1736, Validation Loss: 74677.8672\n",
      "Epoch [200/250], Training Loss: 360999.0851, Validation Loss: 53855.2148\n",
      "Early stopping after 232 epochs. Best validation loss: 51359.9824\n",
      "Epoch [50/250], Training Loss: 574628.1840, Validation Loss: 192947.6250\n",
      "Epoch [100/250], Training Loss: 532607.0903, Validation Loss: 118172.7227\n",
      "Epoch [150/250], Training Loss: 460944.3611, Validation Loss: 76362.5938\n",
      "Epoch [200/250], Training Loss: 361047.2726, Validation Loss: 55585.4688\n",
      "Early stopping after 246 epochs. Best validation loss: 50816.0977\n",
      "Epoch [50/250], Training Loss: 574603.2812, Validation Loss: 192925.5938\n",
      "Epoch [100/250], Training Loss: 532500.2153, Validation Loss: 118128.9727\n",
      "Epoch [150/250], Training Loss: 460831.0764, Validation Loss: 74117.1992\n",
      "Epoch [200/250], Training Loss: 360812.2552, Validation Loss: 53377.4941\n",
      "Early stopping after 240 epochs. Best validation loss: 49726.7031\n",
      "Epoch [50/250], Training Loss: 574592.7986, Validation Loss: 192916.0234\n",
      "Epoch [100/250], Training Loss: 533199.0972, Validation Loss: 118304.9102\n",
      "Epoch [150/250], Training Loss: 461056.2083, Validation Loss: 73859.5273\n",
      "Epoch [200/250], Training Loss: 361051.6701, Validation Loss: 52404.8086\n",
      "Early stopping after 244 epochs. Best validation loss: 49698.5723\n",
      "Epoch [50/250], Training Loss: 529359.4340, Validation Loss: 116563.5625\n",
      "Epoch [100/250], Training Loss: 382882.6319, Validation Loss: 55170.4688\n",
      "Early stopping after 125 epochs. Best validation loss: 51659.5469\n",
      "Epoch [50/250], Training Loss: 530149.1528, Validation Loss: 116663.4062\n",
      "Epoch [100/250], Training Loss: 382905.3038, Validation Loss: 56722.5488\n",
      "Early stopping after 123 epochs. Best validation loss: 49911.6133\n",
      "Epoch [50/250], Training Loss: 529833.6111, Validation Loss: 116617.1172\n",
      "Epoch [100/250], Training Loss: 383043.3368, Validation Loss: 61538.6113\n",
      "Early stopping after 132 epochs. Best validation loss: 57139.8379\n",
      "Epoch [50/250], Training Loss: 528849.4410, Validation Loss: 116671.9883\n",
      "Epoch [100/250], Training Loss: 381998.0139, Validation Loss: 55329.3848\n",
      "Early stopping after 127 epochs. Best validation loss: 50624.8555\n",
      "Epoch [50/250], Training Loss: 528455.1146, Validation Loss: 116540.2227\n",
      "Epoch [100/250], Training Loss: 381592.5851, Validation Loss: 55663.0117\n",
      "Early stopping after 122 epochs. Best validation loss: 52088.0371\n",
      "Epoch [50/250], Training Loss: 528586.2049, Validation Loss: 116646.5664\n",
      "Epoch [100/250], Training Loss: 381730.4149, Validation Loss: 56681.2656\n",
      "Early stopping after 125 epochs. Best validation loss: 51664.0820\n",
      "Epoch [50/250], Training Loss: 534041.1528, Validation Loss: 118215.2422\n",
      "Epoch [100/250], Training Loss: 383910.2917, Validation Loss: 56880.3926\n",
      "Early stopping after 135 epochs. Best validation loss: 51334.2500\n",
      "Epoch [50/250], Training Loss: 533971.6458, Validation Loss: 118158.0586\n",
      "Epoch [100/250], Training Loss: 383738.8941, Validation Loss: 55470.0273\n",
      "Early stopping after 136 epochs. Best validation loss: 49993.7715\n",
      "Epoch [50/250], Training Loss: 534044.1319, Validation Loss: 118216.7500\n",
      "Epoch [100/250], Training Loss: 383647.6476, Validation Loss: 54910.1738\n",
      "Early stopping after 122 epochs. Best validation loss: 49855.8867\n",
      "Epoch [50/250], Training Loss: 403380.0399, Validation Loss: 58157.1523\n",
      "Early stopping after 69 epochs. Best validation loss: 53189.2891\n",
      "Epoch [50/250], Training Loss: 401872.7500, Validation Loss: 57555.6133\n",
      "Early stopping after 71 epochs. Best validation loss: 52032.2051\n",
      "Epoch [50/250], Training Loss: 400658.9549, Validation Loss: 56194.7070\n",
      "Early stopping after 72 epochs. Best validation loss: 52227.5820\n",
      "Epoch [50/250], Training Loss: 403056.3854, Validation Loss: 55903.1973\n",
      "Early stopping after 75 epochs. Best validation loss: 50015.8262\n",
      "Epoch [50/250], Training Loss: 399118.6441, Validation Loss: 56711.1621\n",
      "Early stopping after 67 epochs. Best validation loss: 49240.4531\n",
      "Epoch [50/250], Training Loss: 398055.0990, Validation Loss: 54990.2637\n",
      "Early stopping after 74 epochs. Best validation loss: 51297.5430\n",
      "Epoch [50/250], Training Loss: 409873.4809, Validation Loss: 56829.9746\n",
      "Early stopping after 68 epochs. Best validation loss: 50506.3164\n",
      "Epoch [50/250], Training Loss: 403755.2552, Validation Loss: 57414.1738\n",
      "Early stopping after 71 epochs. Best validation loss: 51614.5664\n",
      "Epoch [50/250], Training Loss: 435554.9288, Validation Loss: 61476.3809\n",
      "Early stopping after 69 epochs. Best validation loss: 50866.3535\n",
      "Training model for hour 23\n",
      "Epoch [50/250], Training Loss: 521176.2361, Validation Loss: 160966.1797\n",
      "Epoch [100/250], Training Loss: 487776.0122, Validation Loss: 95959.0781\n",
      "Epoch [150/250], Training Loss: 410926.7153, Validation Loss: 62016.0527\n",
      "Epoch [200/250], Training Loss: 321493.6528, Validation Loss: 49912.7949\n",
      "Early stopping after 217 epochs. Best validation loss: 48024.2910\n",
      "Epoch [50/250], Training Loss: 521165.9965, Validation Loss: 160964.3359\n",
      "Epoch [100/250], Training Loss: 487594.1823, Validation Loss: 95862.2227\n",
      "Epoch [150/250], Training Loss: 411744.2951, Validation Loss: 60580.5488\n",
      "Epoch [200/250], Training Loss: 321606.7465, Validation Loss: 49762.3984\n",
      "Early stopping after 214 epochs. Best validation loss: 47505.9688\n",
      "Epoch [50/250], Training Loss: 521177.8611, Validation Loss: 160965.1719\n",
      "Epoch [100/250], Training Loss: 487696.6389, Validation Loss: 95954.7305\n",
      "Epoch [150/250], Training Loss: 410904.8819, Validation Loss: 61574.3027\n",
      "Epoch [200/250], Training Loss: 321683.2708, Validation Loss: 49890.3418\n",
      "Early stopping after 226 epochs. Best validation loss: 48246.2305\n",
      "Epoch [50/250], Training Loss: 521184.4375, Validation Loss: 161175.4766\n",
      "Epoch [100/250], Training Loss: 486657.9913, Validation Loss: 96085.2227\n",
      "Epoch [150/250], Training Loss: 410589.9097, Validation Loss: 61296.4941\n",
      "Epoch [200/250], Training Loss: 321144.0694, Validation Loss: 48267.1484\n",
      "Early stopping after 219 epochs. Best validation loss: 47304.2891\n",
      "Epoch [50/250], Training Loss: 521184.0174, Validation Loss: 161175.3672\n",
      "Epoch [100/250], Training Loss: 486860.5660, Validation Loss: 96183.6445\n",
      "Epoch [150/250], Training Loss: 410342.5000, Validation Loss: 62612.8398\n",
      "Epoch [200/250], Training Loss: 321078.7378, Validation Loss: 50220.4590\n",
      "Early stopping after 201 epochs. Best validation loss: 49171.8574\n",
      "Epoch [50/250], Training Loss: 521183.8924, Validation Loss: 161175.2734\n",
      "Epoch [100/250], Training Loss: 486440.4028, Validation Loss: 95979.2188\n",
      "Epoch [150/250], Training Loss: 410547.8958, Validation Loss: 62838.7715\n",
      "Epoch [200/250], Training Loss: 321224.8142, Validation Loss: 50490.5059\n",
      "Early stopping after 218 epochs. Best validation loss: 49895.6406\n",
      "Epoch [50/250], Training Loss: 521149.6354, Validation Loss: 161185.1328\n",
      "Epoch [100/250], Training Loss: 487134.5677, Validation Loss: 96191.6602\n",
      "Epoch [150/250], Training Loss: 410463.1424, Validation Loss: 63087.7969\n",
      "Epoch [200/250], Training Loss: 321049.9080, Validation Loss: 49987.8457\n",
      "Early stopping after 228 epochs. Best validation loss: 48445.4395\n",
      "Epoch [50/250], Training Loss: 521148.7639, Validation Loss: 161185.0078\n",
      "Epoch [100/250], Training Loss: 486862.6111, Validation Loss: 96141.7617\n",
      "Epoch [150/250], Training Loss: 410358.8194, Validation Loss: 61366.4590\n",
      "Epoch [200/250], Training Loss: 321135.3247, Validation Loss: 49907.9648\n",
      "Early stopping after 226 epochs. Best validation loss: 48790.7305\n",
      "Epoch [50/250], Training Loss: 521148.5625, Validation Loss: 161184.9219\n",
      "Epoch [100/250], Training Loss: 487057.0295, Validation Loss: 96186.8477\n",
      "Epoch [150/250], Training Loss: 410240.2292, Validation Loss: 61293.4238\n",
      "Epoch [200/250], Training Loss: 320955.9774, Validation Loss: 49718.5859\n",
      "Early stopping after 207 epochs. Best validation loss: 48645.4023\n",
      "Epoch [50/250], Training Loss: 480131.8715, Validation Loss: 96727.4180\n",
      "Epoch [100/250], Training Loss: 338473.4132, Validation Loss: 49773.4707\n",
      "Early stopping after 121 epochs. Best validation loss: 48710.6992\n",
      "Epoch [50/250], Training Loss: 474849.8993, Validation Loss: 94832.7656\n",
      "Epoch [100/250], Training Loss: 337877.1615, Validation Loss: 48859.5156\n",
      "Early stopping after 114 epochs. Best validation loss: 48082.6758\n",
      "Epoch [50/250], Training Loss: 474667.7500, Validation Loss: 94874.9414\n",
      "Epoch [100/250], Training Loss: 337787.8333, Validation Loss: 49203.4609\n",
      "Early stopping after 119 epochs. Best validation loss: 48114.3086\n",
      "Epoch [50/250], Training Loss: 473925.0903, Validation Loss: 94882.9688\n",
      "Epoch [100/250], Training Loss: 336797.6875, Validation Loss: 49258.5410\n",
      "Early stopping after 117 epochs. Best validation loss: 48447.6113\n",
      "Epoch [50/250], Training Loss: 474064.8819, Validation Loss: 94894.8867\n",
      "Epoch [100/250], Training Loss: 336786.8073, Validation Loss: 50699.6855\n",
      "Early stopping after 114 epochs. Best validation loss: 50000.3125\n",
      "Epoch [50/250], Training Loss: 474183.4861, Validation Loss: 95042.9883\n",
      "Epoch [100/250], Training Loss: 336881.5260, Validation Loss: 49936.4629\n",
      "Early stopping after 112 epochs. Best validation loss: 48917.8145\n",
      "Epoch [50/250], Training Loss: 481022.4549, Validation Loss: 96845.6680\n",
      "Epoch [100/250], Training Loss: 338932.0521, Validation Loss: 48830.7500\n",
      "Early stopping after 119 epochs. Best validation loss: 47513.2773\n",
      "Epoch [50/250], Training Loss: 481034.3993, Validation Loss: 96855.2773\n",
      "Epoch [100/250], Training Loss: 339135.7691, Validation Loss: 49845.3066\n",
      "Early stopping after 117 epochs. Best validation loss: 48427.4160\n",
      "Epoch [50/250], Training Loss: 481036.8021, Validation Loss: 96857.2227\n",
      "Epoch [100/250], Training Loss: 338669.7726, Validation Loss: 48895.0117\n",
      "Early stopping after 124 epochs. Best validation loss: 47673.9297\n",
      "Epoch [50/250], Training Loss: 358261.2847, Validation Loss: 52056.3730\n",
      "Early stopping after 65 epochs. Best validation loss: 50029.7715\n",
      "Epoch [50/250], Training Loss: 359561.0990, Validation Loss: 54120.1875\n",
      "Early stopping after 75 epochs. Best validation loss: 50388.8027\n",
      "Epoch [50/250], Training Loss: 353774.1962, Validation Loss: 50756.0918\n",
      "Early stopping after 78 epochs. Best validation loss: 48138.0977\n",
      "Epoch [50/250], Training Loss: 364541.1858, Validation Loss: 51790.6523\n",
      "Early stopping after 66 epochs. Best validation loss: 48762.7168\n",
      "Epoch [50/250], Training Loss: 352730.3177, Validation Loss: 50112.3340\n",
      "Early stopping after 62 epochs. Best validation loss: 49517.5430\n",
      "Epoch [50/250], Training Loss: 364705.4722, Validation Loss: 50625.4492\n",
      "Early stopping after 61 epochs. Best validation loss: 49141.1016\n",
      "Epoch [50/250], Training Loss: 363843.5573, Validation Loss: 51731.1621\n",
      "Early stopping after 58 epochs. Best validation loss: 51599.3359\n",
      "Epoch [50/250], Training Loss: 365161.9601, Validation Loss: 54735.7031\n",
      "Early stopping after 62 epochs. Best validation loss: 49763.6777\n",
      "Epoch [50/250], Training Loss: 373261.7101, Validation Loss: 51025.2441\n",
      "Early stopping after 64 epochs. Best validation loss: 48930.5840\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "num_epochs = 250\n",
    "patience = 10  # for early stopping\n",
    "best_loss_global = np.inf\n",
    "\n",
    "for i in range(24):\n",
    "    print(f\"Training model for hour {i}\")\n",
    "    for hidden_dim in hidden_dim_array:\n",
    "        for layer_dim in layer_dim_array:\n",
    "            for lambda_l1 in lambda_l1_array:\n",
    "                for lambda_l2 in lambda_l2_array:\n",
    "                    torch.manual_seed(2024)\n",
    "                    np.random.seed(2024)\n",
    "                    model = LSTMmodel(input_dim, hidden_dim, layer_dim, output_dim).to(device)\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                    # set seed for reproducibility\n",
    "                    best_loss = np.inf\n",
    "                    counter = 0\n",
    "\n",
    "                    # initialize lists to store loss values\n",
    "                    training_losses = []\n",
    "                    validation_losses = []\n",
    "\n",
    "                    for epoch in range(num_epochs):\n",
    "                        model.train()\n",
    "                        train_loss = 0\n",
    "                        for X_batch, y_batch in train_loader[i]:\n",
    "                            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            # forward pass\n",
    "                            outputs = model(X_batch)\n",
    "\n",
    "                            mse_loss = criterion(outputs.squeeze(), y_batch.squeeze())\n",
    "\n",
    "                            # L1 regularization\n",
    "                            l1_loss = l1_regularization(model, lambda_l1)\n",
    "                            l2_loss = l2_regularization(model, lambda_l2)\n",
    "\n",
    "                            # calc total loss\n",
    "                            loss = mse_loss + l1_loss + l2_loss\n",
    "\n",
    "                            # backward pass and optimization\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                            train_loss += loss.item()\n",
    "\n",
    "\n",
    "                        # average training loss\n",
    "                        avg_train_loss = train_loss / len(train_loader[i])\n",
    "                        training_losses.append(avg_train_loss)\n",
    "\n",
    "                        # validation\n",
    "                        model.eval()\n",
    "                        val_losses = []\n",
    "                        with torch.no_grad():\n",
    "                            for X_batch, y_batch in val_loader[i]:\n",
    "                                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                                outputs = model(X_batch)\n",
    "                                mse_loss = criterion(outputs.squeeze(), y_batch.squeeze())\n",
    "                                loss = mse_loss\n",
    "                                val_losses.append(loss.item())\n",
    "\n",
    "                        avg_val_loss = np.mean(val_losses)\n",
    "                        validation_losses.append(avg_val_loss)\n",
    "                        if (epoch + 1) % 50 == 0:\n",
    "                            print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "                        # torch.save(model.state_dict(), 'output/nn-paths/last_model.pth')\n",
    "                        \n",
    "                        # early stopping\n",
    "                        if avg_val_loss < best_loss:\n",
    "                            best_loss = avg_val_loss\n",
    "                            counter = 0\n",
    "                            # save the best model\n",
    "                            torch.save(model.state_dict(), f'/Users/johan/Documents/04 Uni/09 Asset Pricing Data/hour paths/best_model_{layer_dim}_{hidden_dim}_{int(np.abs(np.log10(lambda_l1)))}_{int(np.abs(np.log10(lambda_l2)))}_hour{i}.pth')\n",
    "                        else:\n",
    "                            counter += 1\n",
    "                            if counter >= patience:\n",
    "                                print(f\"Early stopping after {epoch} epochs. Best validation loss: {best_loss:.4f}\")\n",
    "                                break\n",
    "                        \n",
    "                        if epoch == (num_epochs - 1):\n",
    "                            print(f\"Training stopped after {epoch} epochs. Best validation loss: {best_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating all models in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # update the array to load all models\n",
    "# lambda_l1_array = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "# lambda_l2_array = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "# hidden_dim_array = [128, 256, 512]\n",
    "# layer_dim_array = [2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden dim: 512, Layer dim: 2, L1: 0.1, L2: 0.0001, Avg Validation Loss: 72321.7944\n",
      "RMSE (overall): 358.9551, MAE (overall): 283.6950\n",
      "---\n",
      "Best hyperparameters found:\n",
      "Hidden dim = 512, Layer dim = 2, L1 = 0.1, L2 = 0.0001\n",
      "Validation Loss = 72321.7944, RMSE = 358.9551, MAE = 283.6950\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/nn-paths/best_model_2_512_1_4_hour0.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMmodel(input_dim, best_hidden_dim, best_layer_dim, output_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m24\u001b[39m):\n\u001b[0;32m---> 76\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/nn-paths/best_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_layer_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_hidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mlog10(best_lambda_l1)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mlog10(best_lambda_l2)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_hour\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/nn-paths/best_model_hour\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest model saved as output/nn-paths/best_model_hour\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/nn-paths/best_model_2_512_1_4_hour0.pth'"
     ]
    }
   ],
   "source": [
    "best_val_loss = np.inf\n",
    "\n",
    "for hidden_dim in hidden_dim_array:\n",
    "    for layer_dim in layer_dim_array:\n",
    "        for lambda_l1 in lambda_l1_array:\n",
    "            for lambda_l2 in lambda_l2_array:\n",
    "\n",
    "                all_val_losses = []\n",
    "                all_predictions = []  # Store predictions for ALL hours\n",
    "                all_actuals = []      # Store actual targets for ALL hours\n",
    "\n",
    "                for i in range(24):\n",
    "                    model_path = f'/Users/johan/Documents/04 Uni/09 Asset Pricing Data/hour paths/best_model_{layer_dim}_{hidden_dim}_{int(np.abs(np.log10(lambda_l1)))}_{int(np.abs(np.log10(lambda_l2)))}_hour{i}.pth'\n",
    "\n",
    "                    # Load the LSTM model\n",
    "                    model = LSTMmodel(input_dim, hidden_dim, layer_dim, output_dim).to(device)\n",
    "                    model.load_state_dict(torch.load(model_path))\n",
    "                    model.eval()\n",
    "\n",
    "                    # --- Validation Loss for hour i ---\n",
    "                    val_losses_hour = []\n",
    "                    with torch.no_grad():\n",
    "                        for X_batch, y_batch in val_loader[i]:\n",
    "                            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                            outputs = model(X_batch)\n",
    "                            mse_loss = criterion(outputs.squeeze(), y_batch.squeeze())\n",
    "                            val_losses_hour.append(mse_loss.item())\n",
    "\n",
    "                    if len(val_losses_hour) == 0:\n",
    "                        continue\n",
    "                    hour_val_loss = np.mean(val_losses_hour)\n",
    "                    all_val_losses.append(hour_val_loss)\n",
    "\n",
    "                    # --- Test predictions for hour i ---\n",
    "                    with torch.no_grad():\n",
    "                        for X_batch, y_batch in test_loader[i]:\n",
    "                            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                            outputs = model(X_batch)\n",
    "                            # extend them into the global lists\n",
    "                            all_predictions.extend(outputs.squeeze().tolist())\n",
    "                            all_actuals.extend(y_batch.squeeze().tolist())\n",
    "\n",
    "                # 1. Compute aggregated validation loss (averaged across hours)\n",
    "                avg_val_loss = np.mean(all_val_losses)\n",
    "\n",
    "                # 2. Compute single RMSE / MAE on the combined *entire day* test data\n",
    "                overall_rmse = root_mean_squared_error(all_actuals, all_predictions)\n",
    "                overall_mae = mean_absolute_error(all_actuals, all_predictions)\n",
    "\n",
    "                # Compare to best so far\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    best_hidden_dim = hidden_dim\n",
    "                    best_lambda_l1 = lambda_l1\n",
    "                    best_lambda_l2 = lambda_l2\n",
    "                    best_layer_dim = layer_dim\n",
    "                    best_rmse = overall_rmse\n",
    "                    best_mae = overall_mae\n",
    "\n",
    "                # Print aggregated results for this hyperparam setting\n",
    "                print(f'Hidden dim: {hidden_dim}, Layer dim: {layer_dim}, '\n",
    "                      f'L1: {lambda_l1}, L2: {lambda_l2}, '\n",
    "                      f'Avg Validation Loss: {avg_val_loss:.4f}')\n",
    "                print(f'RMSE (overall): {overall_rmse:.4f}, MAE (overall): {overall_mae:.4f}')\n",
    "                print('---')\n",
    "\n",
    "# After all hyperparam combos:\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(f'Hidden dim = {best_hidden_dim}, Layer dim = {best_layer_dim}, '\n",
    "      f'L1 = {best_lambda_l1}, L2 = {best_lambda_l2}')\n",
    "print(f'Validation Loss = {best_val_loss:.4f}, RMSE = {best_rmse:.4f}, MAE = {best_mae:.4f}')\n",
    "\n",
    "# save the best model as best_model.pth\n",
    "model = LSTMmodel(input_dim, best_hidden_dim, best_layer_dim, output_dim).to(device)\n",
    "for i in range(24):\n",
    "    model.load_state_dict(torch.load(f'/Users/johan/Documents/04 Uni/09 Asset Pricing Data/hour paths/best_model_{layer_dim}_{hidden_dim}_{int(np.abs(np.log10(lambda_l1)))}_{int(np.abs(np.log10(lambda_l2)))}_hour{i}.pth'))\n",
    "    torch.save(model.state_dict(), f'/Users/johan/Documents/04 Uni/09 Asset Pricing Data/hour paths/best_model_hour{i}.pth')\n",
    "    print(f'Best model saved as /Users/johan/Documents/04 Uni/09 Asset Pricing Data/hour paths/best_model_hour{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/nn-paths/best_model_hour[0].pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the LSTM model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMmodel(input_dim, hidden_dim, layer_dim, output_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path))\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     11\u001b[0m preds_for_hour_i \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/nn-paths/best_model_hour[0].pth'"
     ]
    }
   ],
   "source": [
    "hour_predictions = []  # Store predictions for ALL hours\n",
    "hour_actuals = []      # Store actual targets for ALL hours\n",
    "\n",
    "for i in range(24):\n",
    "    model_path = f'output/nn-paths/best_model_hour[{i}].pth'\n",
    "    # Load the LSTM model\n",
    "    model = LSTMmodel(input_dim, hidden_dim, layer_dim, output_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    preds_for_hour_i = []\n",
    "    acts_for_hour_i = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader[i]:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            preds_for_hour_i.extend(outputs.squeeze().tolist())\n",
    "            acts_for_hour_i.extend(y_batch.squeeze().tolist())\n",
    "\n",
    "    # Store the lists in hourly_predictions / hourly_actuals\n",
    "    hour_predictions.append(preds_for_hour_i)\n",
    "    hour_actuals.append(acts_for_hour_i)\n",
    "\n",
    "hour_predictions = [np.array(p) for p in hour_predictions] \n",
    "hour_actuals     = [np.array(a) for a in hour_actuals] \n",
    "\n",
    "num_samples_per_hour = len(hour_predictions[0])\n",
    "assert all(len(hour_predictions[h]) == num_samples_per_hour for h in range(24))\n",
    "\n",
    "# Stack them to shape (24, num_samples_per_hour)\n",
    "preds_2d = np.vstack(hour_predictions)  # shape: (24, N)\n",
    "acts_2d  = np.vstack(hour_actuals) \n",
    "\n",
    "preds_ordered = preds_2d.T.reshape(-1)\n",
    "acts_ordered  = acts_2d.T.reshape(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371.53169124862654, 294.91109526943467)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(acts_ordered, preds_ordered), mean_absolute_error(acts_ordered, preds_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(preds_ordered, label='Predicted', alpha=0.8)\n",
    "plt.plot(acts_ordered,  label='Actual', alpha=0.8)\n",
    "plt.title(\"Interleaved Predictions vs. Actual (First from Hour0, Hour1, ..., Hour23)\")\n",
    "plt.xlabel(\"Interleaved Sample Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
