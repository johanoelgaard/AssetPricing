{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from DMI:\n",
    "=======================\n",
    "https://dmigw.govcloud.dk/v2/metObs/bulk/?api-key=d40321ee-7de5-4417-a0bf-108bd34061ab\n",
    "\n",
    "https://dmigw.govcloud.dk/v2/climateData/bulk/?api-key=fa9056ec-2f41-4042-828b-91750e966966\n",
    "\n",
    "This notebook opens and transforms bulk climateData from DMI (Danish Meteorological Institute) into a pandas DataFrame and then saves it as a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import orjson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api keys for different DMI services\n",
    "forecast_api_key = 'e55dced6-70fb-44f1-a658-cdef62c74b6a'\n",
    "climate_api_key = 'fa9056ec-2f41-4042-828b-91750e966966'\n",
    "metobs_api_key = 'd40321ee-7de5-4417-a0bf-108bd34061ab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk loader function for every year\n",
    "def bulk_load_year(year, file_paths):\n",
    "    all_records = []\n",
    "    \n",
    "    total_files = len(file_paths)\n",
    "    processed_files = 0\n",
    "\n",
    "    print(f\"\\nStarted processing {total_files} files for year {year}.\")\n",
    "\n",
    "    # Process files sequentially\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:  # Open in binary mode for orjson\n",
    "                for line in file:\n",
    "                    if line.strip():\n",
    "                        json_obj = orjson.loads(line)\n",
    "                        properties = json_obj.get('properties', {})\n",
    "                        geometry = json_obj.get('geometry', {})\n",
    "\n",
    "                        # Filter out records where timeResolution is not 'hour'\n",
    "                        if properties.get('timeResolution') != 'hour':\n",
    "                            continue\n",
    "\n",
    "                        cellId = properties.get('cellId')\n",
    "                        from_time = properties.get('from')\n",
    "                        to_time = properties.get('to')\n",
    "                        parameterId = properties.get('parameterId')\n",
    "                        value = properties.get('value')\n",
    "\n",
    "                        # Skip records with missing critical data\n",
    "                        if None in (cellId, from_time, to_time, parameterId, value):\n",
    "                            continue\n",
    "\n",
    "                        key = (cellId, from_time, to_time)\n",
    "\n",
    "                        # Build a record\n",
    "                        record = {\n",
    "                            'key': key,\n",
    "                            'cellId': cellId,\n",
    "                            'from': from_time,\n",
    "                            'to': to_time,\n",
    "                            parameterId: value\n",
    "                        }\n",
    "\n",
    "                        # Always add geometry\n",
    "                        record['geometry_type'] = geometry.get('type')\n",
    "                        coordinates = geometry.get('coordinates', [[]])\n",
    "                        flat_coords = coordinates[0] if coordinates else []\n",
    "                        record['coordinates'] = flat_coords\n",
    "\n",
    "                        all_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "        # Update the processed files counter\n",
    "        processed_files += 1\n",
    "\n",
    "        # Print progress every 10 files\n",
    "        if processed_files % 100 == 0 or processed_files == total_files:\n",
    "            print(f\"Processed {processed_files}/{total_files} files for year {year}.\")\n",
    "\n",
    "    if not all_records:\n",
    "        print(f\"No records were loaded for year {year}. Please check your data and filters.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "\n",
    "    # Aggregate records by key\n",
    "    aggregated_data = {}\n",
    "    for record in all_records:\n",
    "        key = record.pop('key')\n",
    "        if key not in aggregated_data:\n",
    "            aggregated_data[key] = record\n",
    "        else:\n",
    "            # Update existing record with new parameterId and value\n",
    "            aggregated_data[key].update(record)\n",
    "\n",
    "    # Convert the aggregated data into a DataFrame\n",
    "    df = pd.DataFrame(aggregated_data.values())\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"DataFrame is empty after aggregation for year {year}.\")\n",
    "        return df\n",
    "\n",
    "    # Optimize data types if 'cellId' exists\n",
    "    if 'cellId' in df.columns:\n",
    "        df['cellId'] = df['cellId'].astype('category')\n",
    "    else:\n",
    "        print(f\"Warning: 'cellId' column is missing in the DataFrame for year {year}.\")\n",
    "\n",
    "    if 'from' in df.columns:\n",
    "        df['from'] = pd.to_datetime(df['from'])\n",
    "    if 'to' in df.columns:\n",
    "        df['to'] = pd.to_datetime(df['to'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# function to process all in a folder\n",
    "def process_all_years(folder_path, output_folder_path):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "    # Gather all file paths\n",
    "    file_paths = [\n",
    "        os.path.join(folder_path, filename)\n",
    "        for filename in os.listdir(folder_path)\n",
    "        if filename.endswith('.txt')\n",
    "    ]\n",
    "\n",
    "    # Create a mapping from year to list of file paths\n",
    "    year_to_files = {}\n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # Extract the year from the filename using regex\n",
    "        match = re.match(r'(\\d{4})-\\d{2}-\\d{2}\\.txt', filename)\n",
    "        if match:\n",
    "            year = match.group(1)\n",
    "            year_to_files.setdefault(year, []).append(file_path)\n",
    "        else:\n",
    "            print(f\"Filename {filename} does not match expected pattern. Skipping.\")\n",
    "\n",
    "    # Process files for each year\n",
    "    for year in sorted(year_to_files.keys()):\n",
    "        files_for_year = year_to_files[year]\n",
    "        df_year = bulk_load_year(year, files_for_year)\n",
    "\n",
    "        if not df_year.empty:\n",
    "            # Construct the output file path\n",
    "            output_filename = f\"{year}.csv\"\n",
    "            output_file_path = os.path.join(output_folder_path, output_filename)\n",
    "\n",
    "            # Save the DataFrame to a CSV file in the specified output folder\n",
    "            df_year.to_csv(output_file_path, index=False)\n",
    "            print(f\"Saved data for year {year} to {output_file_path}.\")\n",
    "        else:\n",
    "            print(f\"No data to save for year {year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started processing 1 files for year 2010.\n",
      "Processed 1/1 files for year 2010.\n",
      "Saved data for year 2010 to /Users/johan/Downloads/20k-output/2010.csv.\n",
      "\n",
      "Started processing 365 files for year 2011.\n",
      "Processed 100/365 files for year 2011.\n",
      "Processed 200/365 files for year 2011.\n",
      "Processed 300/365 files for year 2011.\n",
      "Processed 365/365 files for year 2011.\n",
      "Saved data for year 2011 to /Users/johan/Downloads/20k-output/2011.csv.\n",
      "\n",
      "Started processing 366 files for year 2012.\n",
      "Processed 100/366 files for year 2012.\n",
      "Processed 200/366 files for year 2012.\n",
      "Processed 300/366 files for year 2012.\n",
      "Processed 366/366 files for year 2012.\n",
      "Saved data for year 2012 to /Users/johan/Downloads/20k-output/2012.csv.\n",
      "\n",
      "Started processing 365 files for year 2013.\n",
      "Processed 100/365 files for year 2013.\n",
      "Processed 200/365 files for year 2013.\n",
      "Processed 300/365 files for year 2013.\n",
      "Processed 365/365 files for year 2013.\n",
      "Saved data for year 2013 to /Users/johan/Downloads/20k-output/2013.csv.\n",
      "\n",
      "Started processing 365 files for year 2014.\n",
      "Processed 100/365 files for year 2014.\n",
      "Processed 200/365 files for year 2014.\n",
      "Processed 300/365 files for year 2014.\n",
      "Processed 365/365 files for year 2014.\n",
      "Saved data for year 2014 to /Users/johan/Downloads/20k-output/2014.csv.\n",
      "\n",
      "Started processing 365 files for year 2015.\n",
      "Processed 100/365 files for year 2015.\n",
      "Processed 200/365 files for year 2015.\n",
      "Processed 300/365 files for year 2015.\n",
      "Processed 365/365 files for year 2015.\n",
      "Saved data for year 2015 to /Users/johan/Downloads/20k-output/2015.csv.\n",
      "\n",
      "Started processing 366 files for year 2016.\n",
      "Processed 100/366 files for year 2016.\n",
      "Processed 200/366 files for year 2016.\n",
      "Processed 300/366 files for year 2016.\n",
      "Processed 366/366 files for year 2016.\n",
      "Saved data for year 2016 to /Users/johan/Downloads/20k-output/2016.csv.\n",
      "\n",
      "Started processing 365 files for year 2017.\n",
      "Processed 100/365 files for year 2017.\n",
      "Processed 200/365 files for year 2017.\n",
      "Processed 300/365 files for year 2017.\n",
      "Processed 365/365 files for year 2017.\n",
      "Saved data for year 2017 to /Users/johan/Downloads/20k-output/2017.csv.\n",
      "\n",
      "Started processing 365 files for year 2018.\n",
      "Processed 100/365 files for year 2018.\n",
      "Processed 200/365 files for year 2018.\n",
      "Processed 300/365 files for year 2018.\n",
      "Processed 365/365 files for year 2018.\n",
      "Saved data for year 2018 to /Users/johan/Downloads/20k-output/2018.csv.\n",
      "\n",
      "Started processing 365 files for year 2019.\n",
      "Processed 100/365 files for year 2019.\n",
      "Processed 200/365 files for year 2019.\n",
      "Processed 300/365 files for year 2019.\n",
      "Processed 365/365 files for year 2019.\n",
      "Saved data for year 2019 to /Users/johan/Downloads/20k-output/2019.csv.\n",
      "\n",
      "Started processing 366 files for year 2020.\n",
      "Processed 100/366 files for year 2020.\n",
      "Processed 200/366 files for year 2020.\n",
      "Processed 300/366 files for year 2020.\n",
      "Processed 366/366 files for year 2020.\n",
      "Saved data for year 2020 to /Users/johan/Downloads/20k-output/2020.csv.\n",
      "\n",
      "Started processing 365 files for year 2021.\n",
      "Processed 100/365 files for year 2021.\n",
      "Processed 200/365 files for year 2021.\n",
      "Processed 300/365 files for year 2021.\n",
      "Processed 365/365 files for year 2021.\n",
      "Saved data for year 2021 to /Users/johan/Downloads/20k-output/2021.csv.\n",
      "\n",
      "Started processing 365 files for year 2022.\n",
      "Processed 100/365 files for year 2022.\n",
      "Processed 200/365 files for year 2022.\n",
      "Processed 300/365 files for year 2022.\n",
      "Processed 365/365 files for year 2022.\n",
      "Saved data for year 2022 to /Users/johan/Downloads/20k-output/2022.csv.\n",
      "\n",
      "Started processing 365 files for year 2023.\n",
      "Processed 100/365 files for year 2023.\n",
      "Processed 200/365 files for year 2023.\n",
      "Processed 300/365 files for year 2023.\n",
      "Processed 365/365 files for year 2023.\n",
      "Saved data for year 2023 to /Users/johan/Downloads/20k-output/2023.csv.\n",
      "\n",
      "Started processing 283 files for year 2024.\n",
      "Processed 100/283 files for year 2024.\n",
      "Processed 200/283 files for year 2024.\n",
      "Processed 283/283 files for year 2024.\n",
      "Saved data for year 2024 to /Users/johan/Downloads/20k-output/2024.csv.\n"
     ]
    }
   ],
   "source": [
    "# paths\n",
    "folder_path = '/Users/johan/Downloads/20k-load'  # Update with your folder path\n",
    "output_folder_path = '/Users/johan/Downloads/20k-output'  # Specify your output folder path\n",
    "\n",
    "# run the function\n",
    "process_all_years(folder_path, output_folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
